[
  {
    "id": 1,
    "question": "What is MongoDB and what are its key characteristics?",
    "solution": "**MongoDB** is a popular **open-source, document-oriented NoSQL database** designed for high performance, high availability, and easy scalability.\n\n**Key Characteristics:**\n\n1. **Document-Oriented:** Stores data in flexible, JSON-like documents (specifically, BSON - Binary JSON). Fields can vary from document to document within the same collection.\n\n2. **Schema-less:** Unlike SQL databases that enforce a rigid schema, MongoDB allows storing documents with different structures in the same collection.\n\n3. **NoSQL:** Part of the NoSQL (Not Only SQL) movement, designed to address limitations of relational databases for modern applications requiring massive scale and flexible data models.\n\n4. **Distributed Database:** Built for horizontal scaling (sharding) to handle large volumes of data and traffic across multiple servers.",
    "difficulty": "Easy",
    "category": "Database",
    "type": "Conceptual",
    "tags": [
      "MongoDB",
      "NoSQL",
      "Document Database",
      "Schema-less",
      "BSON"
    ]
  },
  {
    "id": 2,
    "question": "Explain MongoDB's salient features in detail.",
    "solution": "**MongoDB's Salient Features:**\n\n1. **Document Model (BSON):**\n   - **Flexibility:** Easily evolve schema without downtime\n   - **Richness:** Supports embedded documents and arrays\n   - **Example:** A movie document can embed IMDB rating, cast, and genres directly\n\n2. **Scalability (Horizontal Scaling via Sharding):**\n   - Distributes data across multiple servers (shards)\n   - Handles massive amounts of data and high read/write loads\n\n3. **High Availability (Replica Sets):**\n   - Provides redundancy and automatic failover\n   - One primary server, multiple secondaries\n   - Automatic election of new primary if current fails\n\n4. **Indexing:**\n   - Supports various index types (single field, compound, multi-key, text, geospatial, unique)\n   - Significantly improves query performance\n\n5. **Aggregation Framework:**\n   - Powerful ETL tool within the database\n   - Pipeline of stages (`$match`, `$group`, `$sort`, `$project`, `$unwind`)\n   - Enables complex data analysis and transformations\n\n6. **Ad Hoc Queries:**\n   - Supports rich, expressive queries for finding specific documents, ranges, and patterns",
    "difficulty": "Medium",
    "category": "Database",
    "type": "Conceptual",
    "tags": [
      "MongoDB Features",
      "BSON",
      "Sharding",
      "Replica Sets",
      "Indexing",
      "Aggregation"
    ]
  },
  {
    "id": 3,
    "question": "Compare MongoDB with Relational Databases (SQL). What are the key differences?",
    "solution": "**MongoDB vs Relational Databases:**\n\n**Detailed Comparison:**\n\n**1. Data Model**\n- **Relational Databases:** Tables with fixed schemas (rows & columns)\n- **MongoDB:** Collections of flexible, JSON-like documents\n\n**2. Schema**\n- **Relational Databases:** Rigid, pre-defined schema; changes require migrations\n- **MongoDB:** Flexible/Dynamic schema; easily adaptable\n\n**3. Relationships**\n- **Relational Databases:** Joins (explicitly defined relationships)\n- **MongoDB:** Embedded documents or referencing\n\n**4. Scaling**\n- **Relational Databases:** Primarily Vertical; Horizontal scaling complex\n- **MongoDB:** Horizontal Scaling (Sharding) built-in\n\n**5. Query Language**\n- **Relational Databases:** SQL (Structured Query Language)\n- **MongoDB:** MongoDB Query Language (MQL) - JSON-like\n\n**6. Data Integrity**\n- **Relational Databases:** Strong ACID compliance by design\n- **MongoDB:** ACID for single-document; Multi-document transactions available\n\n**7. Joins**\n- **Relational Databases:** Core operation to combine data from multiple tables\n- **MongoDB:** No direct join; use `$lookup` in aggregation\n\n**8. Use Cases**\n- **Relational Databases:** Financial systems, traditional ERP, complex analytical queries\n- **MongoDB:** Big Data, IoT, Mobile Apps, Real-time analytics, CMS\n\n**Summary of Key Differences:**\n\n- **Data Model:** Relational databases use tables with fixed schemas, while MongoDB uses flexible document collections\n- **Schema:** SQL databases require predefined schemas, MongoDB allows dynamic schemas\n- **Relationships:** SQL uses joins, MongoDB uses embedded documents or references\n- **Scaling:** SQL primarily scales vertically, MongoDB has built-in horizontal scaling\n- **Query Language:** SQL vs MongoDB Query Language (MQL)\n- **Transactions:** SQL has strong ACID by design, MongoDB has ACID for single documents with multi-document transactions available",
    "difficulty": "Medium",
    "category": "Database",
    "type": "Comparison",
    "tags": [
      "MongoDB vs SQL",
      "NoSQL vs Relational",
      "Database Comparison",
      "ACID",
      "Joins"
    ]
  },
  {
    "id": 4,
    "question": "How do you connect to MongoDB using MongoDB Compass?",
    "solution": "**Connecting to MongoDB in Compass:**\n\n1. **Open MongoDB Compass:** Launch the application\n\n2. **New Connection:**\n   - First time: Connection screen appears automatically\n   - Otherwise: Click **File > Connect To...** or \"New Connection\" button\n\n3. **Enter Connection String:** \n   - **For Atlas (Cloud):** `mongodb+srv://<username>:<password>@<cluster-url>/test?retryWrites=true&w=majority`\n   - **For Local:** `mongodb://localhost:27017/`\n\n4. **Connect:** Click \"Connect\"\n\n**After Connection:**\n- See list of databases\n- Click on database (e.g., `sample_mflix`) to explore collections\n- Click on collection (e.g., `movies`) to view documents\n\n**Query Bar Sections:**\n- **Filter:** Query conditions (find() part)\n- **Projection:** Fields to include/exclude\n- **Sort:** Order results\n- **Limit:** Maximum documents to return\n- **Skip:** Documents to skip from beginning",
    "difficulty": "Easy",
    "category": "Database",
    "type": "Practical",
    "tags": [
      "MongoDB Compass",
      "Connection",
      "Atlas",
      "Local MongoDB",
      "Query Bar"
    ]
  },
  {
    "id": 5,
    "question": "Write MongoDB queries to find documents with different conditions using comparison operators.",
    "solution": "**MongoDB Comparison Operators Examples:**\n\n```javascript\n// Find all movies\ndb.movies.find({});\n\n// Find movies from 1994\ndb.movies.find({\"year\": 1994});\n\n// Movies with IMDB rating >= 9.0\ndb.movies.find({\"imdb.rating\": {\"$gte\": 9.0}});\n\n// Movies released after 2000 with high ratings\ndb.movies.find({\n    \"year\": {\"$gt\": 2000},\n    \"imdb.rating\": {\"$gte\": 8.5}\n});\n\n// Movies NOT from 1994\ndb.movies.find({\"year\": {\"$ne\": 1994}});\n\n// Movies between 1990 and 2000\ndb.movies.find({\n    \"year\": {\"$gte\": 1990, \"$lt\": 2000}\n});\n\n// Movies with rating less than 5\ndb.movies.find({\"imdb.rating\": {\"$lt\": 5}});\n```\n\n**Comparison Operators:**\n- `$gt`: Greater than\n- `$gte`: Greater than or equal\n- `$lt`: Less than\n- `$lte`: Less than or equal\n- `$ne`: Not equal\n- `$eq`: Equal (default behavior)",
    "difficulty": "Easy",
    "category": "Database",
    "type": "Query",
    "tags": [
      "MongoDB Queries",
      "Comparison Operators",
      "Find",
      "Filtering"
    ]
  },
  {
    "id": 6,
    "question": "Demonstrate the use of logical operators ($and, $or, $not, $nor) in MongoDB queries.",
    "solution": "**MongoDB Logical Operators Examples:**\n\n```javascript\n// $or: Movies from 1994 OR Action genre\ndb.movies.find({\n    \"$or\": [\n        {\"year\": 1994},\n        {\"genres\": \"Action\"}\n    ]\n});\n\n// $and: Movies from 1990s AND Action genre\ndb.movies.find({\n    \"$and\": [\n        {\"year\": {\"$gte\": 1990, \"$lt\": 2000}},\n        {\"genres\": \"Action\"}\n    ]\n});\n\n// $nor: Movies that are NOT Action or Comedy\ndb.movies.find({\n    \"$nor\": [\n        {\"genres\": \"Action\"},\n        {\"genres\": \"Comedy\"}\n    ]\n});\n\n// $not: Movies where year is NOT greater than 2000\ndb.movies.find({\n    \"year\": {\"$not\": {\"$gt\": 2000}}\n});\n\n// Complex combination\ndb.movies.find({\n    \"$and\": [\n        {\n            \"$or\": [\n                {\"genres\": \"Drama\"},\n                {\"genres\": \"Thriller\"}\n            ]\n        },\n        {\"year\": {\"$gte\": 2000}},\n        {\"imdb.rating\": {\"$gte\": 7.0}}\n    ]\n});\n```\n\n**Logical Operators:**\n- `$or`: Matches documents that satisfy at least one condition\n- `$and`: Requires all conditions to be true\n- `$nor`: Matches documents that fail all conditions\n- `$not`: Inverts the effect of a query expression",
    "difficulty": "Medium",
    "category": "Database",
    "type": "Query",
    "tags": [
      "MongoDB Queries",
      "Logical Operators",
      "Complex Queries",
      "Boolean Logic"
    ]
  },
  {
    "id": 7,
    "question": "How do you work with arrays in MongoDB using array operators?",
    "solution": "**MongoDB Array Operators Examples:**\n\n```javascript\n// $all: Movies that have BOTH Crime AND Drama genres\ndb.movies.find({\"genres\": {\"$all\": [\"Crime\", \"Drama\"]}});\n\n// $size: Movies with exactly 3 genres\ndb.movies.find({\"genres\": {\"$size\": 3}});\n\n// $in: Movies with any of these genres\ndb.movies.find({\"genres\": {\"$in\": [\"Action\", \"Adventure\", \"Sci-Fi\"]}});\n\n// $nin: Movies NOT in these genres\ndb.movies.find({\"genres\": {\"$nin\": [\"Horror\", \"Thriller\"]}});\n\n// Movies with at least one actor from this list\ndb.movies.find({\"cast\": {\"$in\": [\"Tom Hanks\", \"Morgan Freeman\", \"Brad Pitt\"]}});\n\n// $elemMatch: Complex conditions on array elements\ndb.movies.find({\n    \"cast\": {\n        \"$elemMatch\": {\n            \"$regex\": \"^Tom\",\n            \"$options\": \"i\"\n        }\n    }\n});\n\n// Check if field exists and is an array\ndb.movies.find({\n    \"genres\": {\"$exists\": true, \"$type\": \"array\"}\n});\n```\n\n**Array Operators:**\n- `$all`: All specified elements must be present\n- `$size`: Array has exact number of elements\n- `$in`: Matches any of the specified values\n- `$nin`: Does not match any of the specified values\n- `$elemMatch`: Matches documents with array elements that satisfy condition",
    "difficulty": "Medium",
    "category": "Database",
    "type": "Query",
    "tags": [
      "MongoDB Arrays",
      "Array Operators",
      "elemMatch",
      "Array Queries"
    ]
  },
  {
    "id": 8,
    "question": "Explain projection in MongoDB with examples. How do you include and exclude fields?",
    "solution": "**MongoDB Projection Examples:**\n\n```javascript\n// Include only title and year, exclude _id\ndb.movies.find(\n    {\"year\": 2010}, \n    {\"title\": 1, \"year\": 1, \"_id\": 0}\n);\n\n// Include only specific fields (1 = include)\ndb.movies.find({}, {\"title\": 1, \"genres\": 1}).limit(3);\n\n// Exclude specific fields (0 = exclude)\ndb.movies.find({}, {\"plot\": 0, \"fullplot\": 0}).limit(3);\n\n// Project nested fields\ndb.movies.find({}, {\"title\": 1, \"imdb.rating\": 1, \"_id\": 0}).limit(3);\n\n// Project array elements\ndb.movies.find(\n    {}, \n    {\n        \"title\": 1, \n        \"genres\": {\"$slice\": 2}, // First 2 genres only\n        \"_id\": 0\n    }\n).limit(3);\n\n// Conditional projection using $cond\ndb.movies.find({}, {\n    \"title\": 1,\n    \"ratingCategory\": {\n        \"$cond\": {\n            \"if\": {\"$gte\": [\"$imdb.rating\", 8]},\n            \"then\": \"High\",\n            \"else\": \"Standard\"\n        }\n    },\n    \"_id\": 0\n}).limit(5);\n```\n\n**Projection Rules:**\n- Use `1` to include fields, `0` to exclude\n- Cannot mix include/exclude (except for `_id`)\n- `_id` is included by default unless explicitly excluded\n- Can project nested fields using dot notation\n- Use `$slice` for array field projection",
    "difficulty": "Medium",
    "category": "Database",
    "type": "Query",
    "tags": [
      "MongoDB Projection",
      "Field Selection",
      "Include Exclude",
      "Nested Fields"
    ]
  },
  {
    "id": 9,
    "question": "How do you sort, limit, and skip results in MongoDB queries?",
    "solution": "**MongoDB Sort, Limit, and Skip Examples:**\n\n```javascript\n// Sort movies from 1994 by title (ascending)\ndb.movies.find({\"year\": 1994}).sort({\"title\": 1});\n\n// Sort by multiple fields: year descending, then title ascending\ndb.movies.find({}).sort({\"year\": -1, \"title\": 1}).limit(5);\n\n// Sort by IMDB rating (highest first)\ndb.movies.find({\"imdb.rating\": {\"$exists\": true}})\n         .sort({\"imdb.rating\": -1})\n         .limit(10);\n\n// Pagination: Skip first 5, get next 5 (page 2)\ndb.movies.find({}).skip(5).limit(5);\n\n// Get top 10 highest rated movies\ndb.movies.find({\"imdb.rating\": {\"$exists\": true}})\n         .sort({\"imdb.rating\": -1})\n         .limit(10);\n\n// Efficient pagination with sort for consistent results\ndb.movies.find({})\n         .sort({\"_id\": 1})\n         .skip(10)\n         .limit(5);\n\n// Calculate pagination info\nconst totalMovies = db.movies.countDocuments({});\nconst pageSize = 10;\nconst totalPages = Math.ceil(totalMovies / pageSize);\nprint(`Total movies: ${totalMovies}, Total pages: ${totalPages}`);\n```\n\n**Key Points:**\n- `1` = ascending order, `-1` = descending order\n- Always use `sort()` with pagination for consistent results\n- Chain methods: `find().sort().skip().limit()`\n- For large datasets, consider using indexes on sort fields",
    "difficulty": "Medium",
    "category": "Database",
    "type": "Query",
    "tags": [
      "MongoDB Sorting",
      "Pagination",
      "Limit",
      "Skip",
      "Performance"
    ]
  },
  {
    "id": 10,
    "question": "Explain MongoDB's insertOne() and insertMany() methods with examples.",
    "solution": "**MongoDB Insert Operations:**\n\n```javascript\n// insertOne() - Insert a single document\ndb.movies.insertOne({\n    \"title\": \"New Movie 2025\",\n    \"year\": 2025,\n    \"plot\": \"A great new movie.\",\n    \"genres\": [\"Drama\", \"Thriller\"],\n    \"imdb\": {\n        \"rating\": 8.5,\n        \"votes\": 1000\n    }\n});\n\n// insertMany() - Insert multiple documents\ndb.movies.insertMany([\n    {\n        \"title\": \"Movie One\",\n        \"year\": 2025,\n        \"genres\": [\"Action\"]\n    },\n    {\n        \"title\": \"Movie Two\", \n        \"year\": 2025,\n        \"genres\": [\"Comedy\"]\n    }\n]);\n\n// Insert with custom _id\ndb.movies.insertOne({\n    \"_id\": \"custom_movie_001\",\n    \"title\": \"Custom ID Movie\",\n    \"year\": 2025\n});\n\n// insertMany() with options\ndb.movies.insertMany([\n    {\"title\": \"Movie A\", \"year\": 2025},\n    {\"title\": \"Movie B\", \"year\": 2025}\n], { ordered: false }); // Continue on error\n\n// Error handling\ntry {\n    const result = db.movies.insertMany(documents);\n    console.log(`${result.insertedCount} documents inserted.`);\n} catch (error) {\n    console.error(\"Insert error:\", error);\n}\n```\n\n**Key Differences:**\n- `insertOne()`: Single document, atomic operation\n- `insertMany()`: Multiple documents, more efficient for bulk inserts\n- `ordered: false`: Continue inserting even if some documents fail\n- MongoDB auto-generates `_id` if not provided\n- `insertMany()` reduces network overhead vs multiple `insertOne()` calls",
    "difficulty": "Easy",
    "category": "Database",
    "type": "CRUD",
    "tags": [
      "MongoDB Insert",
      "insertOne",
      "insertMany",
      "CRUD Operations",
      "Bulk Insert"
    ]
  },
  {
    "id": 11,
    "question": "How do you update documents in MongoDB? Explain updateOne(), updateMany(), and update operators.",
    "solution": "**MongoDB Update Operations:**\n\n```javascript\n// updateOne() - Update first matching document\ndb.movies.updateOne(\n    {\"title\": \"Movie Title\"}, // filter\n    {\n        \"$set\": {\n            \"plot\": \"Updated plot\",\n            \"imdb.rating\": 9.0\n        }\n    }\n);\n\n// updateMany() - Update all matching documents\ndb.movies.updateMany(\n    {\"year\": 2025}, // filter\n    {\n        \"$set\": {\"updated\": true},\n        \"$currentDate\": {\"lastModified\": true}\n    }\n);\n\n// Upsert (update if exists, insert if doesn't)\ndb.movies.updateOne(\n    {\"title\": \"Non-existent Movie\"},\n    {\n        \"$set\": {\n            \"title\": \"Non-existent Movie\",\n            \"year\": 2025,\n            \"created\": new Date()\n        }\n    },\n    {\"upsert\": true}\n);\n\n// Multiple update operators\ndb.movies.updateOne(\n    {\"title\": \"Movie Title\"},\n    {\n        \"$inc\": {\"imdb.votes\": 100}, // increment by 100\n        \"$push\": {\"genres\": \"Thriller\"}, // add to array\n        \"$unset\": {\"unwanted_field\": \"\"}, // remove field\n        \"$rename\": {\"old_field\": \"new_field\"} // rename field\n    }\n);\n\n// Array update operators\ndb.movies.updateOne(\n    {\"title\": \"Movie Title\"},\n    {\n        \"$addToSet\": {\"genres\": \"Action\"}, // add if not exists\n        \"$pull\": {\"genres\": \"Horror\"}, // remove from array\n        \"$pop\": {\"cast\": 1} // remove last element (1) or first (-1)\n    }\n);\n```\n\n**Update Operators:**\n- `$set`: Set field value\n- `$inc`: Increment numeric value\n- `$push`: Add element to array\n- `$addToSet`: Add to array if not exists\n- `$pull`: Remove from array\n- `$unset`: Remove field\n- `$rename`: Rename field\n- `$currentDate`: Set to current date",
    "difficulty": "Medium",
    "category": "Database",
    "type": "CRUD",
    "tags": [
      "MongoDB Update",
      "updateOne",
      "updateMany",
      "Update Operators",
      "Upsert"
    ]
  },
  {
    "id": 12,
    "question": "Explain why updateMany() with update operators is superior to fetching and updating documents in a loop.",
    "solution": "**Why updateMany() with Update Operators is Superior:**\n\n**1. Atomicity and Concurrency** 🔐\n- Update operators perform atomic operations on the server\n- Prevents race conditions in concurrent environments\n- No risk of data corruption from simultaneous updates\n\n**2. Performance and Efficiency** 🚀\n- **Reduced Network Traffic**: Only send update command, not full documents\n- **Server-Side Execution**: MongoDB server optimized for bulk operations\n- **Single Round Trip**: One request vs multiple fetch-update cycles\n\n**3. Specific Operations** 🎯\n- `$set`: Updates field values efficiently\n- `$inc`: Prevents race conditions in counter updates\n- `$push`: Safe array operations\n\n**Example Comparison:**\n\n```javascript\n// ✅ RIGHT WAY (updateMany with operators)\ndb.orders.updateMany(\n    { status: \"pending\" },\n    { $set: { status: \"processed\" } }\n);\n\n// ❌ WRONG WAY (fetch-update loop)\nconst pendingOrders = await db.orders.find({ status: \"pending\" }).toArray();\nfor (const order of pendingOrders) {\n    order.status = \"processed\";\n    await db.orders.updateOne(\n        { _id: order._id }, \n        { $set: { status: \"processed\" } }\n    );\n}\n```\n\n**Problems with Loop Approach:**\n- High network overhead (multiple round trips)\n- Slow performance\n- Race condition vulnerabilities\n- Potential data inconsistency\n- Resource intensive\n\n**Benefits of updateMany():**\n- Single network request\n- Atomic execution\n- Server-optimized performance\n- Consistent data state\n- Efficient resource usage",
    "difficulty": "Medium",
    "category": "Database",
    "type": "Best Practices",
    "tags": [
      "MongoDB Performance",
      "updateMany",
      "Atomicity",
      "Race Conditions",
      "Best Practices"
    ]
  },
  {
    "id": 13,
    "question": "How do you delete documents in MongoDB? Explain deleteOne(), deleteMany(), and findOneAndDelete().",
    "solution": "**MongoDB Delete Operations:**\n\n```javascript\n// deleteOne() - Delete first matching document\ndb.movies.deleteOne({\"title\": \"Movie to Delete\"});\n\n// deleteMany() - Delete all matching documents\ndb.movies.deleteMany({\"year\": 2025});\n\n// Delete with complex filter\ndb.movies.deleteMany({\n    \"$and\": [\n        {\"year\": {\"$lt\": 1950}},\n        {\"imdb.rating\": {\"$lt\": 5}}\n    ]\n});\n\n// findOneAndDelete() - Delete and return the deleted document\nconst deletedMovie = db.movies.findOneAndDelete(\n    {\"title\": \"Custom ID Movie\"}\n);\nprint(\"Deleted movie:\", deletedMovie.title);\n\n// Delete with options\ndb.movies.deleteMany(\n    {\"year\": {\"$lt\": 1920}},\n    {\"collation\": {\"locale\": \"en\", \"strength\": 2}}\n);\n\n// Conditional delete based on array size\ndb.movies.deleteMany({\n    \"genres\": {\"$size\": 0} // Delete movies with no genres\n});\n\n// Delete all documents (be careful!)\n// db.movies.deleteMany({}); // Uncomment to delete all\n\n// Get count before deletion\nconst countBefore = db.movies.countDocuments({\"year\": {\"$lt\": 1920}});\nconst result = db.movies.deleteMany({\"year\": {\"$lt\": 1920}});\nprint(`Deleted ${result.deletedCount} out of ${countBefore} documents`);\n```\n\n**Delete Methods:**\n- `deleteOne()`: Removes first matching document\n- `deleteMany()`: Removes all matching documents\n- `findOneAndDelete()`: Removes and returns the deleted document\n\n**Return Values:**\n- `deleteOne()`/`deleteMany()`: `{acknowledged: true, deletedCount: n}`\n- `findOneAndDelete()`: The actual deleted document or null\n\n**Best Practices:**\n- Always test delete filters with `find()` first\n- Use `countDocuments()` to verify expected deletion count\n- Be extremely careful with `deleteMany({})`\n- Consider using soft deletes for important data",
    "difficulty": "Easy",
    "category": "Database",
    "type": "CRUD",
    "tags": [
      "MongoDB Delete",
      "deleteOne",
      "deleteMany",
      "findOneAndDelete",
      "CRUD Operations"
    ]
  },
  {
    "id": 14,
    "question": "What is the MongoDB Aggregation Framework? Explain its key concepts and basic pipeline stages.",
    "solution": "**MongoDB Aggregation Framework:**\n\nThe Aggregation Framework is MongoDB's powerful data processing pipeline that allows you to process data records and return computed results. It's like an ETL (Extract, Transform, Load) tool within the database.\n\n**Key Concepts:**\n- **Pipeline:** Array of stages that documents pass through sequentially\n- **Stage:** Data processing step (e.g., `$match`, `$group`, `$sort`)\n- **Operator:** Functions used within stages (e.g., `$sum`, `$avg`)\n\n**Basic Pipeline Example:**\n\n```javascript\n// Count movies by year and sort by year\ndb.movies.aggregate([\n    // Stage 1: $group - Groups documents by year and counts them\n    {\n        $group: {\n            _id: \"$year\", // Group by the 'year' field\n            count: { $sum: 1 } // Count documents in each group\n        }\n    },\n    // Stage 2: $sort - Sort by year ascending\n    {\n        $sort: { _id: 1 }\n    },\n    // Stage 3: $limit - Limit to first 10 results\n    {\n        $limit: 10\n    }\n]);\n```\n\n**Common Pipeline Stages:**\n- `$match`: Filter documents (like WHERE in SQL)\n- `$group`: Group documents and perform aggregations\n- `$sort`: Sort documents\n- `$project`: Reshape documents, include/exclude fields\n- `$limit`: Limit number of documents\n- `$skip`: Skip documents\n- `$unwind`: Deconstruct array fields\n- `$lookup`: Join with another collection\n- `$addFields`: Add new fields to documents\n\n**Advantages:**\n- Server-side processing (faster than client-side)\n- Pipeline approach (clear, readable)\n- Powerful data transformation capabilities\n- Memory efficient\n- Can utilize indexes for performance",
    "difficulty": "Medium",
    "category": "Database",
    "type": "Aggregation",
    "tags": [
      "MongoDB Aggregation",
      "Pipeline",
      "Data Processing",
      "ETL",
      "Stages"
    ]
  },
  {
    "id": 15,
    "question": "Write a complex aggregation pipeline to find the average IMDB rating per genre for movies after 2000.",
    "solution": "**Complex Aggregation Pipeline - Average IMDB Rating per Genre:**\n\n```javascript\ndb.movies.aggregate([\n    // Stage 1: $match - Filter movies after 2000 with valid ratings\n    {\n        $match: {\n            \"year\": { $gt: 2000 },\n            \"imdb.rating\": { $exists: true, $ne: \"\" }\n        }\n    },\n    // Stage 2: $unwind - Deconstruct genres array\n    // Converts each movie with multiple genres into separate documents\n    {\n        $unwind: \"$genres\"\n    },\n    // Stage 3: $group - Group by genre and calculate statistics\n    {\n        $group: {\n            _id: \"$genres\", // Group by genre name\n            avgRating: { $avg: \"$imdb.rating\" }, // Average rating\n            movieCount: { $sum: 1 }, // Count movies per genre\n            maxRating: { $max: \"$imdb.rating\" }, // Highest rating\n            minRating: { $min: \"$imdb.rating\" } // Lowest rating\n        }\n    },\n    // Stage 4: $match - Filter genres with sufficient movies\n    {\n        $match: {\n            \"movieCount\": { $gte: 10 } // At least 10 movies\n        }\n    },\n    // Stage 5: $sort - Sort by average rating descending\n    {\n        $sort: { \"avgRating\": -1 }\n    },\n    // Stage 6: $limit - Top 10 genres\n    {\n        $limit: 10\n    },\n    // Stage 7: $project - Format output\n    {\n        $project: {\n            genre: \"$_id\",\n            averageRating: { $round: [\"$avgRating\", 2] },\n            movieCount: 1,\n            ratingRange: {\n                $concat: [\n                    { $toString: \"$minRating\" },\n                    \" - \",\n                    { $toString: \"$maxRating\" }\n                ]\n            },\n            _id: 0\n        }\n    }\n]);\n```\n\n**Pipeline Explanation:**\n1. **$match**: Filter for movies after 2000 with valid IMDB ratings\n2. **$unwind**: Convert array of genres into individual documents\n3. **$group**: Aggregate by genre, calculate average, count, min, max\n4. **$match**: Only include genres with at least 10 movies\n5. **$sort**: Order by average rating (highest first)\n6. **$limit**: Take top 10 genres\n7. **$project**: Format output with rounded averages and rating ranges",
    "difficulty": "Hard",
    "category": "Database",
    "type": "Aggregation",
    "tags": [
      "MongoDB Aggregation",
      "Complex Pipeline",
      "unwind",
      "group",
      "Statistical Analysis"
    ]
  },
  {
    "id": 16,
    "question": "Explain MongoDB indexing. What are the different types of indexes and their use cases?",
    "solution": "**MongoDB Indexing:**\n\nIndexes are special data structures that store a portion of collection data in an easy-to-traverse form, dramatically improving query performance.\n\n**Why Use Indexes?**\n- **Performance:** Speeds up read operations\n- **Sorting:** Enables efficient sorting\n- **Uniqueness:** Enforces unique values\n\n**Trade-offs:**\n- **Storage:** Consumes additional space\n- **Write Performance:** Slows down writes (must update indexes)\n\n**Index Types:**\n\n**1. Single Field Index**\n```javascript\n// Create ascending index on year field\ndb.movies.createIndex({ \"year\": 1 });\n// Good for: db.movies.find({ year: 1994 })\n```\n\n**2. Compound Index**\n```javascript\n// Index on multiple fields (ESR: Equality, Sort, Range)\ndb.movies.createIndex({ \n    \"year\": 1,      // Equality queries\n    \"imdb.rating\": -1  // Sort field\n});\n// Good for: db.movies.find({ year: 2010 }).sort({ \"imdb.rating\": -1 })\n```\n\n**3. Multikey Index (Arrays)**\n```javascript\n// Automatically created for array fields\ndb.movies.createIndex({ \"genres\": 1 });\n// Good for: db.movies.find({ genres: \"Action\" })\n```\n\n**4. Text Index**\n```javascript\n// Full-text search capability\ndb.movies.createIndex({ \n    \"title\": \"text\", \n    \"plot\": \"text\" \n});\n// Good for: db.movies.find({ $text: { $search: \"love\" } })\n```\n\n**5. Geospatial Index (2dsphere)**\n```javascript\n// For location-based queries\ndb.theaters.createIndex({ \"location.geo\": \"2dsphere\" });\n// Good for: proximity searches, geo queries\n```\n\n**6. Unique Index**\n```javascript\n// Ensures field uniqueness\ndb.users.createIndex({ \"email\": 1 }, { \"unique\": true });\n```\n\n**7. Partial Index**\n```javascript\n// Index only documents meeting criteria\ndb.movies.createIndex(\n    { \"imdb.rating\": 1 },\n    { \"partialFilterExpression\": { \"imdb.rating\": { $gt: 8.5 } } }\n);\n```\n\n**8. TTL Index**\n```javascript\n// Auto-delete documents after time\ndb.logs.createIndex(\n    { \"createdAt\": 1 },\n    { \"expireAfterSeconds\": 3600 } // 1 hour\n);\n```",
    "difficulty": "Medium",
    "category": "Database",
    "type": "Indexing",
    "tags": [
      "MongoDB Indexes",
      "Performance",
      "Index Types",
      "Optimization",
      "Database Design"
    ]
  },
  {
    "id": 17,
    "question": "How do you manage indexes in MongoDB? Show examples of creating, viewing, and dropping indexes.",
    "solution": "**MongoDB Index Management:**\n\n**Creating Indexes:**\n\n```javascript\n// Single field index\ndb.movies.createIndex({ \"year\": 1 });\n\n// Compound index with custom name\ndb.movies.createIndex(\n    { \"title\": 1, \"year\": -1 },\n    { name: \"title_year_compound\" }\n);\n\n// Text index with weights\ndb.movies.createIndex(\n    { \n        \"title\": \"text\", \n        \"plot\": \"text\" \n    },\n    { \n        weights: { title: 10, plot: 5 },\n        name: \"title_plot_text\"\n    }\n);\n\n// Background index creation (non-blocking)\ndb.movies.createIndex(\n    { \"imdb.rating\": 1 },\n    { background: true }\n);\n\n// Sparse index (only documents with the field)\ndb.movies.createIndex(\n    { \"awards.wins\": 1 },\n    { sparse: true }\n);\n```\n\n**Viewing Indexes:**\n\n```javascript\n// View all indexes on collection\ndb.movies.getIndexes();\n\n// View index statistics\ndb.movies.aggregate([{ $indexStats: {} }]);\n\n// Check index usage\ndb.movies.find({ year: 1994 }).explain(\"executionStats\");\n\n// List all indexes in database\ndb.runCommand(\"listCollections\").cursor.firstBatch.forEach(\n    function(collection) {\n        print(collection.name);\n        db[collection.name].getIndexes().forEach(\n            function(index) {\n                print(\"  \" + tojson(index));\n            }\n        );\n    }\n);\n```\n\n**Dropping Indexes:**\n\n```javascript\n// Drop index by name\ndb.movies.dropIndex(\"year_1\");\n\n// Drop index by key specification\ndb.movies.dropIndex({ \"title\": 1, \"year\": -1 });\n\n// Drop all indexes except _id\ndb.movies.dropIndexes();\n\n// Drop specific indexes\ndb.movies.dropIndexes([\"year_1\", \"title_plot_text\"]);\n```\n\n**Index Monitoring:**\n\n```javascript\n// Monitor slow operations\ndb.setProfilingLevel(2, { slowms: 100 });\n\n// View profiler data\ndb.system.profile.find().sort({ ts: -1 }).limit(5);\n\n// Check index hit ratio\ndb.serverStatus().indexCounters;\n```\n\n**Best Practices:**\n- Create indexes on frequently queried fields\n- Use compound indexes for multi-field queries\n- Monitor index usage with `$indexStats`\n- Drop unused indexes to improve write performance\n- Use background creation for large collections\n- Consider partial indexes for selective data",
    "difficulty": "Medium",
    "category": "Database",
    "type": "Indexing",
    "tags": [
      "Index Management",
      "createIndex",
      "dropIndex",
      "Index Monitoring",
      "Performance Tuning"
    ]
  },
  {
    "id": 18,
    "question": "What are MongoDB replica sets? Explain their purpose and benefits.",
    "solution": "**MongoDB Replica Sets:**\n\nA replica set is a group of MongoDB servers that maintain the same data set, providing redundancy and high availability. It consists of multiple MongoDB instances running on different servers.\n\n**Replica Set Architecture:**\n- **Primary:** Receives all write operations\n- **Secondary:** Replicates data from primary, can serve reads\n- **Arbiter:** Participates in elections but doesn't store data\n\n**Key Benefits:**\n\n**1. High Availability** 🔄\n- Automatic failover when primary fails\n- Secondary automatically elected as new primary\n- Minimal downtime during failures\n\n**2. Data Redundancy** 💾\n- Multiple copies of data across different servers\n- Protection against hardware failures\n- Geographic distribution possible\n\n**3. Read Scaling** 📊\n- Secondary nodes can serve read queries\n- Distribute read load across multiple servers\n- Improved application performance\n\n**4. Backup and Maintenance** 🔧\n- Take backups from secondary without affecting primary\n- Perform maintenance on individual nodes\n- Rolling upgrades possible\n\n**Configuration Example:**\n\n```javascript\n// Initialize replica set\nrs.initiate({\n    _id: \"myReplicaSet\",\n    members: [\n        { _id: 0, host: \"mongo1.example.com:27017\" },\n        { _id: 1, host: \"mongo2.example.com:27017\" },\n        { _id: 2, host: \"mongo3.example.com:27017\" }\n    ]\n});\n\n// Check replica set status\nrs.status();\n\n// Add a new member\nrs.add(\"mongo4.example.com:27017\");\n\n// Remove a member\nrs.remove(\"mongo4.example.com:27017\");\n```\n\n**Read Preferences:**\n- `primary`: Read from primary only (default)\n- `secondary`: Read from secondary only\n- `primaryPreferred`: Read from primary, fallback to secondary\n- `secondaryPreferred`: Read from secondary, fallback to primary\n- `nearest`: Read from nearest member\n\n**Write Concerns:**\n- `w: 1`: Acknowledge after writing to primary\n- `w: \"majority\"`: Acknowledge after majority confirmation\n- `w: 3`: Acknowledge after writing to 3 members\n\n**Use Cases:**\n- Mission-critical applications requiring high availability\n- Applications with high read traffic\n- Geographic data distribution\n- Zero-downtime maintenance requirements",
    "difficulty": "Medium",
    "category": "Database",
    "type": "Architecture",
    "tags": [
      "Replica Sets",
      "High Availability",
      "Failover",
      "Data Redundancy",
      "Read Scaling"
    ]
  },
  {
    "id": 19,
    "question": "What is MongoDB sharding? When and why would you use it?",
    "solution": "**MongoDB Sharding:**\n\nSharding is MongoDB's method for distributing data across multiple machines. It's a horizontal scaling approach that allows MongoDB to handle large data sets and high throughput operations.\n\n**Sharding Architecture:**\n\n**1. Shard** 🗄️\n- Each shard contains a subset of the data\n- Can be a single mongod or a replica set\n- Stores data based on shard key ranges\n\n**2. Config Servers** ⚙️\n- Store metadata and configuration settings\n- Track which data is on which shard\n- Must be deployed as replica set\n\n**3. Query Router (mongos)** 🔀\n- Routes queries to appropriate shards\n- Aggregates results from multiple shards\n- Application connects to mongos, not directly to shards\n\n**When to Use Sharding:**\n\n**Data Size Indicators:**\n- Working set no longer fits in RAM\n- Database size exceeds single server capacity\n- Individual server storage limits reached\n\n**Performance Indicators:**\n- High write throughput requirements\n- Read queries becoming slow\n- CPU or I/O bottlenecks on single server\n\n**Operational Indicators:**\n- Need for geographic data distribution\n- Regulatory requirements for data locality\n- Disaster recovery across regions\n\n**Sharding Benefits:**\n\n```javascript\n// Example: E-commerce with millions of users\n// Shard by user_id for even distribution\nsh.shardCollection(\"ecommerce.orders\", { \"user_id\": 1 });\n\n// Example: Time-series data\n// Shard by timestamp for time-based queries\nsh.shardCollection(\"analytics.events\", { \"timestamp\": 1 });\n\n// Example: Geographic application\n// Shard by location for regional queries\nsh.shardCollection(\"locations.stores\", { \"region\": 1, \"store_id\": 1 });\n```\n\n**Shard Key Selection:**\n\n**Good Shard Keys:**\n- High cardinality (many possible values)\n- Even distribution of data\n- Supports common query patterns\n- Avoid monotonically increasing values\n\n**Example:**\n```javascript\n// ✅ Good: Composite key with high cardinality\n{ \"customer_id\": 1, \"order_date\": 1 }\n\n// ❌ Bad: Monotonically increasing\n{ \"_id\": 1 }  // ObjectId is time-based\n\n// ❌ Bad: Low cardinality\n{ \"status\": 1 }  // Only few possible values\n```\n\n**Considerations:**\n- **Complexity:** Adds operational complexity\n- **Shard Key Immutable:** Cannot change after sharding\n- **Cross-Shard Operations:** Slower than single-shard queries\n- **Minimum 3 Config Servers:** Required for production\n\n**Use Cases:**\n- Large-scale web applications\n- IoT data collection\n- Real-time analytics\n- Multi-tenant applications\n- Global applications with regional data",
    "difficulty": "Hard",
    "category": "Database",
    "type": "Architecture",
    "tags": [
      "Sharding",
      "Horizontal Scaling",
      "Distributed Database",
      "Performance",
      "Architecture"
    ]
  },
  {
    "id": 20,
    "question": "How do you implement transactions in MongoDB? Provide examples of multi-document transactions.",
    "solution": "**MongoDB Transactions:**\n\nMongoDB supports ACID transactions for single documents by default. Multi-document transactions are available for replica sets (MongoDB 4.0+) and sharded clusters (MongoDB 4.2+).\n\n**Single Document Transactions:**\n```javascript\n// Automatically atomic and consistent\ndb.accounts.updateOne(\n    { _id: \"account1\" },\n    {\n        $inc: { balance: -100 },\n        $push: { transactions: { \n            type: \"debit\", \n            amount: 100, \n            date: new Date() \n        }}\n    }\n);\n```\n\n**Multi-Document Transactions:**\n\n**Example 1: Bank Transfer**\n```javascript\nconst session = db.getMongo().startSession();\nsession.startTransaction();\n\ntry {\n    const accountsCollection = session.getDatabase('bank').collection('accounts');\n    \n    // Debit from source account\n    const debitResult = accountsCollection.updateOne(\n        { _id: \"account1\", balance: { $gte: 100 } },\n        { $inc: { balance: -100 } },\n        { session }\n    );\n    \n    if (debitResult.matchedCount === 0) {\n        throw new Error(\"Insufficient funds or account not found\");\n    }\n    \n    // Credit to destination account\n    accountsCollection.updateOne(\n        { _id: \"account2\" },\n        { $inc: { balance: 100 } },\n        { session }\n    );\n    \n    // Record transaction history\n    session.getDatabase('bank').collection('transactions').insertOne({\n        from: \"account1\",\n        to: \"account2\",\n        amount: 100,\n        timestamp: new Date(),\n        status: \"completed\"\n    }, { session });\n    \n    session.commitTransaction();\n    print(\"Transfer completed successfully\");\n    \n} catch (error) {\n    session.abortTransaction();\n    print(\"Transfer failed: \" + error.message);\n} finally {\n    session.endSession();\n}\n```\n\n**Example 2: E-commerce Order Processing**\n```javascript\nconst session = db.getMongo().startSession();\nsession.startTransaction({\n    readConcern: { level: \"majority\" },\n    writeConcern: { w: \"majority\" }\n});\n\ntry {\n    const ordersDb = session.getDatabase('ecommerce');\n    \n    // 1. Create order\n    const orderResult = ordersDb.collection('orders').insertOne({\n        _id: \"order123\",\n        customerId: \"customer456\",\n        items: [\n            { productId: \"prod1\", quantity: 2, price: 50 },\n            { productId: \"prod2\", quantity: 1, price: 30 }\n        ],\n        total: 130,\n        status: \"pending\",\n        createdAt: new Date()\n    }, { session });\n    \n    // 2. Update inventory\n    const inventoryUpdates = [\n        {\n            updateOne: {\n                filter: { _id: \"prod1\", stock: { $gte: 2 } },\n                update: { $inc: { stock: -2 } },\n                session\n            }\n        },\n        {\n            updateOne: {\n                filter: { _id: \"prod2\", stock: { $gte: 1 } },\n                update: { $inc: { stock: -1 } },\n                session\n            }\n        }\n    ];\n    \n    const inventoryResult = ordersDb.collection('inventory').bulkWrite(\n        inventoryUpdates,\n        { session }\n    );\n    \n    if (inventoryResult.modifiedCount !== 2) {\n        throw new Error(\"Insufficient stock for one or more items\");\n    }\n    \n    // 3. Update customer points\n    ordersDb.collection('customers').updateOne(\n        { _id: \"customer456\" },\n        { \n            $inc: { loyaltyPoints: 13 }, // 10% of order total\n            $push: { orderHistory: \"order123\" }\n        },\n        { session }\n    );\n    \n    session.commitTransaction();\n    print(\"Order processed successfully\");\n    \n} catch (error) {\n    session.abortTransaction();\n    print(\"Order processing failed: \" + error.message);\n} finally {\n    session.endSession();\n}\n```\n\n**Transaction Options:**\n```javascript\n// Configure transaction options\nsession.startTransaction({\n    readConcern: { level: \"majority\" },    // Read committed data\n    writeConcern: { w: \"majority\" },       // Write to majority\n    maxTimeMS: 5000                        // 5-second timeout\n});\n```\n\n**Best Practices:**\n- Keep transactions short-lived\n- Handle exceptions properly\n- Use appropriate read/write concerns\n- Avoid long-running operations in transactions\n- Consider retrying on transient failures\n- Design for minimal cross-shard transactions",
    "difficulty": "Hard",
    "category": "Database",
    "type": "Transactions",
    "tags": [
      "MongoDB Transactions",
      "ACID",
      "Multi-document",
      "Session",
      "Atomicity"
    ]
  },
  {
    "id": 21,
    "question": "Write a MongoDB query to find all movies that have 'Tom Hanks' in their cast array AND were released in 1994.",
    "solution": "```javascript\n// Find movies with Tom Hanks from 1994\ndb.movies.find({\n    \"cast\": \"Tom Hanks\", // Matches if \"Tom Hanks\" is anywhere in the cast array\n    \"year\": 1994\n});\n\n// More specific array queries\ndb.movies.find({\n    \"cast\": { $in: [\"Tom Hanks\", \"Morgan Freeman\"] }, // Either actor\n    \"year\": { $gte: 1990, $lte: 1999 } // 1990s movies\n});\n\n// Find movies where Tom Hanks is the first actor listed\ndb.movies.find({ \"cast.0\": \"Tom Hanks\" });\n```\n\n**Explanation:**\nWhen you query on an array field (like `cast`), MongoDB automatically checks if the array contains the specified value. You can use `$in` for multiple values or array notation for specific positions.",
    "difficulty": "Medium",
    "category": "Array Queries",
    "database": "MongoDB",
    "tags": [
      "MongoDB",
      "Array",
      "Find",
      "Multiple Conditions"
    ]
  },
  {
    "id": 22,
    "question": "Write a MongoDB query to find movies whose title contains the word 'Godfather' (case-insensitive) using regex.",
    "solution": "```javascript\n// Case-insensitive regex search\ndb.movies.find({\n    \"title\": { $regex: \"godfather\", $options: \"i\" }\n});\n\n// Multiple regex patterns\ndb.movies.find({\n    $or: [\n        { \"title\": { $regex: \"star wars\", $options: \"i\" } },\n        { \"title\": { $regex: \"star trek\", $options: \"i\" } }\n    ]\n});\n\n// Regex with word boundaries\ndb.movies.find({\n    \"title\": { $regex: \"\\\\bthe\\\\b\", $options: \"i\" } // Find titles with \"the\" as whole word\n});\n```\n\n**Explanation:**\n`$regex` allows pattern matching. `$options: \"i\"` makes it case-insensitive. Use word boundaries (`\\b`) to match exact words.",
    "difficulty": "Medium",
    "category": "Text Search",
    "database": "MongoDB",
    "tags": [
      "MongoDB",
      "Regex",
      "Text Search",
      "Case Insensitive"
    ]
  },
  {
    "id": 23,
    "question": "Create an aggregation pipeline to find the top 5 most common genres in the movies collection.",
    "solution": "```javascript\n// Top 5 most common genres\ndb.movies.aggregate([\n    { $unwind: \"$genres\" }, // Deconstruct the genres array\n    { \n        $group: { \n            _id: \"$genres\", \n            count: { $sum: 1 } \n        } \n    }, // Group by each genre and count\n    { $sort: { count: -1 } }, // Sort by count in descending order\n    { $limit: 5 } // Get only the top 5\n]);\n\n// More complex genre analysis\ndb.movies.aggregate([\n    { $match: { \"year\": { $gte: 2000 } } }, // Only recent movies\n    { $unwind: \"$genres\" },\n    {\n        $group: {\n            _id: \"$genres\",\n            count: { $sum: 1 },\n            avgRating: { $avg: \"$imdb.rating\" },\n            avgYear: { $avg: \"$year\" }\n        }\n    },\n    { $match: { count: { $gte: 10 } } }, // Only genres with 10+ movies\n    { $sort: { avgRating: -1 } }\n]);\n```\n\n**Explanation:**\n1. `$unwind` decomposes the genres array into individual documents\n2. `$group` counts occurrences of each genre\n3. `$sort` orders by count in descending order\n4. `$limit` restricts to top 5 results",
    "difficulty": "Medium",
    "category": "Aggregation",
    "database": "MongoDB",
    "tags": [
      "MongoDB",
      "Aggregation",
      "Unwind",
      "Group",
      "Statistics"
    ]
  },
  {
    "id": 24,
    "question": "Write a query using `$elemMatch` to find movies where there is at least one comment by 'Andrea G.' with text containing 'great'.",
    "solution": "```javascript\n// Using $elemMatch for embedded documents\ndb.movies.find({\n    \"comments\": {\n        $elemMatch: {\n            \"user\": \"Andrea G.\",\n            \"text\": { $regex: \"great\", $options: \"i\" }\n        }\n    }\n});\n\n// More $elemMatch examples\n// Find movies with awards that won an Oscar\ndb.movies.find({\n    \"awards\": {\n        $elemMatch: {\n            \"type\": \"Oscar\",\n            \"result\": \"Won\"\n        }\n    }\n});\n\n// Complex $elemMatch with multiple conditions\ndb.movies.find({\n    \"reviews\": {\n        $elemMatch: {\n            \"rating\": { $gte: 4 },\n            \"helpful_votes\": { $gte: 10 },\n            \"review_date\": { \n                $gte: new Date(\"2020-01-01\") \n            }\n        }\n    }\n});\n```\n\n**Explanation:**\n`$elemMatch` is crucial when you need to match multiple conditions within *a single element* of an array of embedded documents. Without `$elemMatch`, MongoDB might match elements independently.",
    "difficulty": "Hard",
    "category": "Array Queries",
    "database": "MongoDB",
    "tags": [
      "MongoDB",
      "elemMatch",
      "Embedded Documents",
      "Array"
    ]
  },
  {
    "id": 25,
    "question": "Create a 2dsphere index on a location field and write a query to find theaters near a specific point within a given distance range.",
    "solution": "```javascript\n// Create a 2dsphere index on the location.geo field\ndb.theaters.createIndex({ \"location.geo\": \"2dsphere\" });\n\n// Find theaters near a specific location\ndb.theaters.find({\n    \"location.geo\": {\n        $near: {\n            $geometry: {\n                type: \"Point\",\n                coordinates: [-86.509552, 36.164974] // [longitude, latitude]\n            },\n            $minDistance: 10000, // 10km minimum\n            $maxDistance: 50000  // 50km maximum\n        }\n    }\n}).limit(5);\n\n// Alternative syntax with $nearSphere\ndb.theaters.find({\n    \"location.geo\": {\n        $nearSphere: {\n            $geometry: {\n                type: \"Point\",\n                coordinates: [-73.9857, 40.7484]\n            },\n            $maxDistance: 5000 // 5km\n        }\n    }\n});\n```\n\n**Explanation:**\nGeospatial queries require a 2dsphere index. Use `$near` for proximity searches with distance constraints. **Important:** Coordinates are in [longitude, latitude] order.",
    "difficulty": "Hard",
    "category": "Geospatial",
    "database": "MongoDB",
    "tags": [
      "MongoDB",
      "Geospatial",
      "2dsphere",
      "Near",
      "Index"
    ]
  },
  {
    "id": 26,
    "question": "Write a GeoJSON Point format and a query to find documents within a circular area using `$geoWithin` and `$centerSphere`.",
    "solution": "```javascript\n// GeoJSON Point format\n// Important: Coordinates are [longitude, latitude]\nlocation: {\n  type: \"Point\",\n  coordinates: [-73.856077, 40.848447] // [longitude, latitude]\n}\n\n// Find theaters within a circular area\ndb.theaters.find({\n    \"location.geo\": {\n        $geoWithin: {\n            $centerSphere: [\n                [-73.9857, 40.7484], // [longitude, latitude] - Times Square\n                10 / 3963.2 // 10 miles radius (converted to radians)\n            ]\n        }\n    }\n}).limit(10);\n\n// Find theaters within a polygon\ndb.theaters.find({\n    \"location.geo\": {\n        $geoWithin: {\n            $geometry: {\n                type: \"Polygon\",\n                coordinates: [[\n                    [-74.0, 40.7],  // Southwest corner\n                    [-73.9, 40.7],  // Southeast corner\n                    [-73.9, 40.8],  // Northeast corner\n                    [-74.0, 40.8],  // Northwest corner\n                    [-74.0, 40.7]   // Close the polygon\n                ]]\n            }\n        }\n    }\n});\n```\n\n**Explanation:**\nGeoJSON format requires `type` and `coordinates` fields. For circular searches, convert distance to radians (miles/3963.2 or km/6378.1). Polygons must be closed (first point = last point).",
    "difficulty": "Hard",
    "category": "Geospatial",
    "database": "MongoDB",
    "tags": [
      "MongoDB",
      "GeoJSON",
      "geoWithin",
      "centerSphere",
      "Polygon"
    ]
  },
  {
    "id": 27,
    "question": "Create an aggregation pipeline using `$geoNear` to group theaters by distance ranges from a specific point.",
    "solution": "```javascript\n// Aggregate theaters by distance from a point\ndb.theaters.aggregate([\n    {\n        $geoNear: {\n            near: {\n                type: \"Point\",\n                coordinates: [-73.9857, 40.7484] // Times Square\n            },\n            distanceField: \"distance\",\n            maxDistance: 50000, // 50km\n            spherical: true\n        }\n    },\n    {\n        $group: {\n            _id: {\n                $switch: {\n                    branches: [\n                        { case: { $lt: [\"$distance\", 10000] }, then: \"< 10km\" },\n                        { case: { $lt: [\"$distance\", 25000] }, then: \"10-25km\" },\n                        { case: { $lt: [\"$distance\", 50000] }, then: \"25-50km\" }\n                    ],\n                    default: \"> 50km\"\n                }\n            },\n            count: { $sum: 1 },\n            avgDistance: { $avg: \"$distance\" }\n        }\n    },\n    { $sort: { _id: 1 } }\n]);\n```\n\n**Explanation:**\n`$geoNear` must be the first stage in an aggregation pipeline. It calculates distances and sorts by proximity. Use `$switch` for conditional grouping by distance ranges.",
    "difficulty": "Hard",
    "category": "Geospatial Aggregation",
    "database": "MongoDB",
    "tags": [
      "MongoDB",
      "geoNear",
      "Aggregation",
      "Distance",
      "Grouping"
    ]
  },
  {
    "id": 28,
    "question": "What is Mongoose and why would you use it over the native MongoDB driver? Provide key benefits.",
    "solution": "**Mongoose** is an **Object Data Modeling (ODM)** library for Node.js and MongoDB that provides a higher-level, schema-based abstraction over the native MongoDB driver.\n\n**Key Benefits:**\n\n| Feature | Benefit |\n|---------|--------|\n| **Schema and Data Modeling** | Enforces structure for documents, maintains data consistency |\n| **Data Validation** | Built-in and custom validators ensure data integrity |\n| **Middleware (Hooks)** | Execute logic before/after operations (e.g., password hashing) |\n| **Population** | Easily reference and query documents in other collections |\n| **Query Building** | Chainable and readable API for complex queries |\n| **Type Casting** | Automatic conversion between JavaScript and MongoDB types |\n| **Connection Management** | Simplified connection pooling and management |\n\n**Example Schema:**\n```javascript\nconst mongoose = require('mongoose');\nconst { Schema } = mongoose;\n\nconst userSchema = new Schema({\n    name: { type: String, required: true, minlength: 2 },\n    email: { type: String, required: true, unique: true },\n    age: { type: Number, min: 0, max: 120 },\n    createdAt: { type: Date, default: Date.now }\n}, { timestamps: true });\n\nconst User = mongoose.model('User', userSchema);\n```\n\n**Why choose Mongoose:**\n- Enforces data structure and validation\n- Reduces boilerplate code\n- Better error handling\n- Rich ecosystem and community support",
    "difficulty": "Medium",
    "category": "Mongoose Basics",
    "database": "MongoDB",
    "tags": [
      "Mongoose",
      "ODM",
      "Schema",
      "Validation",
      "Node.js"
    ]
  },
  {
    "id": 29,
    "question": "Write a MongoDB query to count movies by actor using aggregation and find the top 10 actors with the most movies.",
    "solution": "```javascript\n// Count movies by actor and find top 10\ndb.movies.aggregate([\n    { $unwind: \"$cast\" }, // Deconstruct the cast array\n    { \n        $group: { \n            _id: \"$cast\", \n            movieCount: { $sum: 1 } \n        } \n    },\n    { $sort: { movieCount: -1 } }, // Sort by movie count descending\n    { $limit: 10 }, // Top 10 actors\n    {\n        $project: {\n            actor: \"$_id\",\n            movieCount: 1,\n            _id: 0\n        }\n    }\n]);\n\n// More detailed actor analysis\ndb.movies.aggregate([\n    { $unwind: \"$cast\" },\n    {\n        $group: {\n            _id: \"$cast\",\n            movieCount: { $sum: 1 },\n            avgRating: { $avg: \"$imdb.rating\" },\n            firstMovie: { $min: \"$year\" },\n            latestMovie: { $max: \"$year\" },\n            genres: { $addToSet: \"$genres\" }\n        }\n    },\n    { $match: { movieCount: { $gte: 5 } } }, // At least 5 movies\n    { $sort: { avgRating: -1 } },\n    { $limit: 20 }\n]);\n```\n\n**Explanation:**\n1. `$unwind` creates a document for each cast member\n2. `$group` counts movies per actor\n3. `$sort` orders by movie count\n4. `$project` reshapes the output for better readability",
    "difficulty": "Medium",
    "category": "Aggregation",
    "database": "MongoDB",
    "tags": [
      "MongoDB",
      "Aggregation",
      "Unwind",
      "Group",
      "Statistics",
      "Top N"
    ]
  },
  {
    "id": 30,
    "question": "Write a query using `$geoIntersects` to find theaters that intersect with a specific polygon area.",
    "solution": "```javascript\n// Find theaters that intersect with a polygon area\ndb.theaters.find({\n    \"location.geo\": {\n        $geoIntersects: {\n            $geometry: {\n                type: \"Polygon\",\n                coordinates: [[\n                    [-74.0, 40.7],  // Southwest corner\n                    [-73.9, 40.7],  // Southeast corner\n                    [-73.9, 40.8],  // Northeast corner\n                    [-74.0, 40.8],  // Northwest corner\n                    [-74.0, 40.7]   // Close the polygon (first point = last point)\n                ]]\n            }\n        }\n    }\n}).limit(5);\n\n// Find theaters intersecting with a LineString (road)\ndb.theaters.find({\n    \"location.geo\": {\n        $geoIntersects: {\n            $geometry: {\n                type: \"LineString\",\n                coordinates: [\n                    [-73.9857, 40.7484],\n                    [-73.9757, 40.7584],\n                    [-73.9657, 40.7684]\n                ]\n            }\n        }\n    }\n});\n\n// Find theaters intersecting with multiple geometries\ndb.theaters.find({\n    $or: [\n        {\n            \"location.geo\": {\n                $geoIntersects: {\n                    $geometry: {\n                        type: \"Polygon\",\n                        coordinates: [/* polygon 1 */]\n                    }\n                }\n            }\n        },\n        {\n            \"location.geo\": {\n                $geoIntersects: {\n                    $geometry: {\n                        type: \"Polygon\",\n                        coordinates: [/* polygon 2 */]\n                    }\n                }\n            }\n        }\n    ]\n});\n```\n\n**Explanation:**\n`$geoIntersects` finds documents where the geometry intersects with the specified shape. Works with Polygon, LineString, Point, and other GeoJSON types. Polygon coordinates must form a closed loop.",
    "difficulty": "Hard",
    "category": "Geospatial",
    "database": "MongoDB",
    "tags": [
      "MongoDB",
      "geoIntersects",
      "Polygon",
      "LineString",
      "GeoJSON"
    ]
  },
  {
    "id": 31,
    "question": "Create a text search query with a text index and explain the difference between `$regex` and `$text` search.",
    "solution": "```javascript\n// Create text index first\ndb.movies.createIndex({ \"title\": \"text\", \"plot\": \"text\" });\n\n// Text search (requires text index)\ndb.movies.find({ $text: { $search: \"godfather\" } });\n\n// Advanced text search with scoring\ndb.movies.find(\n    { $text: { $search: \"love story romance\" } },\n    { score: { $meta: \"textScore\" } }\n).sort({ score: { $meta: \"textScore\" } });\n\n// Text search with phrase and exclusion\ndb.movies.find({ \n    $text: { \n        $search: '\"star wars\" -prequel' \n    } \n});\n\n// Regex search (no index required)\ndb.movies.find({\n    \"title\": { $regex: \"godfather\", $options: \"i\" }\n});\n\n// Combined regex patterns\ndb.movies.find({\n    $or: [\n        { \"title\": { $regex: \"star wars\", $options: \"i\" } },\n        { \"title\": { $regex: \"star trek\", $options: \"i\" } }\n    ]\n});\n```\n\n**Comparison: `$regex` vs `$text`**\n\n| Feature | `$regex` | `$text` |\n|---------|----------|--------|\n| **Index Requirement** | Optional (2d, sparse) | Required (text index) |\n| **Performance** | Slower on large datasets | Faster with proper indexing |\n| **Language Support** | Basic pattern matching | Language-aware (stemming, stop words) |\n| **Scoring** | No relevance scoring | Built-in relevance scoring |\n| **Phrase Search** | Manual pattern construction | Native phrase support with quotes |\n| **Case Sensitivity** | Manual with options | Automatically case-insensitive |\n| **Fuzzy Matching** | No | Limited fuzzy capabilities |\n\n**When to use:**\n- **`$regex`**: Pattern matching, partial string searches, simple text filtering\n- **`$text`**: Full-text search, relevance ranking, multi-language content",
    "difficulty": "Hard",
    "category": "Text Search",
    "database": "MongoDB",
    "tags": [
      "MongoDB",
      "Text Search",
      "Regex",
      "Text Index",
      "Scoring"
    ]
  },
  {
    "id": 32,
    "question": "Explain the coordinate order in GeoJSON and write queries for different geospatial operators with proper coordinate formatting.",
    "solution": "**GeoJSON Coordinate Order:**\nIn GeoJSON format, coordinates are always in **[longitude, latitude]** order:\n- **Longitude**: East-West position (-180 to 180)\n- **Latitude**: North-South position (-90 to 90)\n\n```javascript\n// Correct GeoJSON Point format\nlocation: {\n    type: \"Point\",\n    coordinates: [-73.856077, 40.848447] // [longitude, latitude]\n}\n\n// Common coordinate examples\nconst coordinates = {\n    \"Times Square\": [-73.9857, 40.7484],\n    \"Central Park\": [-73.9654, 40.7829],\n    \"Brooklyn Bridge\": [-73.9969, 40.7061],\n    \"Statue of Liberty\": [-74.0445, 40.6892]\n};\n\n// $near - Find closest points (sorted by distance)\ndb.theaters.find({\n    \"location.geo\": {\n        $near: {\n            $geometry: {\n                type: \"Point\",\n                coordinates: [-73.9857, 40.7484] // Times Square [lng, lat]\n            },\n            $maxDistance: 1000 // 1km radius\n        }\n    }\n});\n\n// $geoWithin - Find points within area (unsorted)\ndb.theaters.find({\n    \"location.geo\": {\n        $geoWithin: {\n            $centerSphere: [\n                [-73.9857, 40.7484], // Center point [lng, lat]\n                5 / 3963.2 // 5 miles in radians\n            ]\n        }\n    }\n});\n\n// $geoIntersects - Find geometries that intersect\ndb.theaters.find({\n    \"location.geo\": {\n        $geoIntersects: {\n            $geometry: {\n                type: \"Polygon\",\n                coordinates: [[\n                    [-74.0, 40.7],  // [lng, lat] - SW corner\n                    [-73.9, 40.7],  // [lng, lat] - SE corner  \n                    [-73.9, 40.8],  // [lng, lat] - NE corner\n                    [-74.0, 40.8],  // [lng, lat] - NW corner\n                    [-74.0, 40.7]   // [lng, lat] - Close polygon\n                ]]\n            }\n        }\n    }\n});\n```\n\n**Memory Tips:**\n- Think \"**X, Y**\" where X=longitude (horizontal), Y=latitude (vertical)\n- Longitude comes first (like reading left to right)\n- NYC example: [-73.xx, 40.xx] - negative longitude (west), positive latitude (north)",
    "difficulty": "Medium",
    "category": "Geospatial",
    "database": "MongoDB",
    "tags": [
      "MongoDB",
      "GeoJSON",
      "Coordinates",
      "Longitude",
      "Latitude"
    ]
  },
  {
    "id": 33,
    "question": "Write an aggregation pipeline that finds theaters and their nearby restaurants using `$lookup` with geospatial queries.",
    "solution": "```javascript\n// Find theaters and nearby restaurants (hypothetical collections)\ndb.theaters.aggregate([\n    {\n        $match: { \"location.state\": \"NY\" } // Filter theaters in NY\n    },\n    {\n        $lookup: {\n            from: \"restaurants\",\n            let: { theaterLocation: \"$location.geo\" },\n            pipeline: [\n                {\n                    $geoNear: {\n                        near: \"$$theaterLocation\", // Use theater's location\n                        distanceField: \"distanceFromTheater\",\n                        maxDistance: 1000, // 1km from theater\n                        spherical: true\n                    }\n                },\n                { \n                    $match: { \n                        \"rating\": { $gte: 4.0 } // Only highly rated restaurants\n                    } \n                },\n                { $limit: 3 } // Top 3 nearest restaurants\n            ],\n            as: \"nearbyRestaurants\"\n        }\n    },\n    {\n        $match: {\n            \"nearbyRestaurants.0\": { $exists: true } // Only theaters with nearby restaurants\n        }\n    },\n    {\n        $project: {\n            theaterName: \"$name\",\n            address: \"$location.address\",\n            restaurantCount: { $size: \"$nearbyRestaurants\" },\n            nearbyRestaurants: {\n                $map: {\n                    input: \"$nearbyRestaurants\",\n                    as: \"restaurant\",\n                    in: {\n                        name: \"$$restaurant.name\",\n                        cuisine: \"$$restaurant.cuisine\",\n                        rating: \"$$restaurant.rating\",\n                        distance: {\n                            $round: [\"$$restaurant.distanceFromTheater\", 0]\n                        }\n                    }\n                }\n            }\n        }\n    },\n    {\n        $sort: { restaurantCount: -1 } // Theaters with most nearby restaurants first\n    },\n    { $limit: 10 }\n]);\n\n// Alternative: Find restaurants within walking distance of multiple theaters\ndb.restaurants.aggregate([\n    {\n        $lookup: {\n            from: \"theaters\",\n            let: { restaurantLocation: \"$location.geo\" },\n            pipeline: [\n                {\n                    $geoNear: {\n                        near: \"$$restaurantLocation\",\n                        distanceField: \"distanceFromRestaurant\",\n                        maxDistance: 500 // 500m walking distance\n                    }\n                }\n            ],\n            as: \"nearbyTheaters\"\n        }\n    },\n    {\n        $addFields: {\n            theaterCount: { $size: \"$nearbyTheaters\" },\n            avgDistanceToTheaters: {\n                $avg: \"$nearbyTheaters.distanceFromRestaurant\"\n            }\n        }\n    },\n    {\n        $match: { theaterCount: { $gte: 2 } } // Restaurants near multiple theaters\n    },\n    { $sort: { theaterCount: -1, avgDistanceToTheaters: 1 } }\n]);\n```\n\n**Explanation:**\n- `$lookup` with `$geoNear` enables spatial joins between collections\n- Use `let` to pass variables from parent pipeline to sub-pipeline\n- `$geoNear` must be the first stage in the sub-pipeline\n- Combine geospatial queries with other filters for complex business logic",
    "difficulty": "Expert",
    "category": "Geospatial Aggregation",
    "database": "MongoDB",
    "tags": [
      "MongoDB",
      "Lookup",
      "geoNear",
      "Aggregation",
      "Spatial Join"
    ]
  },
  {
    "id": 34,
    "question": "What are the best practices for geospatial queries in MongoDB? List at least 5 key recommendations.",
    "solution": "**MongoDB Geospatial Query Best Practices:**\n\n1. **Always Create 2dsphere Index**\n```javascript\n// Create index before performing geospatial queries\ndb.collection.createIndex({ \"location\": \"2dsphere\" });\n\n// Compound geospatial index for filtered queries\ndb.theaters.createIndex({ \n    \"location.geo\": \"2dsphere\",\n    \"name\": 1,\n    \"category\": 1\n});\n```\n\n2. **Use Appropriate Distance Units**\n```javascript\n// Specify distances in meters (default for 2dsphere)\ndb.theaters.find({\n    \"location.geo\": {\n        $near: {\n            $geometry: { type: \"Point\", coordinates: [-73.9857, 40.7484] },\n            $maxDistance: 5000 // 5 kilometers in meters\n        }\n    }\n});\n```\n\n3. **Limit Result Sets**\n```javascript\n// Always use .limit() to avoid performance issues\ndb.theaters.find({\n    \"location.geo\": {\n        $geoWithin: {\n            $centerSphere: [[-73.9857, 40.7484], 10/3963.2]\n        }\n    }\n}).limit(50); // Reasonable limit\n```\n\n4. **Store Coordinates in [longitude, latitude] Order**\n```javascript\n// Correct GeoJSON format\n{\n    location: {\n        type: \"Point\",\n        coordinates: [-73.9857, 40.7484] // [lng, lat] - GeoJSON standard\n    }\n}\n```\n\n5. **Use Aggregation for Complex Analysis**\n```javascript\n// Leverage aggregation pipelines for advanced geospatial analysis\ndb.theaters.aggregate([\n    {\n        $geoNear: {\n            near: { type: \"Point\", coordinates: [-73.9857, 40.7484] },\n            distanceField: \"distance\",\n            maxDistance: 10000\n        }\n    },\n    {\n        $group: {\n            _id: { $trunc: { $divide: [\"$distance\", 1000] } }, // Group by km\n            count: { $sum: 1 }\n        }\n    }\n]);\n```\n\n**Additional Best Practices:**\n\n- **Validate GeoJSON Data**: Ensure coordinates are within valid ranges\n- **Consider Earth's Curvature**: Use spherical calculations for accuracy\n- **Optimize Query Selectivity**: Combine geospatial with other indexed fields\n- **Monitor Query Performance**: Use `.explain()` to analyze execution plans\n- **Choose Right Geospatial Operator**: `$near` for sorted distance, `$geoWithin` for area containment",
    "difficulty": "Medium",
    "category": "Best Practices",
    "database": "MongoDB",
    "tags": [
      "MongoDB",
      "Geospatial",
      "Best Practices",
      "Performance",
      "Optimization"
    ]
  },
  {
    "id": 35,
    "question": "Write queries demonstrating the difference between `$near` and `$geoWithin` for geospatial searches.",
    "solution": "```javascript\n// $near - Returns documents sorted by distance (closest first)\n// Requires 2dsphere index\ndb.theaters.find({\n    \"location.geo\": {\n        $near: {\n            $geometry: {\n                type: \"Point\",\n                coordinates: [-73.9857, 40.7484] // Times Square\n            },\n            $minDistance: 500,   // Minimum 500 meters\n            $maxDistance: 5000   // Maximum 5 kilometers\n        }\n    }\n}).limit(10); // Results are sorted by distance automatically\n\n// $geoWithin - Returns documents within area (unsorted)\n// Better performance for area-based queries\ndb.theaters.find({\n    \"location.geo\": {\n        $geoWithin: {\n            $centerSphere: [\n                [-73.9857, 40.7484], // Center point\n                5 / 3963.2 // 5 miles radius in radians\n            ]\n        }\n    }\n}); // Results are NOT sorted by distance\n\n// $geoWithin with polygon\ndb.theaters.find({\n    \"location.geo\": {\n        $geoWithin: {\n            $geometry: {\n                type: \"Polygon\",\n                coordinates: [[\n                    [-74.0, 40.7],  // Define area boundaries\n                    [-73.9, 40.7],\n                    [-73.9, 40.8],\n                    [-74.0, 40.8],\n                    [-74.0, 40.7]\n                ]]\n            }\n        }\n    }\n});\n\n// Performance comparison with aggregation\ndb.theaters.aggregate([\n    {\n        $facet: {\n            \"nearResults\": [\n                {\n                    $match: {\n                        \"location.geo\": {\n                            $near: {\n                                $geometry: { type: \"Point\", coordinates: [-73.9857, 40.7484] },\n                                $maxDistance: 5000\n                            }\n                        }\n                    }\n                },\n                { $limit: 10 }\n            ],\n            \"withinResults\": [\n                {\n                    $match: {\n                        \"location.geo\": {\n                            $geoWithin: {\n                                $centerSphere: [[-73.9857, 40.7484], 5000/6378100]\n                            }\n                        }\n                    }\n                },\n                { $limit: 10 }\n            ]\n        }\n    }\n]);\n```\n\n**Key Differences:**\n\n| Feature | `$near` | `$geoWithin` |\n|---------|---------|-------------|\n| **Sorting** | Automatically sorted by distance | No automatic sorting |\n| **Performance** | Slower (due to sorting) | Faster for area queries |\n| **Use Case** | \"Find closest N places\" | \"Find all places in area\" |\n| **Distance Field** | Can add distance with `$geoNear` | Distance not calculated |\n| **Index Requirement** | Requires 2dsphere index | Works with or without index |\n| **Limit Behavior** | Gets closest N documents | Gets first N found documents |\n\n**When to use:**\n- **`$near`**: Finding nearest restaurants, closest ATMs, proximity-based recommendations\n- **`$geoWithin`**: Delivery zones, administrative boundaries, area-based analytics",
    "difficulty": "Medium",
    "category": "Geospatial",
    "database": "MongoDB",
    "tags": [
      "MongoDB",
      "Near",
      "geoWithin",
      "Performance",
      "Comparison"
    ]
  },
  {
    "id": 36,
    "question": "What is Mongoose and list the key benefits of using Mongoose over the native MongoDB driver?",
    "solution": "**Mongoose** is an **Object Data Modeling (ODM)** library for Node.js and MongoDB that provides a higher-level, schema-based abstraction over the native MongoDB driver.\n\n**Key Benefits:**\n\n| Feature | Description |\n|---------|------------|\n| **Schema and Data Modeling** | Enforces a structure for your documents, which helps maintain data consistency |\n| **Data Validation** | Built-in and custom validators to ensure data integrity before it's saved |\n| **Middleware (Hooks)** | Allows you to execute logic before or after database operations (e.g., hashing passwords before saving a user) |\n| **Population** | Easily reference and query documents in other collections, simplifying complex queries that would otherwise require manual lookups |\n| **Query Building** | Provides a chainable and more readable API for building complex queries |\n\n```javascript\n// Example of Mongoose benefits\nconst mongoose = require('mongoose');\n\n// Schema with validation\nconst userSchema = new mongoose.Schema({\n    name: { type: String, required: true },\n    email: { type: String, required: true, unique: true },\n    age: { type: Number, min: 18, max: 120 }\n});\n\n// Model creation\nconst User = mongoose.model('User', userSchema);\n\n// Chainable queries\nconst users = await User.find({ age: { $gt: 25 } })\n    .select('name email')\n    .sort({ name: 1 })\n    .limit(10);\n```",
    "difficulty": "Medium",
    "category": "Mongoose Basics",
    "database": "MongoDB",
    "tags": [
      "Mongoose",
      "ODM",
      "Schema",
      "Benefits",
      "Node.js"
    ]
  },
  {
    "id": 37,
    "question": "Create a comprehensive Mongoose schema with various data types, validation rules, and explain the key components.",
    "solution": "```javascript\nconst mongoose = require('mongoose');\nconst { Schema } = mongoose;\n\nconst userSchema = new Schema({\n  // Simple field with type\n  name: String,\n  \n  // Field with validation and default value\n  email: {\n    type: String,\n    required: [true, 'Email is required.'], // [value, message]\n    unique: true, // Creates a unique index\n    lowercase: true,\n    trim: true,\n    match: [/\\S+@\\S+\\.\\S+/, 'is invalid'] // Regex validation\n  },\n\n  // Field with min/max validation\n  age: {\n    type: Number,\n    min: 18,\n    max: 120\n  },\n\n  // Enum for roles\n  role: {\n    type: String,\n    enum: ['user', 'admin', 'editor'],\n    default: 'user'\n  },\n\n  // Reference to another model using ObjectId\n  posts: [{\n    type: Schema.Types.ObjectId,\n    ref: 'Post' // 'Post' is the model name we will create later\n  }]\n}, {\n  // Schema options\n  timestamps: true // Adds createdAt and updatedAt fields\n});\n\n// Compile schema into model\nconst User = mongoose.model('User', userSchema);\n```\n\n**Key Schema Components:**\n\n| Component | Purpose |\n|-----------|--------|\n| **Data Types** | `String`, `Number`, `Date`, `Buffer`, `Boolean`, `Mixed`, `ObjectId`, `Array`, `Decimal128`, `Map` |\n| **Validation** | `required`, `min`, `max`, `minlength`, `maxlength`, `enum`, `match` (regex) |\n| **Options** | `timestamps: true` automatically adds `createdAt` and `updatedAt` fields |\n| **References** | `Schema.Types.ObjectId` with `ref` for relationships |\n| **Indexes** | `unique: true` creates automatic indexes |\n\n**Schema Features:**\n- **Automatic transformation**: `lowercase: true`, `trim: true`\n- **Custom validation messages**: `[value, message]` format\n- **Default values**: Automatic field population\n- **Nested objects**: Support for complex data structures",
    "difficulty": "Medium",
    "category": "Mongoose Schema",
    "database": "MongoDB",
    "tags": [
      "Mongoose",
      "Schema",
      "Validation",
      "Data Types",
      "References"
    ]
  },
  {
    "id": 38,
    "question": "Explain the difference between Schema, Model, and Document in Mongoose with code examples.",
    "solution": "**Mongoose Core Concepts:** \n\n | Concept | Definition | Purpose | \n |---------|------------|--------| \n | **Schema** | Blueprint for documents | Defines structure, data types, validation rules | \n | **Model** | Constructor compiled from Schema | Represents a collection, provides CRUD interface | \n | **Document** | Instance of a Model | Individual record with methods like `save()`, `remove()` |\n\n```javascript\nconst mongoose = require('mongoose');\nconst { Schema } = mongoose;\n\n// 1. SCHEMA - Blueprint for documents\nconst userSchema = new Schema({\n  name: { type: String, required: true },\n  email: { type: String, required: true, unique: true },\n  age: { type: Number, min: 18 }\n}, {\n  timestamps: true\n});\n\n// 2. MODEL - Constructor compiled from Schema\n// Mongoose will create a collection named 'users' (plural, lowercase)\nconst User = mongoose.model('User', userSchema);\n\n// 3. DOCUMENT - Instance of a Model\nconst user = new User({\n  name: 'John Doe',\n  email: 'john.doe@example.com',\n  age: 30\n});\n\n// Document methods and properties\nconsole.log(user.name); // 'John Doe'\nconsole.log(user.isNew); // true (not saved to DB yet)\n\n// Save the document\nconst savedUser = await user.save();\nconsole.log(savedUser._id); // ObjectId generated by MongoDB\n\n// Model static methods\nconst allUsers = await User.find(); // Returns array of documents\nconst oneUser = await User.findById(savedUser._id); // Returns single document\n```\n\n**Key Relationships:**\n- **Schema**: defines the structure\n- **Model**: provides database operations\n- **Document**: represents individual records\n- **Collection**: MongoDB collection (auto-created from model name)",
    "difficulty": "Medium",
    "category": "Mongoose Concepts",
    "database": "MongoDB",
    "tags": [
      "Mongoose",
      "Schema",
      "Model",
      "Document",
      "Concepts"
    ]
  },
  {
    "id": 39,
    "question": "Compare the three different methods to create documents in Mongoose: `new Model() + save()`, `Model.create()`, and `Model.insertMany()`. When should you use each?",
    "solution": "**Mongoose Document Creation Methods:**\n\n| Method | Middleware | Performance | Use Case |\n|--------|------------|-------------|----------|\n| **`new Model() + save()`** | Triggers `pre('save')` | Slower | Single documents, need middleware |\n| **`Model.create()`** | Triggers `save` middleware | Medium | Single/multiple docs, need validation |\n| **`Model.insertMany()`** | Triggers `insertMany` middleware | Fastest | Bulk operations, performance critical |\n\n```javascript\n// Method 1: new Model() + document.save()\n// Best for: Single documents when you need pre-save middleware\nconst newUser = new User({ \n    name: 'Jane Smith', \n    email: 'jane.smith@example.com' \n});\n\ntry {\n    const savedUser = await newUser.save();\n    console.log('User saved:', savedUser);\n} catch (error) {\n    console.error('Error saving user:', error);\n}\n\n// Method 2: Model.create()\n// Best for: Convenient single or small batch creation\ntry {\n    const user = await User.create({\n        name: 'John Doe',\n        email: 'john.doe@example.com',\n        age: 30\n    });\n    console.log('User created:', user);\n} catch (error) {\n    console.error('Error creating user:', error);\n}\n\n// Method 3: Model.insertMany()\n// Best for: Bulk operations, high performance\nconst usersToInsert = [\n    { name: 'Alice', email: 'alice@example.com', age: 28 },\n    { name: 'Bob', email: 'bob@example.com', age: 35 }\n];\n\ntry {\n    const createdUsers = await User.insertMany(usersToInsert, { \n        ordered: false // Continue even if some docs fail\n    });\n    console.log(`${createdUsers.length} users were successfully inserted.`);\n} catch (error) {\n    console.error('Error during insertMany:', error);\n}\n```\n\n**Key Differences:**\n- **`insertMany()`** does NOT trigger `save` middleware, only `insertMany` middleware\n- **`create()`** calls `.save()` on each document internally\n- **`insertMany()`** sends all documents in a single command to server\n- **Validation** runs on all methods but `insertMany()` is most efficient\n\n**When to Use:**\n- **`new + save()`**: Need document manipulation before saving, middleware required\n- **`create()`**: Simple creation with validation, small batches\n- **`insertMany()`**: Large datasets, performance-critical bulk operations",
    "difficulty": "Hard",
    "category": "Mongoose CRUD",
    "database": "MongoDB",
    "tags": [
      "Mongoose",
      "Create",
      "Performance",
      "Middleware",
      "Bulk Operations"
    ]
  },
  {
    "id": 40,
    "question": "Write Mongoose queries to demonstrate different read operations with chaining, projections, and sorting.",
    "solution": "```javascript\n// Mongoose read methods return a Query object that is 'thenable'\n// and can be chained with other methods\n\n// 1. Model.find() - Find all documents matching conditions\nconst users = await User.find({ age: { $gt: 25 } })\n    .select('name email') // Projection - only include specific fields\n    .sort({ name: 1 })    // Sort by name ascending\n    .limit(10)            // Limit to 10 results\n    .skip(5)              // Skip first 5 results\n    .lean();              // Return plain JavaScript objects (faster)\n\n// 2. Model.findOne() - Find the first document that matches\nconst user = await User.findOne({ email: 'john.doe@example.com' })\n    .select('name age role')\n    .populate('posts', 'title createdAt'); // Populate referenced documents\n\n// 3. Model.findById() - Convenient shorthand for findOne({ _id: id })\nconst userById = await User.findById('65f3f4c6e8e81d7f6c3d9a54')\n    .select('-password') // Exclude password field\n    .populate({\n        path: 'posts',\n        select: 'title content',\n        options: { sort: { createdAt: -1 }, limit: 5 }\n    });\n\n// 4. Advanced query with multiple conditions\nconst advancedQuery = await User.find({\n    $and: [\n        { age: { $gte: 18, $lte: 65 } },\n        { role: { $in: ['user', 'editor'] } },\n        { email: { $regex: '@company\\.com$', $options: 'i' } }\n    ]\n})\n.select({\n    name: 1,\n    email: 1,\n    age: 1,\n    role: 1,\n    _id: 0  // Exclude _id field\n})\n.sort({ age: -1, name: 1 }) // Sort by age desc, then name asc\n.limit(20)\n.exec(); // Explicitly execute the query\n\n// 5. Query with aggregation-like features\nconst queryWithCount = await User.find({ role: 'user' })\n    .countDocuments(); // Count matching documents\n\n// 6. Using query conditions object\nconst conditions = {\n    age: { $gte: 21 },\n    role: 'user',\n    'profile.isActive': true\n};\n\nconst activeUsers = await User.find(conditions)\n    .select('name email profile.lastLogin')\n    .sort({ 'profile.lastLogin': -1 })\n    .limit(50);\n```\n\n**Query Method Chaining:**\n\n| Method | Purpose | Example |\n|--------|---------|--------|\n| **`.select()`** | Field projection | `.select('name email')` or `.select('-password')` |\n| **`.sort()`** | Sort results | `.sort({ name: 1, age: -1 })` |\n| **`.limit()`** | Limit results | `.limit(10)` |\n| **`.skip()`** | Skip results | `.skip(20)` |\n| **`.populate()`** | Join collections | `.populate('posts', 'title')` |\n| **`.lean()`** | Return plain objects | `.lean()` (faster, no Mongoose methods) |\n| **`.exec()`** | Execute query | `.exec()` (returns promise) |\n\n**Performance Tips:**\n- Use `.lean()` when you don't need Mongoose document methods\n- Use projection to limit returned fields\n- Combine sorting and limiting for pagination\n- Use indexes on frequently queried fields",
    "difficulty": "Medium",
    "category": "Mongoose Queries",
    "database": "MongoDB",
    "tags": [
      "Mongoose",
      "Find",
      "Chaining",
      "Projection",
      "Sorting"
    ]
  },
  {
    "id": 41,
    "question": "Demonstrate Mongoose update operations and explain the difference between `updateOne()`, `updateMany()`, and `findByIdAndUpdate()` with the `new` option.",
    "solution": "```javascript\n// Mongoose Update Operations\n\n// 1. Model.updateOne() - Updates first matching document\n// Does NOT return the updated document\nconst updateResult = await User.updateOne(\n    { email: 'john.doe@example.com' }, // Filter\n    { \n        $set: { \n            age: 31,\n            'profile.lastLogin': new Date() \n        },\n        $inc: { 'profile.loginCount': 1 }\n    }\n);\nconsole.log(`${updateResult.modifiedCount} document updated.`);\n\n// 2. Model.updateMany() - Updates all matching documents\n// Good for bulk updates\nconst bulkUpdateResult = await User.updateMany(\n    { role: 'user', age: { $gt: 30 } }, // Filter multiple docs\n    { $set: { role: 'veteran_user' } }\n);\nconsole.log(`${bulkUpdateResult.modifiedCount} users updated.`);\n\n// 3. Model.findByIdAndUpdate() - Find by ID, update, and return document\n// IMPORTANT: Use { new: true } to return updated document\nconst updatedUser = await User.findByIdAndUpdate(\n    '65f3f4c6e8e81d7f6c3d9a54',\n    { \n        $inc: { age: 1 },\n        $set: { 'profile.lastActivity': new Date() }\n    },\n    { \n        new: true,           // Return updated document (NOT original)\n        runValidators: true, // Run schema validators\n        upsert: false        // Don't create if not found\n    }\n);\nconsole.log('Updated user:', updatedUser);\n\n// 4. Model.findOneAndUpdate() - More flexible version\nconst userUpdated = await User.findOneAndUpdate(\n    { email: 'jane.smith@example.com' },\n    { \n        $push: { \n            'profile.tags': 'premium',\n            'profile.notifications': {\n                message: 'Welcome to premium!',\n                date: new Date()\n            }\n        }\n    },\n    {\n        new: true,\n        runValidators: true,\n        projection: { password: 0 } // Exclude password from result\n    }\n);\n\n// 5. Update with aggregation pipeline (MongoDB 4.2+)\nconst pipelineUpdate = await User.updateMany(\n    { role: 'user' },\n    [\n        {\n            $set: {\n                fullName: { $concat: ['$firstName', ' ', '$lastName'] },\n                updatedAt: new Date()\n            }\n        }\n    ]\n);\n\n// 6. Conditional updates with $cond\nconst conditionalUpdate = await User.updateMany(\n    {},\n    {\n        $set: {\n            status: {\n                $cond: {\n                    if: { $gte: ['$age', 18] },\n                    then: 'adult',\n                    else: 'minor'\n                }\n            }\n        }\n    }\n);\n```\n\n**Update Methods Comparison:**\n\n| Method | Returns Document | Use Case | Performance |\n|--------|------------------|----------|-------------|\n| **`updateOne()`** | No (only stats) | Single doc update, don't need result | Fastest |\n| **`updateMany()`** | No (only stats) | Bulk updates | Fast |\n| **`findByIdAndUpdate()`** | Yes (if `new: true`) | Update by ID, need result | Slower |\n| **`findOneAndUpdate()`** | Yes (if `new: true`) | Update with complex filter, need result | Slower |\n\n**Important Options:**\n\n| Option | Purpose | Default |\n|--------|---------|--------|\n| **`new`** | Return updated document instead of original | `false` |\n| **`runValidators`** | Run schema validation on update | `false` |\n| **`upsert`** | Create document if not found | `false` |\n| **`projection`** | Specify fields to return | All fields |\n\n**Key Points:**\n- **`{ new: true }`** is crucial - without it, you get the original document\n- **`runValidators: true`** ensures schema validation runs on updates\n- **Update operators** like `$set`, `$inc`, `$push`, `$pull` are essential\n- **Performance**: Direct updates are faster than find-and-update methods",
    "difficulty": "Hard",
    "category": "Mongoose Updates",
    "database": "MongoDB",
    "tags": [
      "Mongoose",
      "Update",
      "findByIdAndUpdate",
      "Options",
      "Validation"
    ]
  },
  {
    "id": 42,
    "question": "Implement Mongoose delete operations and explain when to use `deleteOne()`, `deleteMany()`, and `findByIdAndDelete()`.",
    "solution": "```javascript\n// Mongoose Delete Operations\n\n// 1. Model.deleteOne() - Delete first matching document\n// Returns deletion statistics, not the deleted document\nconst deleteResult = await User.deleteOne({ \n    email: 'jane.smith@example.com' \n});\nconsole.log(`${deleteResult.deletedCount} user deleted.`);\n\n// 2. Model.deleteMany() - Delete all matching documents\n// Good for bulk deletions\nconst bulkDeleteResult = await User.deleteMany({\n    role: 'inactive',\n    lastLogin: { $lt: new Date(Date.now() - 365 * 24 * 60 * 60 * 1000) } // 1 year ago\n});\nconsole.log(`${bulkDeleteResult.deletedCount} inactive users deleted.`);\n\n// 3. Model.findByIdAndDelete() - Find by ID and delete\n// Returns the deleted document (useful for logging or undo functionality)\nconst deletedUser = await User.findByIdAndDelete('65f3f4c6e8e81d7f6c3d9a54');\nif (deletedUser) {\n    console.log('Deleted user:', deletedUser.name);\n    // Log deletion for audit trail\n    await AuditLog.create({\n        action: 'USER_DELETED',\n        userId: deletedUser._id,\n        deletedData: deletedUser,\n        deletedBy: currentUserId,\n        deletedAt: new Date()\n    });\n} else {\n    console.log('User not found');\n}\n\n// 4. Model.findOneAndDelete() - More flexible deletion\nconst deletedPost = await Post.findOneAndDelete({\n    author: userId,\n    status: 'draft',\n    createdAt: { $lt: new Date(Date.now() - 30 * 24 * 60 * 60 * 1000) } // 30 days old\n});\n\n// 5. Soft delete implementation (mark as deleted instead of removing)\nconst softDeleteUser = await User.findByIdAndUpdate(\n    userId,\n    {\n        $set: {\n            isDeleted: true,\n            deletedAt: new Date(),\n            deletedBy: currentUserId\n        }\n    },\n    { new: true }\n);\n\n// 6. Cascade delete - Delete related documents\nasync function deleteUserAndPosts(userId) {\n    const session = await mongoose.startSession();\n    session.startTransaction();\n    \n    try {\n        // Delete user's posts first\n        const deletedPosts = await Post.deleteMany(\n            { author: userId },\n            { session }\n        );\n        \n        // Delete the user\n        const deletedUser = await User.findByIdAndDelete(\n            userId,\n            { session }\n        );\n        \n        await session.commitTransaction();\n        \n        return {\n            user: deletedUser,\n            postsDeleted: deletedPosts.deletedCount\n        };\n    } catch (error) {\n        await session.abortTransaction();\n        throw error;\n    } finally {\n        session.endSession();\n    }\n}\n\n// 7. Conditional delete with validation\nasync function safeDeleteUser(userId, currentUserId) {\n    const user = await User.findById(userId);\n    \n    if (!user) {\n        throw new Error('User not found');\n    }\n    \n    if (user.role === 'admin' && user._id.toString() !== currentUserId) {\n        throw new Error('Cannot delete another admin user');\n    }\n    \n    // Check for dependencies\n    const activePosts = await Post.countDocuments({\n        author: userId,\n        status: 'published'\n    });\n    \n    if (activePosts > 0) {\n        throw new Error(`Cannot delete user with ${activePosts} published posts`);\n    }\n    \n    return await User.findByIdAndDelete(userId);\n}\n```\n\n**Delete Methods Comparison:**\n\n| Method | Returns Document | Use Case | Example Scenario |\n|--------|------------------|----------|------------------|\n| **`deleteOne()`** | No (only stats) | Simple deletion, don't need deleted data | Remove duplicate entries |\n| **`deleteMany()`** | No (only stats) | Bulk deletion operations | Cleanup old records |\n| **`findByIdAndDelete()`** | Yes (deleted document) | Need deleted data for logging/undo | User account deletion |\n| **`findOneAndDelete()`** | Yes (deleted document) | Complex filter + need deleted data | Remove specific post |\n\n**Delete Operation Patterns:**\n\n| Pattern | Description | Implementation |\n|---------|-------------|----------------|\n| **Hard Delete** | Permanently remove from database | `deleteOne()`, `deleteMany()` |\n| **Soft Delete** | Mark as deleted, keep in database | Update with `isDeleted: true` |\n| **Cascade Delete** | Delete related documents | Use transactions |\n| **Safe Delete** | Validate before deletion | Check dependencies first |\n\n**Best Practices:**\n- **Use transactions** for cascade deletes\n- **Implement soft delete** for important data\n- **Log deletions** for audit trails\n- **Validate permissions** before deletion\n- **Check dependencies** to prevent orphaned data\n- **Return deleted document** when you need it for logging or undo functionality",
    "difficulty": "Medium",
    "category": "Mongoose Deletes",
    "database": "MongoDB",
    "tags": [
      "Mongoose",
      "Delete",
      "Cascade",
      "Soft Delete",
      "Transactions"
    ]
  },
  {
    "id": 43,
    "question": "Create a Mongoose middleware (hook) example for password hashing before saving a user document and explain pre vs post hooks.",
    "solution": "```javascript\nconst bcrypt = require('bcrypt');\nconst mongoose = require('mongoose');\nconst { Schema } = mongoose;\n\n// User schema with password hashing middleware\nconst userSchema = new Schema({\n    name: { type: String, required: true },\n    email: { type: String, required: true, unique: true },\n    password: { type: String, required: true, minlength: 6 },\n    role: { type: String, enum: ['user', 'admin'], default: 'user' },\n    loginAttempts: { type: Number, default: 0 },\n    lastLogin: Date\n}, {\n    timestamps: true\n});\n\n// PRE SAVE MIDDLEWARE - Runs BEFORE saving\nuserSchema.pre('save', async function(next) {\n    console.log('Pre-save middleware triggered');\n    \n    // 'this' refers to the document being saved\n    if (!this.isModified('password')) {\n        console.log('Password not modified, skipping hash');\n        return next(); // If password hasn't changed, skip hashing\n    }\n    \n    try {\n        console.log('Hashing password...');\n        const salt = await bcrypt.genSalt(10);\n        this.password = await bcrypt.hash(this.password, salt);\n        console.log('Password hashed successfully');\n        next(); // Continue with save operation\n    } catch (error) {\n        console.error('Error hashing password:', error);\n        next(error); // Pass error to abort save\n    }\n});\n\n// PRE SAVE MIDDLEWARE - Validate email format\nuserSchema.pre('save', function(next) {\n    const emailRegex = /^[^\\s@]+@[^\\s@]+\\.[^\\s@]+$/;\n    if (!emailRegex.test(this.email)) {\n        const error = new Error('Invalid email format');\n        return next(error);\n    }\n    next();\n});\n\n// POST SAVE MIDDLEWARE - Runs AFTER successful save\nuserSchema.post('save', function(doc, next) {\n    console.log('Post-save middleware triggered');\n    console.log(`User ${doc.name} has been saved with ID: ${doc._id}`);\n    \n    // Send welcome email (async operation)\n    sendWelcomeEmail(doc.email, doc.name)\n        .then(() => {\n            console.log('Welcome email sent');\n            next();\n        })\n        .catch(error => {\n            console.error('Failed to send welcome email:', error);\n            // Don't pass error to next() - save already succeeded\n            next();\n        });\n});\n\n// PRE UPDATE MIDDLEWARE - Runs before update operations\nuserSchema.pre(['updateOne', 'findOneAndUpdate'], async function(next) {\n    const update = this.getUpdate();\n    \n    // If password is being updated, hash it\n    if (update.$set && update.$set.password) {\n        try {\n            const salt = await bcrypt.genSalt(10);\n            update.$set.password = await bcrypt.hash(update.$set.password, salt);\n            console.log('Password hashed in update middleware');\n        } catch (error) {\n            return next(error);\n        }\n    }\n    \n    next();\n});\n\n// POST DELETE MIDDLEWARE - Cleanup after deletion\nuserSchema.post('findOneAndDelete', async function(doc) {\n    if (doc) {\n        console.log(`User ${doc.name} deleted, cleaning up...`);\n        \n        // Remove user's posts\n        await mongoose.model('Post').deleteMany({ author: doc._id });\n        \n        // Log deletion for audit\n        await mongoose.model('AuditLog').create({\n            action: 'USER_DELETED',\n            userId: doc._id,\n            userName: doc.name,\n            deletedAt: new Date()\n        });\n        \n        console.log('Cleanup completed');\n    }\n});\n\n// Instance methods\nuserSchema.methods.comparePassword = async function(candidatePassword) {\n    return bcrypt.compare(candidatePassword, this.password);\n};\n\nuserSchema.methods.incrementLoginAttempts = function() {\n    this.loginAttempts += 1;\n    return this.save();\n};\n\nuserSchema.methods.resetLoginAttempts = function() {\n    this.loginAttempts = 0;\n    this.lastLogin = new Date();\n    return this.save();\n};\n\n// Static methods\nuserSchema.statics.findByEmail = function(email) {\n    return this.findOne({ email: email.toLowerCase() });\n};\n\nconst User = mongoose.model('User', userSchema);\n\n// Usage examples\nasync function createUser() {\n    try {\n        const user = new User({\n            name: 'John Doe',\n            email: 'john@example.com',\n            password: 'plaintext123' // Will be hashed by pre-save middleware\n        });\n        \n        const savedUser = await user.save();\n        console.log('User created:', savedUser.name);\n        // Password is now hashed in database\n        \n    } catch (error) {\n        console.error('Error creating user:', error.message);\n    }\n}\n\nasync function loginUser(email, password) {\n    try {\n        const user = await User.findByEmail(email);\n        if (!user) {\n            throw new Error('User not found');\n        }\n        \n        const isMatch = await user.comparePassword(password);\n        if (!isMatch) {\n            await user.incrementLoginAttempts();\n            throw new Error('Invalid password');\n        }\n        \n        await user.resetLoginAttempts();\n        return user;\n        \n    } catch (error) {\n        console.error('Login error:', error.message);\n        throw error;\n    }\n}\n\n// Helper function (would be in separate module)\nasync function sendWelcomeEmail(email, name) {\n    // Simulate email sending\n    return new Promise((resolve) => {\n        setTimeout(() => {\n            console.log(`Welcome email sent to ${email}`);\n            resolve();\n        }, 100);\n    });\n}\n```\n\n**Middleware Types Comparison:**\n\n| Type | When it Runs | Use Cases | Error Handling |\n|------|--------------|-----------|----------------|\n| **PRE** | Before operation | Validation, hashing, data transformation | Call `next(error)` to abort |\n| **POST** | After successful operation | Logging, notifications, cleanup | Errors don't affect operation |\n\n**Common Middleware Hooks:**\n\n| Hook | Triggers On | Example Use Case |\n|------|-------------|------------------|\n| **`pre('save')`** | `save()`, `create()` | Hash passwords, validate data |\n| **`post('save')`** | After save success | Send notifications, log events |\n| **`pre('remove')`** | `remove()` | Check dependencies, validate deletion |\n| **`post('remove')`** | After removal | Cleanup related data |\n| **`pre('updateOne')`** | Update operations | Hash passwords in updates |\n| **`pre('find')`** | Query operations | Add default filters |\n\n**Best Practices:**\n- **Use `this.isModified()`** to check if field changed\n- **Handle errors properly** in pre middleware\n- **Don't fail post middleware** - operation already succeeded\n- **Use middleware for** validation, hashing, logging, cleanup\n- **Keep middleware focused** - one responsibility per hook",
    "difficulty": "Hard",
    "category": "Mongoose Middleware",
    "database": "MongoDB",
    "tags": [
      "Mongoose",
      "Middleware",
      "Hooks",
      "Password Hashing",
      "bcrypt"
    ]
  },
  {
    "id": 44,
    "question": "Implement Mongoose population to handle relationships between collections and explain how it works like a 'join' in MongoDB.",
    "solution": "```javascript\n// Population is Mongoose's way of handling relationships\n// It automatically replaces specified paths with actual documents from other collections\n\n// 1. Define schemas with references\nconst userSchema = new Schema({\n    name: String,\n    email: String,\n    profile: {\n        bio: String,\n        avatar: String\n    }\n});\n\nconst postSchema = new Schema({\n    title: String,\n    content: String,\n    author: {\n        type: Schema.Types.ObjectId,\n        ref: 'User', // This tells Mongoose which model to use during population\n        required: true\n    },\n    tags: [String],\n    comments: [{\n        author: {\n            type: Schema.Types.ObjectId,\n            ref: 'User'\n        },\n        text: String,\n        createdAt: { type: Date, default: Date.now }\n    }]\n}, { timestamps: true });\n\nconst User = mongoose.model('User', userSchema);\nconst Post = mongoose.model('Post', postSchema);\n\n// 2. Basic population\nconst post = await Post.findById('some-post-id')\n    .populate('author', 'name email'); // Populate 'author' and select only name and email\n\nconsole.log(post.author.name); // Instead of just an ID, post.author is now the full user document\n\n// 3. Advanced population with options\nconst postsWithAuthors = await Post.find()\n    .populate({\n        path: 'author',\n        select: 'name profile.avatar email',\n        match: { 'profile.verified': true }, // Only populate verified users\n        options: { sort: { name: 1 } }\n    })\n    .populate({\n        path: 'comments.author',\n        select: 'name profile.avatar'\n    })\n    .sort({ createdAt: -1 })\n    .limit(10);\n\n// 4. Conditional population\nconst userPosts = await Post.find({ author: userId })\n    .populate({\n        path: 'author',\n        select: 'name email',\n        match: { active: true },\n        populate: {\n            path: 'department', // Nested population\n            select: 'name location'\n        }\n    });\n\n// 5. Population with aggregation-like features\nconst popularPosts = await Post.find()\n    .populate({\n        path: 'comments.author',\n        select: 'name profile.reputation',\n        options: {\n            sort: { 'profile.reputation': -1 },\n            limit: 5 // Only top 5 commenters by reputation\n        }\n    })\n    .where('comments.5').exists() // Posts with at least 6 comments\n    .sort({ 'comments.length': -1 });\n\n// 6. Virtual population (reverse populate)\nuserSchema.virtual('posts', {\n    ref: 'Post',\n    localField: '_id',\n    foreignField: 'author'\n});\n\n// Enable virtual fields in JSON output\nuserSchema.set('toJSON', { virtuals: true });\n\nconst userWithPosts = await User.findById(userId)\n    .populate({\n        path: 'posts',\n        select: 'title createdAt',\n        options: { sort: { createdAt: -1 }, limit: 10 }\n    });\n\n// 7. Manual population using aggregation\nconst manualPopulation = await Post.aggregate([\n    { $match: { author: mongoose.Types.ObjectId(userId) } },\n    {\n        $lookup: {\n            from: 'users',\n            localField: 'author',\n            foreignField: '_id',\n            as: 'authorDetails'\n        }\n    },\n    {\n        $unwind: '$authorDetails'\n    },\n    {\n        $project: {\n            title: 1,\n            content: 1,\n            'author.name': '$authorDetails.name',\n            'author.email': '$authorDetails.email',\n            createdAt: 1\n        }\n    }\n]);\n```\n\n**Population Features:**\n\n| Feature | Description | Example |\n|---------|-------------|--------|\n| **Basic Population** | Replace ObjectId with referenced document | `.populate('author')` |\n| **Field Selection** | Choose specific fields to populate | `.populate('author', 'name email')` |\n| **Conditional Population** | Filter populated documents | `match: { active: true }` |\n| **Nested Population** | Populate references within populated docs | `populate: { path: 'department' }` |\n| **Virtual Population** | Reverse populate (one-to-many) | Virtual fields with ref |\n\n**How Population Works:**\n1. **Storage**: Only ObjectId is stored in the document\n2. **Query Time**: Mongoose performs separate queries to fetch referenced documents\n3. **Replacement**: ObjectIds are replaced with actual documents\n4. **Performance**: Multiple queries behind the scenes (consider aggregation for complex cases)",
    "difficulty": "Hard",
    "category": "Mongoose Population",
    "database": "MongoDB",
    "tags": [
      "Mongoose",
      "Population",
      "Relationships",
      "References",
      "Virtual"
    ]
  },
  {
    "id": 45,
    "question": "Create a comprehensive Mongoose aggregation pipeline to calculate user statistics and compare it with the aggregation framework concept.",
    "solution": "```javascript\n// Mongoose provides Model.aggregate() method to use MongoDB's aggregation pipeline\n// The aggregation framework processes documents in a series of stages\n\n// Sample User schema for demonstration\nconst userSchema = new Schema({\n    name: String,\n    email: String,\n    age: Number,\n    role: { type: String, enum: ['user', 'editor', 'admin'] },\n    department: String,\n    salary: Number,\n    joinDate: Date,\n    isActive: { type: Boolean, default: true },\n    skills: [String],\n    projects: [{\n        name: String,\n        status: { type: String, enum: ['active', 'completed', 'cancelled'] },\n        budget: Number,\n        startDate: Date\n    }]\n});\n\nconst User = mongoose.model('User', userSchema);\n\n// 1. Basic aggregation - Calculate user statistics by role\nconst roleStats = await User.aggregate([\n    // Stage 1: Filter only active users\n    {\n        $match: { isActive: true }\n    },\n    // Stage 2: Group documents by the 'role' field\n    {\n        $group: {\n            _id: '$role', // The field to group by\n            userCount: { $sum: 1 }, // Count documents in each group\n            averageAge: { $avg: '$age' }, // Calculate the average age in each group\n            averageSalary: { $avg: '$salary' },\n            minSalary: { $min: '$salary' },\n            maxSalary: { $max: '$salary' },\n            totalSalaryBudget: { $sum: '$salary' }\n        }\n    },\n    // Stage 3: Sort the results by user count descending\n    {\n        $sort: { userCount: -1 }\n    },\n    // Stage 4: Reshape the output\n    {\n        $project: {\n            _id: 0, // Exclude the default _id field\n            role: '$_id', // Rename _id to role\n            count: '$userCount',\n            avgAge: { $round: ['$averageAge', 1] }, // Round the average age\n            avgSalary: { $round: ['$averageSalary', 2] },\n            salaryRange: {\n                min: '$minSalary',\n                max: '$maxSalary'\n            },\n            totalBudget: '$totalSalaryBudget'\n        }\n    }\n]);\n\n// 2. Complex aggregation with multiple stages\nconst departmentAnalysis = await User.aggregate([\n    // Stage 1: Match active users with projects\n    {\n        $match: {\n            isActive: true,\n            'projects.0': { $exists: true } // Has at least one project\n        }\n    },\n    // Stage 2: Unwind projects array\n    {\n        $unwind: '$projects'\n    },\n    // Stage 3: Add computed fields\n    {\n        $addFields: {\n            projectDuration: {\n                $dateDiff: {\n                    startDate: '$projects.startDate',\n                    endDate: new Date(),\n                    unit: 'day'\n                }\n            },\n            experienceYears: {\n                $dateDiff: {\n                    startDate: '$joinDate',\n                    endDate: new Date(),\n                    unit: 'year'\n                }\n            }\n        }\n    },\n    // Stage 4: Group by department\n    {\n        $group: {\n            _id: '$department',\n            employeeCount: { $sum: 1 },\n            avgAge: { $avg: '$age' },\n            avgExperience: { $avg: '$experienceYears' },\n            avgSalary: { $avg: '$salary' },\n            totalProjects: { $sum: 1 },\n            activeProjects: {\n                $sum: {\n                    $cond: [{ $eq: ['$projects.status', 'active'] }, 1, 0]\n                }\n            },\n            completedProjects: {\n                $sum: {\n                    $cond: [{ $eq: ['$projects.status', 'completed'] }, 1, 0]\n                }\n            },\n            totalBudget: { $sum: '$projects.budget' },\n            avgProjectDuration: { $avg: '$projectDuration' },\n            topSkills: { $addToSet: '$skills' } // Collect unique skills\n        }\n    },\n    // Stage 5: Add calculated fields\n    {\n        $addFields: {\n            completionRate: {\n                $round: [\n                    {\n                        $multiply: [\n                            { $divide: ['$completedProjects', '$totalProjects'] },\n                            100\n                        ]\n                    },\n                    2\n                ]\n            },\n            avgProjectBudget: {\n                $round: [{ $divide: ['$totalBudget', '$totalProjects'] }, 2]\n            }\n        }\n    },\n    // Stage 6: Sort by total budget descending\n    {\n        $sort: { totalBudget: -1 }\n    },\n    // Stage 7: Final projection\n    {\n        $project: {\n            department: '$_id',\n            employeeCount: 1,\n            avgAge: { $round: ['$avgAge', 1] },\n            avgExperience: { $round: ['$avgExperience', 1] },\n            avgSalary: { $round: ['$avgSalary', 2] },\n            projectStats: {\n                total: '$totalProjects',\n                active: '$activeProjects',\n                completed: '$completedProjects',\n                completionRate: '$completionRate'\n            },\n            budgetStats: {\n                total: '$totalBudget',\n                avgPerProject: '$avgProjectBudget'\n            },\n            avgProjectDuration: { $round: ['$avgProjectDuration', 0] },\n            skillCount: { $size: { $reduce: {\n                input: '$topSkills',\n                initialValue: [],\n                in: { $setUnion: ['$$value', '$$this'] }\n            }}},\n            _id: 0\n        }\n    }\n]);\n\n// 3. Aggregation with lookup (join)\nconst userProjectSummary = await User.aggregate([\n    { $match: { isActive: true } },\n    {\n        $lookup: {\n            from: 'projects', // External collection\n            localField: '_id',\n            foreignField: 'assignedUsers',\n            as: 'assignedProjects'\n        }\n    },\n    {\n        $addFields: {\n            projectCount: { $size: '$assignedProjects' },\n            activeProjectCount: {\n                $size: {\n                    $filter: {\n                        input: '$assignedProjects',\n                        cond: { $eq: ['$$this.status', 'active'] }\n                    }\n                }\n            }\n        }\n    },\n    {\n        $project: {\n            name: 1,\n            role: 1,\n            department: 1,\n            projectCount: 1,\n            activeProjectCount: 1,\n            workload: {\n                $switch: {\n                    branches: [\n                        { case: { $eq: ['$activeProjectCount', 0] }, then: 'Light' },\n                        { case: { $lte: ['$activeProjectCount', 2] }, then: 'Moderate' },\n                        { case: { $lte: ['$activeProjectCount', 4] }, then: 'Heavy' }\n                    ],\n                    default: 'Overloaded'\n                }\n            }\n        }\n    }\n]);\n\nconsole.log('Role Statistics:', roleStats);\nconsole.log('Department Analysis:', departmentAnalysis);\nconsole.log('User Project Summary:', userProjectSummary);\n```\n\n**Aggregation Pipeline Stages:**\n\n| Stage | Purpose | Example |\n|-------|---------|--------|\n| **`$match`** | Filters documents (like WHERE clause) | `{ $match: { isActive: true } }` |\n| **`$group`** | Groups documents and performs aggregations | `{ $group: { _id: '$role', count: { $sum: 1 } } }` |\n| **`$project`** | Reshapes documents, adds/removes fields | `{ $project: { name: 1, _id: 0 } }` |\n| **`$sort`** | Orders documents | `{ $sort: { count: -1 } }` |\n| **`$limit`** | Limits number of documents | `{ $limit: 10 }` |\n| **`$skip`** | Skips documents | `{ $skip: 20 }` |\n| **`$unwind`** | Deconstructs arrays | `{ $unwind: '$projects' }` |\n| **`$lookup`** | Joins with other collections | External collection joins |\n| **`$addFields`** | Adds computed fields | `{ $addFields: { total: { $add: ['$a', '$b'] } } }` |\n\n**Key Benefits:**\n- **Performance**: Processing happens at database level\n- **Powerful**: Complex data transformations and analysis\n- **Pipeline**: Each stage processes output of previous stage\n- **Flexibility**: Combine multiple operations in sequence\n- **Efficiency**: Reduces data transfer between database and application",
    "difficulty": "Hard",
    "category": "Mongoose Aggregation",
    "database": "MongoDB",
    "tags": [
      "Mongoose",
      "Aggregation",
      "Pipeline",
      "Statistics",
      "Analysis"
    ]
  },
  {
    "id": 46,
    "question": "Implement Mongoose transactions for multi-document operations and explain ACID properties with a real-world scenario.",
    "solution": "```javascript\n// Mongoose supports multi-document transactions using sessions\n// This requires a replica set configuration in MongoDB\n// Transactions provide ACID properties: Atomicity, Consistency, Isolation, Durability\n\n// Schemas for demonstration\nconst userSchema = new Schema({\n    name: String,\n    email: String,\n    balance: { type: Number, default: 0 },\n    isActive: { type: Boolean, default: true }\n});\n\nconst accountSchema = new Schema({\n    userId: { type: Schema.Types.ObjectId, ref: 'User', required: true },\n    accountNumber: { type: String, unique: true },\n    balance: { type: Number, default: 0 },\n    type: { type: String, enum: ['checking', 'savings'] }\n});\n\nconst transactionSchema = new Schema({\n    fromAccount: { type: Schema.Types.ObjectId, ref: 'Account' },\n    toAccount: { type: Schema.Types.ObjectId, ref: 'Account' },\n    amount: { type: Number, required: true },\n    type: { type: String, enum: ['transfer', 'deposit', 'withdrawal'] },\n    status: { type: String, enum: ['pending', 'completed', 'failed'], default: 'pending' },\n    description: String\n}, { timestamps: true });\n\nconst User = mongoose.model('User', userSchema);\nconst Account = mongoose.model('Account', accountSchema);\nconst Transaction = mongoose.model('Transaction', transactionSchema);\n\n// 1. Basic Transaction - Money Transfer\nasync function transferMoney(fromAccountId, toAccountId, amount, description) {\n    const session = await mongoose.startSession();\n    session.startTransaction();\n    \n    try {\n        // Step 1: Validate accounts exist and have sufficient balance\n        const fromAccount = await Account.findById(fromAccountId).session(session);\n        const toAccount = await Account.findById(toAccountId).session(session);\n        \n        if (!fromAccount || !toAccount) {\n            throw new Error('One or both accounts not found');\n        }\n        \n        if (fromAccount.balance < amount) {\n            throw new Error('Insufficient balance');\n        }\n        \n        // Step 2: Create transaction record\n        const transactionRecord = await Transaction.create([{\n            fromAccount: fromAccountId,\n            toAccount: toAccountId,\n            amount: amount,\n            type: 'transfer',\n            description: description,\n            status: 'pending'\n        }], { session });\n        \n        // Step 3: Update account balances\n        await Account.findByIdAndUpdate(\n            fromAccountId,\n            { $inc: { balance: -amount } },\n            { session, new: true }\n        );\n        \n        await Account.findByIdAndUpdate(\n            toAccountId,\n            { $inc: { balance: amount } },\n            { session, new: true }\n        );\n        \n        // Step 4: Mark transaction as completed\n        await Transaction.findByIdAndUpdate(\n            transactionRecord[0]._id,\n            { status: 'completed' },\n            { session }\n        );\n        \n        // If all operations succeed, commit the transaction\n        await session.commitTransaction();\n        console.log('Money transfer completed successfully');\n        \n        return {\n            success: true,\n            transactionId: transactionRecord[0]._id,\n            message: `Transferred $${amount} from ${fromAccount.accountNumber} to ${toAccount.accountNumber}`\n        };\n        \n    } catch (error) {\n        // If any operation fails, abort the entire transaction\n        await session.abortTransaction();\n        console.error('Transaction aborted:', error.message);\n        \n        return {\n            success: false,\n            error: error.message\n        };\n        \n    } finally {\n        // Always end the session\n        session.endSession();\n    }\n}\n\n// 2. Complex Transaction - User Registration with Account Creation\nasync function registerUserWithAccount(userData, initialDeposit = 0) {\n    const session = await mongoose.startSession();\n    session.startTransaction();\n    \n    try {\n        // Step 1: Create user\n        const user = await User.create([{\n            name: userData.name,\n            email: userData.email,\n            balance: initialDeposit\n        }], { session });\n        \n        // Step 2: Create checking account\n        const checkingAccount = await Account.create([{\n            userId: user[0]._id,\n            accountNumber: generateAccountNumber(),\n            balance: initialDeposit,\n            type: 'checking'\n        }], { session });\n        \n        // Step 3: Create savings account\n        const savingsAccount = await Account.create([{\n            userId: user[0]._id,\n            accountNumber: generateAccountNumber(),\n            balance: 0,\n            type: 'savings'\n        }], { session });\n        \n        // Step 4: Create initial deposit transaction if amount > 0\n        if (initialDeposit > 0) {\n            await Transaction.create([{\n                toAccount: checkingAccount[0]._id,\n                amount: initialDeposit,\n                type: 'deposit',\n                description: 'Initial deposit',\n                status: 'completed'\n            }], { session });\n        }\n        \n        // Step 5: Send welcome email (simulate)\n        await sendWelcomeEmail(user[0].email, user[0].name);\n        \n        await session.commitTransaction();\n        \n        return {\n            success: true,\n            user: user[0],\n            accounts: {\n                checking: checkingAccount[0],\n                savings: savingsAccount[0]\n            }\n        };\n        \n    } catch (error) {\n        await session.abortTransaction();\n        throw new Error(`User registration failed: ${error.message}`);\n        \n    } finally {\n        session.endSession();\n    }\n}\n\n// 3. Batch Transaction - Multiple Operations\nasync function processBatchTransfers(transfers) {\n    const session = await mongoose.startSession();\n    session.startTransaction();\n    \n    try {\n        const results = [];\n        \n        for (const transfer of transfers) {\n            // Validate each transfer\n            const fromAccount = await Account.findById(transfer.fromAccountId).session(session);\n            if (fromAccount.balance < transfer.amount) {\n                throw new Error(`Insufficient balance in account ${fromAccount.accountNumber}`);\n            }\n            \n            // Process transfer\n            await Account.findByIdAndUpdate(\n                transfer.fromAccountId,\n                { $inc: { balance: -transfer.amount } },\n                { session }\n            );\n            \n            await Account.findByIdAndUpdate(\n                transfer.toAccountId,\n                { $inc: { balance: transfer.amount } },\n                { session }\n            );\n            \n            // Record transaction\n            const transaction = await Transaction.create([{\n                fromAccount: transfer.fromAccountId,\n                toAccount: transfer.toAccountId,\n                amount: transfer.amount,\n                type: 'transfer',\n                description: transfer.description,\n                status: 'completed'\n            }], { session });\n            \n            results.push(transaction[0]);\n        }\n        \n        await session.commitTransaction();\n        return { success: true, transactions: results };\n        \n    } catch (error) {\n        await session.abortTransaction();\n        throw error;\n        \n    } finally {\n        session.endSession();\n    }\n}\n\n// Helper functions\nfunction generateAccountNumber() {\n    return Math.random().toString().substr(2, 10);\n}\n\nasync function sendWelcomeEmail(email, name) {\n    // Simulate email sending\n    return new Promise(resolve => setTimeout(resolve, 100));\n}\n\n// Usage examples\nasync function examples() {\n    try {\n        // Transfer money between accounts\n        const transferResult = await transferMoney(\n            'fromAccountId123',\n            'toAccountId456',\n            100.00,\n            'Monthly rent payment'\n        );\n        \n        // Register new user with accounts\n        const registrationResult = await registerUserWithAccount({\n            name: 'John Doe',\n            email: 'john@example.com'\n        }, 500.00);\n        \n    } catch (error) {\n        console.error('Operation failed:', error.message);\n    }\n}\n```\n\n**ACID Properties in MongoDB Transactions:**\n\n| Property | Description | Example |\n|----------|-------------|--------|\n| **Atomicity** | All operations succeed or all fail | Money transfer: debit AND credit both happen or neither |\n| **Consistency** | Database remains in valid state | Account balances always accurate after transactions |\n| **Isolation** | Concurrent transactions don't interfere | Multiple transfers don't see intermediate states |\n| **Durability** | Committed changes persist | Completed transactions survive system crashes |\n\n**When to Use Transactions:**\n\n| Scenario | Reason | Example |\n|----------|--------|--------|\n| **Financial Operations** | Money must be conserved | Bank transfers, payment processing |\n| **Multi-step Registration** | All steps must complete | User + profile + accounts creation |\n| **Inventory Management** | Stock levels must be accurate | Order processing with inventory deduction |\n| **Data Integrity** | Related data must stay consistent | User deletion with cleanup of related records |\n\n**Best Practices:**\n- **Keep transactions short** - minimize lock time\n- **Handle errors properly** - always abort on failure\n- **Use sessions consistently** - pass session to all operations\n- **Avoid long-running operations** - transactions have timeouts\n- **Test rollback scenarios** - ensure proper cleanup on failures",
    "difficulty": "Expert",
    "category": "Mongoose Transactions",
    "database": "MongoDB",
    "tags": [
      "Mongoose",
      "Transactions",
      "ACID",
      "Sessions",
      "Financial"
    ]
  },
  {
    "id": 47,
    "question": "Explain MongoDB storage engines, compare WiredTiger, MMAPv1, and In-Memory engines with their use cases and trade-offs.",
    "solution": "**MongoDB Storage Engines** are components that handle how data is stored on and retrieved from disk. Understanding storage engines is crucial for performance optimization and architectural decisions.\n\n```javascript\n// Storage engine configuration examples\n\n// 1. Starting MongoDB with specific storage engine\n// Command line examples:\n\n// WiredTiger (default)\nmongod --storageEngine wiredTiger --wiredTigerCacheSizeGB 4\n\n// In-Memory (Enterprise only)\nmongod --storageEngine inMemory --inMemorySizeGB 8\n\n// Configuration file approach\n// mongod.conf\n/*\nstorage:\n  engine: wiredTiger\n  wiredTiger:\n    engineConfig:\n      cacheSizeGB: 4\n      directoryForIndexes: true\n    collectionConfig:\n      blockCompressor: snappy\n    indexConfig:\n      prefixCompression: true\n*/\n\n// 2. Storage engine specific operations\n// Check current storage engine\ndb.serverStatus().storageEngine\n\n// WiredTiger specific statistics\ndb.serverStatus().wiredTiger\n\n// Collection storage statistics\ndb.collection.stats()\n```\n\n**Storage Engine Comparison:**\n\n| Feature | WiredTiger | MMAPv1 | In-Memory |\n|---------|------------|--------|-----------|\n| **Status** | Default & Recommended | Deprecated | Enterprise Only |\n| **Concurrency** | Document-level locking | Collection-level locking | Document-level locking |\n| **Compression** | Yes (Snappy, zlib, zstd) | No | N/A |\n| **Caching** | Configurable internal cache | Relies on OS cache | All data in RAM |\n| **Persistence** | Persistent | Persistent | Non-persistent |\n| **Performance** | High | Moderate | Ultra-high |\n| **Memory Usage** | Efficient | Higher | RAM-dependent |\n| **Write Performance** | Excellent | Good | Excellent |\n| **Read Performance** | Excellent | Good | Ultra-fast |\n\n**1. WiredTiger (Default & Recommended):**\n\n```javascript\n// WiredTiger advantages demonstration\n\n// Document-level concurrency - multiple writers can work simultaneously\nconst Promise = require('bluebird');\n\n// This would cause blocking in MMAPv1 but works efficiently in WiredTiger\nconst concurrentWrites = async () => {\n    const writes = [];\n    \n    for (let i = 0; i < 10; i++) {\n        writes.push(\n            User.create({\n                name: `User ${i}`,\n                email: `user${i}@example.com`,\n                data: generateLargeData()\n            })\n        );\n    }\n    \n    // All writes can proceed simultaneously\n    const results = await Promise.all(writes);\n    console.log(`Created ${results.length} users concurrently`);\n};\n\n// Compression benefits\nconst compressionExample = {\n    // Original document size: ~1MB\n    userData: {\n        profile: {\n            description: \"A\".repeat(100000), // Large text field\n            preferences: {\n                notifications: true,\n                privacy: \"private\",\n                themes: [\"dark\", \"light\", \"auto\"]\n            }\n        },\n        activity: Array(1000).fill().map((_, i) => ({\n            timestamp: new Date(),\n            action: `action_${i}`,\n            data: `data_${i}\".repeat(100)`\n        }))\n    }\n    // With Snappy compression: ~300KB storage\n    // With zlib compression: ~200KB storage (slower but better ratio)\n};\n```\n\n**WiredTiger Features:**\n- **Document-Level Concurrency**: Multiple clients can modify different documents simultaneously\n- **Compression**: Reduces storage space by 50-80% with minimal performance impact\n- **Caching**: Configurable internal cache (default: 50% of RAM - 1GB)\n- **Checkpointing**: Periodic snapshots ensure data durability\n- **Journal**: Write-ahead logging for crash recovery\n\n**2. MMAPv1 (Deprecated):**\n\n| Limitation | Impact | WiredTiger Solution |\n|------------|--------|-----------------|\n| **Collection-level locking** | One writer per collection | Document-level locking |\n| **No compression** | Larger storage requirements | Built-in compression |\n| **Memory mapping** | Relies on OS virtual memory | Dedicated cache management |\n| **Power of 2 allocation** | Space wastage | Efficient space allocation |\n\n**3. In-Memory Storage Engine:**\n\n```javascript\n// In-Memory engine use cases and configuration\n\n// Configuration for In-Memory engine\nconst inMemoryConfig = {\n    // All data stored in RAM\n    storageEngine: 'inMemory',\n    inMemorySizeGB: 16, // Total memory allocation\n    \n    // Typical use cases:\n    useCases: {\n        caching: {\n            description: \"High-speed caching layer\",\n            dataPattern: \"Frequently accessed, easily reconstructible\",\n            durability: \"Not required\"\n        },\n        realTimeAnalytics: {\n            description: \"Real-time data processing\",\n            dataPattern: \"Streaming data, temporary aggregations\",\n            durability: \"Processed results stored elsewhere\"\n        },\n        sessionStore: {\n            description: \"User session data\",\n            dataPattern: \"Temporary, user-specific data\",\n            durability: \"Can be regenerated on login\"\n        },\n        leaderboards: {\n            description: \"Gaming scores and rankings\",\n            dataPattern: \"Frequently updated, real-time rankings\",\n            durability: \"Periodic snapshots to persistent storage\"\n        }\n    }\n};\n\n// Hybrid architecture example\nconst hybridArchitecture = {\n    primary: {\n        engine: \"wiredTiger\",\n        role: \"Data durability and persistence\",\n        operations: [\"writes\", \"complex queries\", \"backups\"]\n    },\n    secondaryHidden: {\n        engine: \"inMemory\",\n        role: \"Ultra-fast reads for real-time features\",\n        operations: [\"real-time analytics\", \"caching\", \"session data\"]\n    },\n    routing: {\n        writes: \"Primary (WiredTiger)\",\n        reads: {\n            analytical: \"Secondary (In-Memory)\",\n            transactional: \"Primary (WiredTiger)\"\n        }\n    }\n};\n```\n\n**In-Memory Features:**\n- **Ultra-low Latency**: All data access from RAM\n- **Non-Persistent**: Data lost on shutdown/crash\n- **Enterprise Only**: Requires MongoDB Enterprise license\n- **Memory Bound**: Dataset must fit in available RAM\n\n**Choosing the Right Storage Engine:**\n\n| Scenario | Recommended Engine | Reason |\n|----------|-------------------|--------|\n| **General Purpose** | WiredTiger | Best balance of features and performance |\n| **High Concurrency** | WiredTiger | Document-level locking |\n| **Storage Optimization** | WiredTiger | Compression capabilities |\n| **Ultra-low Latency** | In-Memory | All data in RAM |\n| **Caching Layer** | In-Memory | Fast access, data can be reconstructed |\n| **Legacy Systems** | WiredTiger | MMAPv1 is deprecated |\n| **Real-time Analytics** | In-Memory | Fastest possible data access |\n\n**Performance Considerations:**\n\n```javascript\n// Storage engine performance tuning\nconst performanceTuning = {\n    wiredTiger: {\n        cacheSize: \"50% of RAM minus 1GB (default)\",\n        compression: \"snappy (balanced), zlib (max compression)\",\n        checkpointInterval: \"60 seconds (default)\",\n        journalCommitInterval: \"100ms (default)\"\n    },\n    inMemory: {\n        memorySize: \"Total dataset size + working set\",\n        indexMemory: \"Included in total memory allocation\",\n        considerations: [\"No disk I/O\", \"Restart loses all data\"]\n    },\n    monitoring: {\n        wiredTigerCache: \"db.serverStatus().wiredTiger.cache\",\n        storageStats: \"db.stats()\",\n        collectionStats: \"db.collection.stats()\"\n    }\n};\n```\n\n**Best Practices:**\n- **Use WiredTiger** for production applications (it's the default)\n- **Configure cache size** appropriately for WiredTiger\n- **Consider In-Memory** for specific high-performance use cases\n- **Monitor storage metrics** regularly\n- **Never use MMAPv1** for new deployments\n- **Plan for failover** when using In-Memory engine",
    "difficulty": "Hard",
    "category": "MongoDB Storage",
    "database": "MongoDB",
    "tags": [
      "MongoDB",
      "Storage Engines",
      "WiredTiger",
      "In-Memory",
      "Performance"
    ]
  },
  {
    "id": 48,
    "question": "Demonstrate the use of `$explain` and `$hint` for MongoDB query optimization and performance analysis.",
    "solution": "```javascript\n// $explain and $hint are powerful tools for query optimization\n// $explain shows how MongoDB executes queries\n// $hint forces MongoDB to use specific indexes\n\n// Sample collection setup for demonstration\ndb.orders.insertMany([\n    { orderId: 1, customerId: 101, status: \"pending\", amount: 250.00, date: new Date(\"2024-01-15\") },\n    { orderId: 2, customerId: 102, status: \"completed\", amount: 175.50, date: new Date(\"2024-01-16\") },\n    { orderId: 3, customerId: 101, status: \"pending\", amount: 320.75, date: new Date(\"2024-01-17\") },\n    // ... more documents\n]);\n\n// Create various indexes for demonstration\ndb.orders.createIndex({ status: 1 }); // Single field index\ndb.orders.createIndex({ customerId: 1, date: -1 }); // Compound index\ndb.orders.createIndex({ amount: 1 }); // Amount index\ndb.orders.createIndex({ status: 1, amount: -1 }); // Status + amount compound\n\n// 1. Using $explain - Basic Query Analysis\n// Three verbosity levels: queryPlanner, executionStats, allPlansExecution\n\n// queryPlanner (default) - Shows winning query plan\ndb.orders.find({ status: \"pending\" }).explain();\n\n// executionStats - Shows execution statistics\nconst executionStats = db.orders.find({ status: \"pending\" }).explain(\"executionStats\");\n/*\nKey metrics in executionStats:\n- totalDocsExamined: Documents scanned\n- totalDocsReturned: Documents returned\n- executionTimeMillis: Query execution time\n- indexesUsed: Which indexes were utilized\n- stage: IXSCAN (index scan) vs COLLSCAN (collection scan)\n*/\n\n// allPlansExecution - Shows all considered plans\ndb.orders.find({ status: \"pending\" }).explain(\"allPlansExecution\");\n\n// 2. Complex Query Analysis\nconst complexQuery = db.orders.find({\n    status: \"pending\",\n    amount: { $gte: 200 },\n    customerId: { $in: [101, 102, 103] }\n}).sort({ date: -1 }).explain(\"executionStats\");\n\n// Analyze the results\nfunction analyzeQueryPerformance(explainResult) {\n    const stats = explainResult.executionStats;\n    \n    console.log(\"Query Performance Analysis:\");\n    console.log(`Execution Time: ${stats.executionTimeMillis}ms`);\n    console.log(`Documents Examined: ${stats.totalDocsExamined}`);\n    console.log(`Documents Returned: ${stats.totalDocsReturned}`);\n    console.log(`Index Used: ${stats.winningPlan.inputStage?.indexName || 'None (Collection Scan)'}`);\n    \n    // Performance indicators\n    const ratio = stats.totalDocsReturned / stats.totalDocsExamined;\n    if (ratio < 0.1) {\n        console.log(\"⚠️  Warning: Low selectivity ratio - consider better indexing\");\n    }\n    \n    if (stats.executionTimeMillis > 100) {\n        console.log(\"⚠️  Warning: Query taking too long - optimization needed\");\n    }\n    \n    if (stats.winningPlan.stage === 'COLLSCAN') {\n        console.log(\"⚠️  Warning: Collection scan detected - create appropriate index\");\n    }\n}\n\n// 3. Using $hint to Force Specific Index Usage\n\n// Without hint - MongoDB chooses the index\ndb.orders.find({ \n    status: \"pending\", \n    amount: { $gte: 200 } \n}).explain(\"executionStats\");\n\n// With hint - Force use of status index\ndb.orders.find({ \n    status: \"pending\", \n    amount: { $gte: 200 } \n}).hint({ status: 1 }).explain(\"executionStats\");\n\n// With hint - Force use of compound index\ndb.orders.find({ \n    status: \"pending\", \n    amount: { $gte: 200 } \n}).hint({ status: 1, amount: -1 }).explain(\"executionStats\");\n\n// Force collection scan (for comparison)\ndb.orders.find({ status: \"pending\" }).hint({ $natural: 1 }).explain(\"executionStats\");\n\n// 4. Performance Testing and Comparison\nfunction compareIndexPerformance() {\n    const query = { status: \"pending\", amount: { $gte: 200 } };\n    \n    console.log(\"Comparing different index strategies:\");\n    \n    // Test 1: No hint (MongoDB's choice)\n    const noHint = db.orders.find(query).explain(\"executionStats\");\n    console.log(`No Hint: ${noHint.executionStats.executionTimeMillis}ms`);\n    \n    // Test 2: Status index\n    const statusHint = db.orders.find(query).hint({ status: 1 }).explain(\"executionStats\");\n    console.log(`Status Index: ${statusHint.executionStats.executionTimeMillis}ms`);\n    \n    // Test 3: Compound index\n    const compoundHint = db.orders.find(query).hint({ status: 1, amount: -1 }).explain(\"executionStats\");\n    console.log(`Compound Index: ${compoundHint.executionStats.executionTimeMillis}ms`);\n    \n    // Test 4: Amount index\n    const amountHint = db.orders.find(query).hint({ amount: 1 }).explain(\"executionStats\");\n    console.log(`Amount Index: ${amountHint.executionStats.executionTimeMillis}ms`);\n}\n\n// 5. Aggregation Pipeline Explain\nconst aggregationExplain = db.orders.aggregate([\n    { $match: { status: \"pending\" } },\n    { $group: { \n        _id: \"$customerId\", \n        totalAmount: { $sum: \"$amount\" },\n        orderCount: { $sum: 1 }\n    }},\n    { $sort: { totalAmount: -1 } },\n    { $limit: 10 }\n]).explain(\"executionStats\");\n\n// 6. Index Effectiveness Analysis\nfunction analyzeIndexEffectiveness(collectionName) {\n    // Get index usage statistics\n    const indexStats = db[collectionName].aggregate([\n        { $indexStats: {} }\n    ]).toArray();\n    \n    console.log(\"Index Usage Statistics:\");\n    indexStats.forEach(index => {\n        console.log(`Index: ${index.name}`);\n        console.log(`Usage Count: ${index.accesses.ops}`);\n        console.log(`Last Used: ${index.accesses.since}`);\n        \n        if (index.accesses.ops === 0) {\n            console.log(`⚠️  Index '${index.name}' is unused - consider dropping`);\n        }\n    });\n}\n\n// 7. Query Optimization Recommendations\nfunction optimizeQuery(query, collection) {\n    const explainResult = db[collection].find(query).explain(\"executionStats\");\n    const stats = explainResult.executionStats;\n    \n    const recommendations = [];\n    \n    // Check for collection scan\n    if (stats.winningPlan.stage === 'COLLSCAN') {\n        recommendations.push(\"Create an index on frequently queried fields\");\n    }\n    \n    // Check selectivity\n    const selectivity = stats.totalDocsReturned / stats.totalDocsExamined;\n    if (selectivity < 0.1) {\n        recommendations.push(\"Improve query selectivity - consider compound indexes\");\n    }\n    \n    // Check execution time\n    if (stats.executionTimeMillis > 100) {\n        recommendations.push(\"Query is slow - consider index optimization\");\n    }\n    \n    // Check if sort is in memory\n    if (stats.winningPlan.inputStage?.stage === 'SORT') {\n        recommendations.push(\"Sort operation not using index - create index with sort fields\");\n    }\n    \n    return recommendations;\n}\n\n// 8. Mongoose Integration\nconst mongoose = require('mongoose');\n\n// Explain with Mongoose\nconst User = mongoose.model('User', userSchema);\n\n// Method 1: Using .explain()\nconst mongooseExplain = await User.find({ status: 'active' }).explain('executionStats');\n\n// Method 2: Using native MongoDB operations\nconst nativeExplain = await User.collection.find({ status: 'active' }).explain('executionStats');\n\n// Method 3: Aggregation explain\nconst aggExplain = await User.aggregate([\n    { $match: { status: 'active' } },\n    { $group: { _id: '$department', count: { $sum: 1 } } }\n]).explain('executionStats');\n```\n\n**$explain Verbosity Levels:**\n\n| Level | Information Provided | Use Case |\n|-------|---------------------|----------|\n| **`queryPlanner`** | Query plan selection | Understanding index selection |\n| **`executionStats`** | Execution metrics and timing | Performance analysis |\n| **`allPlansExecution`** | All considered plans | Debugging query optimizer |\n\n**Key $explain Metrics:**\n\n| Metric | Good Value | Bad Value | Action |\n|--------|------------|-----------|--------|\n| **executionTimeMillis** | < 100ms | > 1000ms | Optimize indexes |\n| **totalDocsExamined** | Close to returned | Much higher than returned | Improve selectivity |\n| **stage** | IXSCAN | COLLSCAN | Create indexes |\n| **indexesUsed** | Appropriate index | None or wrong index | Review index strategy |\n\n**$hint Use Cases:**\n\n| Scenario | Purpose | Example |\n|----------|---------|--------|\n| **Performance Testing** | Compare different indexes | `.hint({ field: 1 })` |\n| **Override Poor Choice** | Force better index | `.hint({ compound: 1, index: -1 })` |\n| **Debugging** | Force collection scan | `.hint({ $natural: 1 })` |\n| **Specific Requirements** | Ensure index usage | `.hint({ status: 1 })` |\n\n**Best Practices:**\n- **Use `executionStats`** for performance analysis\n- **Monitor `totalDocsExamined` vs `totalDocsReturned`** ratio\n- **Use `$hint` sparingly** - query optimizer is usually correct\n- **Test with real data volumes** - small datasets can be misleading\n- **Analyze slow queries regularly** using database profiler\n- **Create compound indexes** matching query patterns\n- **Drop unused indexes** to save space and improve write performance",
    "difficulty": "Hard",
    "category": "Query Optimization",
    "database": "MongoDB",
    "tags": [
      "MongoDB",
      "Explain",
      "Hint",
      "Performance",
      "Optimization"
    ]
  },
  {
    "id": 49,
    "question": "Explain MongoDB's advanced architecture concepts: Sharding and Replication. Compare their purposes, components, and use cases.",
    "solution": "**MongoDB Advanced Architecture** focuses on **Sharding** (horizontal scaling) and **Replication** (high availability). These are fundamental concepts for building robust, scalable MongoDB deployments.\n\n## **1. Replication - High Availability & Data Redundancy**\n\n```javascript\n// Replica Set Configuration Example\n// A replica set is a group of MongoDB servers maintaining the same dataset\n\n// 1. Initialize a replica set\nrs.initiate({\n    _id: \"myReplicaSet\",\n    members: [\n        { _id: 0, host: \"mongodb1.example.com:27017\", priority: 2 }, // Primary preference\n        { _id: 1, host: \"mongodb2.example.com:27017\", priority: 1 }, // Secondary\n        { _id: 2, host: \"mongodb3.example.com:27017\", priority: 1 }, // Secondary\n        { _id: 3, host: \"mongodb4.example.com:27017\", arbiterOnly: true } // Arbiter\n    ]\n});\n\n// 2. Check replica set status\nrs.status();\n\n// 3. Add a new member\nrs.add(\"mongodb5.example.com:27017\");\n\n// 4. Remove a member\nrs.remove(\"mongodb5.example.com:27017\");\n\n// 5. Configure read preferences\nconst mongoose = require('mongoose');\n\n// Connection with read preference\nmongoose.connect('mongodb://mongodb1.example.com:27017,mongodb2.example.com:27017,mongodb3.example.com:27017/myapp?replicaSet=myReplicaSet', {\n    readPreference: 'secondaryPreferred', // Try secondary first, fallback to primary\n    w: 'majority', // Write concern - wait for majority acknowledgment\n    j: true // Journal write concern\n});\n\n// 6. Read preference examples\nconst readPreferences = {\n    primary: \"Only from primary (default, strongest consistency)\",\n    primaryPreferred: \"Primary first, fallback to secondary\",\n    secondary: \"Only from secondaries (may read stale data)\",\n    secondaryPreferred: \"Secondary first, fallback to primary\",\n    nearest: \"Lowest network latency regardless of type\"\n};\n\n// Application-level read preference\nconst User = mongoose.model('User', userSchema);\n\n// Read from secondary for analytics\nconst analyticsData = await User.find({\n    createdAt: { $gte: new Date('2024-01-01') }\n}).read('secondary');\n\n// Critical reads from primary\nconst criticalData = await User.findById(userId).read('primary');\n```\n\n## **2. Sharding - Horizontal Scaling**\n\n```javascript\n// Sharding distributes data across multiple servers (shards)\n// Each shard is typically a replica set for high availability\n\n// 1. Sharded Cluster Components Setup\n\n// Config Servers (store metadata)\n// Start config servers as replica set\nmongod --configsvr --replSet configReplSet --port 27019 --dbpath /data/configdb\n\n// Mongos (query router)\n// Start mongos processes\nmongos --configdb configReplSet/config1.example.com:27019,config2.example.com:27019,config3.example.com:27019 --port 27017\n\n// Shard Servers (data storage)\n// Each shard is a replica set\nmongod --shardsvr --replSet shard1ReplSet --port 27018 --dbpath /data/shard1\n\n// 2. Initialize sharded cluster\n// Connect to mongos and add shards\nsh.addShard(\"shard1ReplSet/shard1-a.example.com:27018,shard1-b.example.com:27018,shard1-c.example.com:27018\");\nsh.addShard(\"shard2ReplSet/shard2-a.example.com:27018,shard2-b.example.com:27018,shard2-c.example.com:27018\");\nsh.addShard(\"shard3ReplSet/shard3-a.example.com:27018,shard3-b.example.com:27018,shard3-c.example.com:27018\");\n\n// 3. Enable sharding for database\nsh.enableSharding(\"ecommerce\");\n\n// 4. Choose shard key and shard collection\n// Shard key determines how data is distributed\ndb.orders.createIndex({ customerId: 1, orderDate: 1 }); // Compound shard key\nsh.shardCollection(\"ecommerce.orders\", { customerId: 1, orderDate: 1 });\n\n// 5. Shard key selection examples\nconst shardKeyStrategies = {\n    userId: {\n        pros: [\"Even distribution if users are evenly distributed\", \"Queries by user are efficient\"],\n        cons: [\"Hotspots if some users are very active\", \"Range queries may hit multiple shards\"]\n    },\n    timestamp: {\n        pros: [\"Good for time-series data\", \"Chronological queries are efficient\"],\n        cons: [\"All writes go to one shard (latest time)\", \"Creates hotspots\"]\n    },\n    hashedUserId: {\n        pros: [\"Even distribution guaranteed\", \"Eliminates hotspots\"],\n        cons: [\"Range queries hit all shards\", \"No query locality\"]\n    },\n    compound: {\n        pros: [\"Balanced distribution and query efficiency\", \"Supports both equality and range queries\"],\n        cons: [\"More complex to design\", \"Must include shard key in queries\"]\n    }\n};\n\n// 6. Monitoring sharded cluster\nsh.status(); // Overall cluster status\ndb.stats(); // Database statistics across shards\ndb.collection.getShardDistribution(); // Data distribution per shard\n\n// 7. Application considerations for sharding\nconst mongoose = require('mongoose');\n\n// Connect to mongos routers\nmongoose.connect('mongodb://mongos1.example.com:27017,mongos2.example.com:27017/ecommerce');\n\n// Queries must include shard key for efficiency\nconst Order = mongoose.model('Order', orderSchema);\n\n// Efficient query (includes shard key)\nconst userOrders = await Order.find({\n    customerId: userId, // Shard key field\n    status: 'pending'\n});\n\n// Inefficient query (missing shard key - scatter-gather)\nconst expensiveOrders = await Order.find({\n    amount: { $gt: 1000 } // No shard key - hits all shards\n});\n```\n\n**Architecture Comparison:**\n\n| Aspect | Replication | Sharding |\n|--------|-------------|----------|\n| **Primary Purpose** | High availability, data redundancy | Horizontal scaling, increased capacity |\n| **Data Distribution** | Same data on all nodes | Different data on each shard |\n| **Scaling Type** | Vertical (read scaling) | Horizontal (read + write scaling) |\n| **Complexity** | Low to Medium | High |\n| **Failure Handling** | Automatic failover | Depends on shard and replica set health |\n| **Query Routing** | Client chooses read preference | Mongos routes based on shard key |\n| **Use Case** | Small to medium datasets | Large datasets (> TB) |\n\n**Replication Components:**\n\n| Component | Role | Characteristics |\n|-----------|------|----------------|\n| **Primary** | Accepts all writes | Only one per replica set |\n| **Secondary** | Replicates from primary | Can serve reads (with read preference) |\n| **Arbiter** | Voting only, no data | Helps with election, minimal resources |\n| **Hidden** | Data replica, no reads | Backup, analytics without affecting production |\n| **Delayed** | Delayed replication | Protection against operator errors |\n\n**Sharding Components:**\n\n| Component | Role | Characteristics |\n|-----------|------|----------------|\n| **Mongos** | Query router | Directs queries to appropriate shards |\n| **Config Servers** | Metadata storage | Store cluster metadata, shard mappings |\n| **Shards** | Data storage | Usually replica sets, store data chunks |\n| **Shard Key** | Distribution strategy | Determines how data is partitioned |\n\n```javascript\n// Combined Architecture - Sharded Cluster with Replica Sets\nconst combinedArchitecture = {\n    configServers: {\n        type: \"Replica Set\",\n        members: 3,\n        purpose: \"Store cluster metadata\",\n        availability: \"High (replica set)\"\n    },\n    mongosRouters: {\n        count: \"2-3 (load balanced)\",\n        purpose: \"Query routing and aggregation\",\n        scaling: \"Add more for higher connection load\"\n    },\n    shards: [\n        {\n            name: \"shard1\",\n            type: \"Replica Set\",\n            members: 3,\n            dataRange: \"customerId: 1-1000000\",\n            purpose: \"Store data chunks + high availability\"\n        },\n        {\n            name: \"shard2\",\n            type: \"Replica Set\",\n            members: 3,\n            dataRange: \"customerId: 1000001-2000000\",\n            purpose: \"Store data chunks + high availability\"\n        }\n    ],\n    benefits: [\n        \"Horizontal scaling (sharding)\",\n        \"High availability (replica sets)\",\n        \"Read scaling (read from secondaries)\",\n        \"Automatic failover within each shard\"\n    ]\n};\n\n// Application design considerations\nconst designPatterns = {\n    shardKeyDesign: {\n        principles: [\n            \"High cardinality (many possible values)\",\n            \"Even distribution (avoid hotspots)\",\n            \"Query locality (related data together)\",\n            \"Immutable (cannot change easily)\"\n        ],\n        antiPatterns: [\n            \"Monotonic values (timestamps, counters)\",\n            \"Low cardinality (gender, status)\",\n            \"Uneven distribution patterns\"\n        ]\n    },\n    readWritePatterns: {\n        reads: {\n            includeShardKey: \"Targets specific shard(s)\",\n            withoutShardKey: \"Scatter-gather across all shards\",\n            readPreference: \"Balance between consistency and performance\"\n        },\n        writes: {\n            withShardKey: \"Routed to appropriate shard\",\n            transactions: \"Limited to single shard or use distributed transactions\"\n        }\n    }\n};\n```\n\n**When to Use Each Architecture:**\n\n| Scenario | Replication | Sharding | Both |\n|----------|-------------|----------|------|\n| **High Availability Required** | ✅ Essential | ❌ Not primary purpose | ✅ Best of both |\n| **Read Scaling** | ✅ Read from secondaries | ✅ Distribute across shards | ✅ Maximum read capacity |\n| **Write Scaling** | ❌ Limited to primary | ✅ Distribute across shards | ✅ Highest write capacity |\n| **Dataset < 1TB** | ✅ Sufficient | ❌ Overkill | ❌ Unnecessary complexity |\n| **Dataset > 10TB** | ❌ Single server limits | ✅ Necessary | ✅ Production standard |\n| **Global Distribution** | ✅ Regional replicas | ✅ Geographic sharding | ✅ Optimal solution |\n| **Development/Testing** | ✅ Simple setup | ❌ Too complex | ❌ Replication sufficient |\n\n**Best Practices:**\n\n1. **Start with Replication**: Always use replica sets, even for single-server deployments\n2. **Plan Shard Key Carefully**: Cannot be changed easily after sharding\n3. **Monitor Shard Balance**: Ensure even data distribution\n4. **Use Appropriate Read Preferences**: Balance consistency vs performance\n5. **Test Failover Scenarios**: Practice disaster recovery procedures\n6. **Monitor Performance**: Track query performance across shards\n7. **Consider Zones**: Use zone sharding for geographic distribution",
    "difficulty": "Expert",
    "category": "MongoDB Architecture",
    "database": "MongoDB",
    "tags": [
      "MongoDB",
      "Sharding",
      "Replication",
      "Architecture",
      "Scaling"
    ]
  }
]