[
    {
        "id": 1,
        "question": "What is Node.js and what makes it unique for server-side development?",
        "solution": "Node.js is an **open-source, cross-platform, back-end JavaScript runtime environment** that executes JavaScript code outside a web browser. It's built on **Chrome's V8 JavaScript engine**.\n\n**Key unique features:**\n- **Non-blocking, event-driven I/O model** - makes it efficient for I/O-intensive operations\n- **Single-threaded** but handles concurrency through the event loop\n- **Cross-platform** - runs on Windows, macOS, and Linux\n- **NPM ecosystem** - largest package repository\n- **Same language for frontend and backend** - JavaScript everywhere\n\nNode.js allows developers to use JavaScript for server-side scripting, building scalable network applications, and command-line tools.",
        "difficulty": "Easy",
        "category": "Core Concepts"
    },
    {
        "id": 2,
        "question": "Explain the Event Loop in Node.js and its different phases.",
        "solution": "The **event loop** is the core mechanism in Node.js that enables non-blocking, asynchronous behavior in a single-threaded environment.\n\n**How it works:**\n1. **Call stack** executes synchronous code\n2. **Asynchronous operations** are offloaded to system APIs\n3. **Callbacks** are registered for these operations\n4. Event loop continues processing while operations run in background\n5. Completed operations' callbacks are placed in **callback queue**\n6. Event loop moves callbacks from queue to call stack when stack is empty\n\n**Event Loop Phases:**\n1. **Timers** - Executes `setTimeout()` and `setInterval()` callbacks\n2. **Pending Callbacks** - Executes I/O callbacks deferred to next iteration\n3. **Poll** - Fetches new I/O events and executes callbacks (most critical phase)\n4. **Check** - Executes `setImmediate()` callbacks\n5. **Close Callbacks** - Executes 'close' event handlers\n\n**Microtasks** (processed between phases):\n- `process.nextTick()` - highest priority\n- Promise callbacks - after nextTick but before next phase",
        "difficulty": "Medium",
        "category": "Event Loop"
    },
    {
        "id": 3,
        "question": "What's the difference between blocking and non-blocking I/O? Provide code examples.",
        "solution": "**Blocking I/O:**\n- Program **stops executing** and waits for I/O operation to complete\n- Entire thread becomes idle during operation\n- Poor performance for server applications\n\n**Non-Blocking I/O:**\n- Program **continues executing** while I/O runs in background\n- Uses callbacks to handle results when ready\n- Better performance and concurrency\n\n```javascript\nimport fs from 'fs';\n\n// Blocking (Synchronous)\ntry {\n  console.log('Before sync read');\n  const dataSync = fs.readFileSync('file.txt', 'utf8'); // BLOCKS HERE\n  console.log('Sync data:', dataSync.substring(0, 20));\n  console.log('After sync read');\n} catch (err) {\n  console.error('Sync error:', err);\n}\n\n// Non-Blocking (Asynchronous)\nconsole.log('Before async read');\nfs.readFile('file.txt', 'utf8', (err, dataAsync) => { // DOESN'T BLOCK\n  if (err) {\n    console.error('Async error:', err);\n    return;\n  }\n  console.log('Async data:', dataAsync.substring(0, 20));\n});\nconsole.log('After async read call'); // Logs before async content\n```\n\nIn non-blocking example, \"After async read call\" logs before \"Async data\" because `readFile` doesn't block the main thread.",
        "difficulty": "Medium",
        "category": "I/O Operations"
    },
    {
        "id": 4,
        "question": "Explain the different types of modules in Node.js and how to use them.",
        "solution": "Node.js has **three types of modules:**\n\n**1. Core Modules** - Built-in with Node.js installation:\n```javascript\nimport fs from 'fs';          // File system\nimport http from 'http';      // HTTP server/client\nimport path from 'path';      // File path utilities\nimport crypto from 'crypto';  // Cryptographic functionality\n```\n\n**2. Local Modules** - Created in your project:\n```javascript\n// utils.js\nexport function add(a, b) {\n  return a + b;\n}\nexport const PI = 3.14;\n\n// app.js\nimport { add, PI } from './utils.js';\nconsole.log(add(5, 3)); // 8\n```\n\n**3. Third-Party Modules** - Installed via npm:\n```javascript\n// Install: npm install express lodash\nimport express from 'express';\nimport _ from 'lodash';\n\nconst app = express();\nconst numbers = _.shuffle([1, 2, 3, 4, 5]);\n```\n\n**Module Benefits:**\n- **Code organization** and reusability\n- **Namespace isolation** - avoid conflicts\n- **Dependency management** through package.json\n- **Lazy loading** - modules loaded when needed",
        "difficulty": "Easy",
        "category": "Modules"
    },
    {
        "id": 5,
        "question": "Compare CommonJS and ES Modules in Node.js. When would you use each?",
        "solution": "**CommonJS vs ES Modules:**\n\n| Feature | CommonJS | ES Modules |\n|---------|----------|------------|\n| **Syntax** | `require()` / `module.exports` | `import` / `export` |\n| **Loading** | Synchronous (blocking) | Asynchronous (non-blocking) |\n| **File Extension** | `.js`, `.cjs` | `.mjs` or `.js` with `\"type\": \"module\"` |\n| **Browser Support** | No (needs bundler) | Yes (native) |\n| **Tree Shaking** | No | Yes (better optimization) |\n| **`this` Context** | Refers to `exports` object | `undefined` at top level |\n| **Strict Mode** | Optional | Default |\n\n**CommonJS Example:**\n```javascript\n// utils.js\nfunction add(a, b) { return a + b; }\nmodule.exports = { add };\n\n// app.js\nconst { add } = require('./utils');\n```\n\n**ES Modules Example:**\n```javascript\n// utils.js\nexport function add(a, b) { return a + b; }\nexport default { add };\n\n// app.js\nimport { add } from './utils.js';\n```\n\n**When to use:**\n- **CommonJS**: Legacy projects, older Node.js versions, when synchronous loading is needed\n- **ES Modules**: New projects, modern Node.js (14+), better tree-shaking, browser compatibility",
        "difficulty": "Medium",
        "category": "Modules"
    },
    {
        "id": 6,
        "question": "What are package.json and package-lock.json? What's the difference?",
        "solution": "**package.json:**\n- **Metadata file** for Node.js project\n- Lists **dependencies** and their version ranges\n- Contains project info (name, version, description, author)\n- Defines **scripts** (`npm run <script-name>`)\n- Created manually with `npm init`\n\n**package-lock.json:**\n- **Automatically generated** by npm\n- Records **exact versions** of all dependencies (including transitive)\n- Ensures **deterministic builds** - same versions everywhere\n- Contains dependency tree with integrity hashes\n- **Should be committed** to version control\n\n```json\n// package.json\n{\n  \"name\": \"my-app\",\n  \"version\": \"1.0.0\",\n  \"scripts\": {\n    \"start\": \"node index.js\",\n    \"test\": \"jest\"\n  },\n  \"dependencies\": {\n    \"express\": \"^4.17.1\",    // ^ allows minor updates\n    \"lodash\": \"~4.17.20\"     // ~ allows patch updates only\n  },\n  \"devDependencies\": {\n    \"nodemon\": \"^2.0.7\"      // Development only\n  }\n}\n```\n\n**Key Differences:**\n- **package.json**: Human-readable, version ranges, project metadata\n- **package-lock.json**: Machine-generated, exact versions, prevents \"works on my machine\" issues\n\n**Dependencies vs DevDependencies:**\n- **dependencies**: Required for app to run in production\n- **devDependencies**: Only needed for development (testing, bundling, linting)",
        "difficulty": "Medium",
        "category": "Package Management"
    },
    {
        "id": 7,
        "question": "What are callbacks in Node.js? Explain the error-first callback pattern.",
        "solution": "**Callbacks** are functions passed as arguments to other functions, invoked to complete an action or handle the result of an asynchronous operation.\n\n**Error-First Callback Pattern:**\nNode.js convention where the **first parameter** is always an error object (or `null` if no error).\n\n```javascript\n// Error-first callback signature\nfunction callback(err, result) {\n  if (err) {\n    // Handle error\n    console.error('Error:', err.message);\n    return;\n  }\n  // Process successful result\n  console.log('Success:', result);\n}\n\n// Example with file reading\nimport fs from 'fs';\n\nfs.readFile('config.txt', 'utf8', (err, data) => {\n  if (err) {\n    console.error('Failed to read file:', err.message);\n    return;\n  }\n  console.log('File content:', data);\n});\n\n// Simple callback example\nfunction greet(name, callback) {\n  console.log('Hello, ' + name + '!');\n  callback();\n}\n\ngreet('Alice', () => {\n  console.log('Greeting complete.');\n});\n```\n\n**Callback Hell Problem:**\n```javascript\n// Nested callbacks become hard to read and maintain\nreadFile('file1.txt', (err1, data1) => {\n  if (err1) return console.error(err1);\n  processData(data1, (err2, processed) => {\n    if (err2) return console.error(err2);\n    writeFile('file2.txt', processed, (err3) => {\n      if (err3) return console.error(err3);\n      console.log('All operations complete!');\n    });\n  });\n});\n```\n\n**Best Practices:**\n- Always check for errors first\n- Return early on errors to avoid nested code\n- Use named functions instead of anonymous callbacks for better readability",
        "difficulty": "Easy",
        "category": "Asynchronous Programming"
    },
    {
        "id": 8,
        "question": "Explain Promises in Node.js. How do they solve callback hell?",
        "solution": "**Promises** represent the eventual completion (or failure) of an asynchronous operation and its resulting value.\n\n**Promise States:**\n1. **Pending** - Initial state, neither fulfilled nor rejected\n2. **Fulfilled (Resolved)** - Operation completed successfully\n3. **Rejected** - Operation failed with an error\n\n**How Promises Solve Callback Hell:**\n- **Chaining** with `.then()` instead of nesting\n- **Single error handler** with `.catch()`\n- **Flatter code structure**\n\n```javascript\nimport fs from 'fs/promises';\n\n// Callback Hell\nfs.readFile('file1.txt', (err1, data1) => {\n  if (err1) return console.error(err1);\n  processData(data1, (err2, processed) => {\n    if (err2) return console.error(err2);\n    fs.writeFile('file2.txt', processed, (err3) => {\n      if (err3) return console.error(err3);\n      console.log('Complete!');\n    });\n  });\n});\n\n// Promise Chain - Much Cleaner!\nfs.readFile('file1.txt', 'utf8')\n  .then(data1 => processData(data1))\n  .then(processed => fs.writeFile('file2.txt', processed))\n  .then(() => console.log('Complete!'))\n  .catch(err => console.error('Error:', err.message));\n\n// Creating Promises\nfunction delay(ms) {\n  return new Promise((resolve, reject) => {\n    setTimeout(() => {\n      resolve(`Delayed by ${ms}ms`);\n    }, ms);\n  });\n}\n\ndelay(1000)\n  .then(result => console.log(result))\n  .catch(err => console.error(err));\n```\n\n**Promise Methods:**\n- **Promise.all()** - Wait for all promises to resolve\n- **Promise.race()** - Wait for first promise to settle\n- **Promise.allSettled()** - Wait for all to settle (resolve or reject)",
        "difficulty": "Medium",
        "category": "Asynchronous Programming"
    },
    {
        "id": 9,
        "question": "What is async/await? How does it improve upon Promises?",
        "solution": "**async/await** is syntactic sugar built on top of Promises, making asynchronous code look and behave like synchronous code.\n\n**Key Features:**\n- **`async`** keyword makes function return a Promise\n- **`await`** keyword pauses execution until Promise resolves\n- **`await`** can only be used inside `async` functions\n- Use **`try...catch`** for error handling\n\n**Comparison:**\n\n```javascript\nimport fs from 'fs/promises';\n\n// Promise Chain\nfunction processFilePromise(filePath) {\n  return fs.readFile(filePath, 'utf8')\n    .then(data => {\n      console.log('File content:', data.substring(0, 30));\n      return data.toUpperCase();\n    })\n    .then(upperData => {\n      return fs.writeFile('output.txt', upperData);\n    })\n    .then(() => {\n      return 'Success!';\n    })\n    .catch(err => {\n      console.error('Error:', err.message);\n      throw err;\n    });\n}\n\n// Async/Await - Much More Readable!\nasync function processFileAsync(filePath) {\n  try {\n    const data = await fs.readFile(filePath, 'utf8');\n    console.log('File content:', data.substring(0, 30));\n    \n    const upperData = data.toUpperCase();\n    await fs.writeFile('output.txt', upperData);\n    \n    return 'Success!';\n  } catch (err) {\n    console.error('Error:', err.message);\n    throw err;\n  }\n}\n\n// Sequential vs Parallel operations\nasync function sequentialOperations() {\n  const result1 = await operation1(); // Waits for completion\n  const result2 = await operation2(); // Starts after result1\n  return [result1, result2];\n}\n\nasync function parallelOperations() {\n  const [result1, result2] = await Promise.all([\n    operation1(), // Both start simultaneously\n    operation2()\n  ]);\n  return [result1, result2];\n}\n```\n\n**Benefits:**\n- **Cleaner syntax** - looks like synchronous code\n- **Better error handling** - standard try/catch\n- **Easier debugging** - clearer stack traces\n- **No callback hell or promise chaining**",
        "difficulty": "Medium",
        "category": "Asynchronous Programming"
    },
    {
        "id": 10,
        "question": "In JavaScript, if you have an API call and a Promise, which one executes first?",
        "solution": "This is a **trick question**! An API call **IS** a Promise. When you make an API call using modern methods like `fetch()`, it returns a Promise.\n\n**The Real Question:** Which Promise resolves first?\n\nWhen you have multiple Promises (including API calls), the one that **resolves first** will have its `.then()` callback executed first. The order depends on which asynchronous operation completes first.\n\n```javascript\n// Both return Promises\nconst apiCall = fetch('https://api.example.com/data'); // Returns Promise\nconst customPromise = new Promise(resolve => {\n  setTimeout(() => resolve('Custom result'), 100);\n});\n\n// Race condition - whoever finishes first wins\nPromise.race([apiCall, customPromise])\n  .then(result => console.log('First to complete:', result));\n\n// Both will execute, order depends on completion time\napiCall.then(response => console.log('API completed'));\ncustomPromise.then(result => console.log('Custom Promise completed'));\n```\n\n**Event Loop Behavior:**\n1. **Execution Start** - Synchronous code runs immediately\n2. **Tasks Initiated** - Both Promises start (non-blocking)\n3. **Microtask Queue** - Resolved Promise callbacks are queued\n4. **Execution Order** - Determined by which Promise resolves first\n\n**Key Points:**\n- API calls using `fetch()`, `axios`, etc. return Promises\n- Multiple Promises execute **concurrently**\n- Resolution order depends on **completion time**\n- All callbacks go to the same **Microtask Queue**\n- It's a **race condition** between async operations",
        "difficulty": "Medium",
        "category": "Asynchronous Programming"
    },
    {
        "id": 11,
        "question": "What are Streams in Node.js? Explain the different types and their benefits.",
        "solution": "**Streams** are objects that let you read or write data continuously, piece by piece (in chunks), without loading entire data into memory at once.\n\n**Types of Streams:**\n\n**1. Readable Streams** - Read data from source:\n```javascript\nimport fs from 'fs';\n\nconst readable = fs.createReadStream('large-file.txt');\nreadable.on('data', chunk => {\n  console.log('Received chunk:', chunk.length, 'bytes');\n});\nreadable.on('end', () => {\n  console.log('Reading complete');\n});\n```\n\n**2. Writable Streams** - Write data to destination:\n```javascript\nconst writable = fs.createWriteStream('output.txt');\nwritable.write('Hello ');\nwritable.write('World!');\nwritable.end(); // Signal end of writing\n```\n\n**3. Duplex Streams** - Both readable and writable:\n```javascript\nimport net from 'net';\n\nconst socket = new net.Socket(); // TCP socket is duplex\nsocket.write('data to server');\nsocket.on('data', data => console.log('from server:', data));\n```\n\n**4. Transform Streams** - Modify data as it passes through:\n```javascript\nimport zlib from 'zlib';\n\nconst gzip = zlib.createGzip(); // Compress data\nfs.createReadStream('input.txt')\n  .pipe(gzip)\n  .pipe(fs.createWriteStream('output.txt.gz'));\n```\n\n**Benefits:**\n- **Memory Efficiency** - Process data without loading all into memory\n- **Time Efficiency** - Start processing as soon as first chunk arrives\n- **Backpressure Handling** - Automatically manages flow control\n- **Composability** - Can pipe streams together\n\n**Piping Example:**\n```javascript\n// Copy and compress file efficiently\nfs.createReadStream('large-file.txt')\n  .pipe(zlib.createGzip())\n  .pipe(fs.createWriteStream('large-file.txt.gz'));\n\nconsole.log('Processing started (non-blocking)');\n```\n\n**Use Cases:**\n- File uploads/downloads\n- Log processing\n- Data transformation\n- Real-time data processing",
        "difficulty": "Medium",
        "category": "Streams"
    },
    {
        "id": 12,
        "question": "How do you handle errors in Node.js for different types of operations?",
        "solution": "Error handling in Node.js varies based on whether operations are **synchronous** or **asynchronous**.\n\n**1. Synchronous Errors** - Use `try...catch`:\n```javascript\ntry {\n  const result = JSON.parse(\"{'invalid json'}\"); // Throws error\n  console.log(result);\n} catch (error) {\n  console.error('Sync error:', error.message);\n}\n```\n\n**2. Callback Errors** - Error-first callback pattern:\n```javascript\nimport fs from 'fs';\n\nfs.readFile('nonexistent.txt', (err, data) => {\n  if (err) {\n    console.error('Callback error:', err.message);\n    return; // Important: return after handling error\n  }\n  console.log('Data:', data);\n});\n```\n\n**3. Promise Errors** - Use `.catch()`:\n```javascript\nsomePromiseFunction()\n  .then(result => {\n    console.log('Success:', result);\n  })\n  .catch(error => {\n    console.error('Promise error:', error.message);\n  });\n```\n\n**4. Async/Await Errors** - Use `try...catch`:\n```javascript\nasync function fetchData() {\n  try {\n    const data = await someAsyncOperation();\n    console.log('Data:', data);\n  } catch (error) {\n    console.error('Async/await error:', error.message);\n  }\n}\n```\n\n**5. Global Error Handlers** - Last resort:\n```javascript\n// Uncaught exceptions\nprocess.on('uncaughtException', (error) => {\n  console.error('UNCAUGHT EXCEPTION! Shutting down...');\n  console.error(error.stack);\n  process.exit(1); // Exit with failure code\n});\n\n// Unhandled promise rejections\nprocess.on('unhandledRejection', (reason, promise) => {\n  console.error('UNHANDLED PROMISE REJECTION!');\n  console.error('Reason:', reason);\n  // Consider exiting process\n});\n```\n\n**Best Practices:**\n- **Always handle errors** - don't let them be swallowed\n- **Use specific error types** when possible\n- **Log errors effectively** for debugging\n- **Fail fast** - handle errors at the source\n- **Graceful degradation** - provide fallbacks when possible\n- **Monitor errors** in production environments",
        "difficulty": "Medium",
        "category": "Error Handling"
    },
    {
        "id": 13,
        "question": "What is Express.js and what are its key features?",
        "solution": "**Express.js** is a minimal and flexible **Node.js web application framework** that provides a robust set of features for building web and mobile applications.\n\n**Key Features:**\n\n**1. Routing** - Define how app responds to client requests:\n```javascript\nimport express from 'express';\nconst app = express();\n\n// Different HTTP methods and routes\napp.get('/', (req, res) => {\n  res.send('Hello World!');\n});\n\napp.post('/users', (req, res) => {\n  res.json({ message: 'User created' });\n});\n\napp.put('/users/:id', (req, res) => {\n  const userId = req.params.id;\n  res.json({ message: `User ${userId} updated` });\n});\n```\n\n**2. Middleware** - Functions that execute during request-response cycle:\n```javascript\n// Application-level middleware\napp.use((req, res, next) => {\n  console.log(`${req.method} ${req.url}`);\n  next(); // Pass control to next middleware\n});\n\n// Built-in middleware\napp.use(express.json()); // Parse JSON bodies\napp.use(express.static('public')); // Serve static files\n```\n\n**3. Template Engines** - Render dynamic HTML:\n```javascript\napp.set('view engine', 'pug');\napp.get('/profile', (req, res) => {\n  res.render('profile', { user: { name: 'John' } });\n});\n```\n\n**4. HTTP Utility Methods** - Convenient response methods:\n```javascript\napp.get('/api/data', (req, res) => {\n  res.status(200).json({ data: 'example' });\n  // res.redirect('/login');\n  // res.cookie('session', 'abc123');\n  // res.download('/files/report.pdf');\n});\n```\n\n**5. Error Handling** - Centralized error management:\n```javascript\n// Error-handling middleware (4 parameters)\napp.use((err, req, res, next) => {\n  console.error(err.stack);\n  res.status(500).send('Something broke!');\n});\n```\n\n**Benefits:**\n- **Minimalist** - unopinionated, flexible\n- **Fast development** - less boilerplate code\n- **Extensive middleware ecosystem**\n- **RESTful API support**\n- **Large community and documentation**",
        "difficulty": "Easy",
        "category": "Express.js"
    },
    {
        "id": 14,
        "question": "Explain middleware in Express.js. What are the different types?",
        "solution": "**Middleware** functions execute during the request-response lifecycle. Each middleware has access to `req`, `res`, and `next` function.\n\n**Types of Middleware:**\n\n**1. Application-Level Middleware** - Bound to app instance:\n```javascript\nimport express from 'express';\nconst app = express();\n\n// Executed for all requests\napp.use((req, res, next) => {\n  console.log(`${new Date().toISOString()} - ${req.method} ${req.url}`);\n  next();\n});\n\n// Executed for specific route\napp.use('/api', (req, res, next) => {\n  // Only for routes starting with /api\n  console.log('API request');\n  next();\n});\n```\n\n**2. Router-Level Middleware** - Bound to router instance:\n```javascript\nconst router = express.Router();\n\n// Middleware specific to this router\nrouter.use((req, res, next) => {\n  console.log('Router middleware');\n  next();\n});\n\nrouter.get('/users', (req, res) => {\n  res.json({ users: [] });\n});\n\napp.use('/api', router);\n```\n\n**3. Error-Handling Middleware** - Has 4 parameters:\n```javascript\n// Must have 4 parameters (err, req, res, next)\napp.use((err, req, res, next) => {\n  console.error('Error occurred:', err.message);\n  res.status(500).json({\n    error: 'Internal Server Error',\n    message: err.message\n  });\n});\n\n// Trigger error\napp.get('/error', (req, res, next) => {\n  const error = new Error('Something went wrong!');\n  next(error); // Pass error to error handler\n});\n```\n\n**4. Built-in Middleware** - Provided by Express:\n```javascript\n// Parse JSON request bodies\napp.use(express.json());\n\n// Parse URL-encoded bodies\napp.use(express.urlencoded({ extended: true }));\n\n// Serve static files\napp.use(express.static('public'));\n```\n\n**5. Third-Party Middleware** - Installed via npm:\n```javascript\nimport cors from 'cors';           // Enable CORS\nimport helmet from 'helmet';       // Security headers\nimport morgan from 'morgan';       // HTTP request logger\n\napp.use(cors());\napp.use(helmet());\napp.use(morgan('combined'));\n```\n\n**Middleware Execution Order:**\n```javascript\napp.use(middleware1); // Executes first\napp.use(middleware2); // Executes second\napp.get('/', middleware3, (req, res) => { // Route-specific\n  res.send('Hello');\n});\n```\n\n**Important Notes:**\n- Always call `next()` to pass control (except in final handler)\n- Middleware executes in the order it's defined\n- Error middleware must have 4 parameters\n- Use `next(error)` to trigger error handling",
        "difficulty": "Medium",
        "category": "Express.js"
    },
    {
        "id": 15,
        "question": "What are Buffers in Node.js? How do you work with binary data?",
        "solution": "**Buffers** in Node.js are global objects used to represent a **fixed-length sequence of bytes**. They're designed to handle **binary data** directly, especially when dealing with TCP streams, file system operations, or other contexts where raw data is involved.\n\n**Key Characteristics:**\n- **Fixed-size memory allocation** outside the V8 JavaScript heap\n- Can be converted to/from strings using specified encodings\n- Provides methods for reading from and writing to the buffer\n- Essential for handling binary data in Node.js\n\n**Creating Buffers:**\n```javascript\n// Create buffer from string\nconst bufFromString = Buffer.from('Hello Node.js!', 'utf8');\nconsole.log('Buffer from string:', bufFromString);\nconsole.log('Buffer to string:', bufFromString.toString('utf8')); // Hello Node.js!\nconsole.log('Buffer to hex:', bufFromString.toString('hex'));   // 48656c6c6f204e6f64652e6a7321\n\n// Create zero-filled buffer (safer)\nconst zeroFilledBuf = Buffer.alloc(10);\nconsole.log('Zero-filled buffer:', zeroFilledBuf); // <Buffer 00 00 00 00 00 00 00 00 00 00>\n\n// Create uninitialized buffer (faster but potentially unsafe)\nconst uninitializedBuf = Buffer.allocUnsafe(10);\nconsole.log('Uninitialized buffer:', uninitializedBuf); // Content is unpredictable\nuninitializedBuf.fill(0); // Fill with zeros if needed\n```\n\n**Working with Buffers:**\n```javascript\n// Writing to buffer\nconst buffer = Buffer.alloc(10);\nbuffer.write('abc', 0, 'utf8'); // Write \"abc\" starting at index 0\nconsole.log('Buffer after write:', buffer); // <Buffer 61 62 63 00 00 00 00 00 00 00>\nconsole.log('String from buffer:', buffer.toString('utf8', 0, 3)); // abc\n\n// Buffer concatenation\nconst buf1 = Buffer.from('Hello ');\nconst buf2 = Buffer.from('World!');\nconst combined = Buffer.concat([buf1, buf2]);\nconsole.log('Combined:', combined.toString()); // Hello World!\n```\n\n**Common Use Cases:**\n- **File I/O operations** - Reading/writing binary files\n- **Network communications** - TCP streams, HTTP bodies\n- **Cryptographic operations** - Hash functions, encryption\n- **Image/media processing** - Handling binary media data\n\n**Important Notes:**\n- Use `Buffer.alloc()` for safer zero-filled buffers\n- Use `Buffer.allocUnsafe()` only when performance is critical and you'll fill the buffer\n- Always specify encoding when converting to/from strings\n- Buffers are fixed-size once created",
        "difficulty": "Medium",
        "category": "Core Concepts"
    },
    {
        "id": 16,
        "question": "Explain the child_process module. What are the different methods and when to use each?",
        "solution": "The **child_process module** in Node.js provides the ability to create and manage **child processes**. This is useful for executing external commands, performing CPU-intensive tasks in separate processes, and leveraging multi-core processors.\n\n**Common Methods:**\n\n**1. `spawn()`** - Launches a new process with streaming I/O:\n```javascript\nimport { spawn } from 'child_process';\n\n// Best for large data or long-running processes\nconst ls = spawn('ls', ['-lh', '.']); // On Windows: 'dir'\n\nls.stdout.on('data', (data) => {\n  console.log(`stdout: ${data}`);\n});\n\nls.stderr.on('data', (data) => {\n  console.error(`stderr: ${data}`);\n});\n\nls.on('close', (code) => {\n  console.log(`Process exited with code ${code}`);\n});\n\nls.on('error', (err) => {\n  console.error('Failed to start subprocess:', err);\n});\n```\n\n**2. `exec()`** - Runs command in shell, buffers output:\n```javascript\nimport { exec } from 'child_process';\n\n// Good for short commands, has buffer limit\nexec('ls -lh', (error, stdout, stderr) => {\n  if (error) {\n    console.error(`exec error: ${error}`);\n    return;\n  }\n  console.log(`stdout: ${stdout}`);\n  if (stderr) console.error(`stderr: ${stderr}`);\n});\n```\n\n**3. `execFile()`** - Runs executable directly without shell:\n```javascript\nimport { execFile } from 'child_process';\n\n// Safer and more efficient than exec()\nexecFile('node', ['--version'], (error, stdout, stderr) => {\n  if (error) {\n    console.error(`execFile error: ${error}`);\n    return;\n  }\n  console.log(`Node.js version: ${stdout}`);\n});\n```\n\n**4. `fork()`** - Creates new Node.js processes with IPC:\n```javascript\nimport { fork } from 'child_process';\n\n// Special for Node.js processes with inter-process communication\nconst child = fork('worker.js');\n\nchild.on('message', (message) => {\n  console.log('Message from child:', message);\n});\n\nchild.send({ hello: 'from parent' });\n\n// worker.js\n// process.on('message', (message) => {\n//   console.log('Message from parent:', message);\n//   process.send({ world: 'from child' });\n// });\n```\n\n**When to Use Each:**\n- **`spawn()`**: Large data streams, long-running processes, real-time output\n- **`exec()`**: Simple shell commands, small output, quick operations\n- **`execFile()`**: Running specific executables, better security than exec()\n- **`fork()`**: CPU-intensive tasks, Node.js worker processes, IPC communication\n\n**Benefits:**\n- **Offload CPU-intensive work** from main thread\n- **Execute system commands** and scripts\n- **Leverage multi-core processors**\n- **Isolate processes** for better error handling",
        "difficulty": "Medium",
        "category": "Child Processes"
    },
    {
        "id": 17,
        "question": "What is connection pooling in Node.js? How do you implement it with databases?",
        "solution": "**Connection pooling** is a technique used to manage and reuse database connections to improve performance and scalability. Instead of creating a new connection for every database operation, a **pool** of pre-established connections is maintained.\n\n**Why Use Connection Pooling?**\n- **Improved Performance**: Reusing existing connections is faster than creating new ones\n- **Resource Management**: Prevents database server from being overwhelmed\n- **Scalability**: Handles more concurrent users efficiently\n- **Reduced Latency**: Eliminates connection overhead for each request\n\n**How It Works:**\n1. Pool maintains a set number of open database connections\n2. When a request needs database access, it borrows a connection from the pool\n3. After operation completes, connection is returned to the pool for reuse\n4. Pool manages connection lifecycle (creation, validation, cleanup)\n\n**Implementation with MySQL:**\n```javascript\n// db.js - Connection pool setup\nconst mysql = require('mysql2');\n\nconst pool = mysql.createPool({\n  host: 'localhost',\n  user: 'root',\n  password: 'your_password',\n  database: 'your_database',\n  waitForConnections: true,\n  connectionLimit: 10,     // Max connections in pool\n  queueLimit: 0           // No limit on queued requests\n});\n\nmodule.exports = pool;\n```\n\n**Using the Pool:**\n```javascript\n// app.js - Using connection pool\nconst express = require('express');\nconst pool = require('./db');\n\nconst app = express();\n\napp.get('/users', (req, res) => {\n  // Get connection from pool\n  pool.getConnection((err, connection) => {\n    if (err) {\n      console.error('Error getting connection:', err);\n      return res.status(500).send('Database error');\n    }\n\n    // Execute query\n    connection.query('SELECT * FROM users', (queryErr, results) => {\n      // IMPORTANT: Always release connection back to pool\n      connection.release();\n      \n      if (queryErr) {\n        console.error('Query error:', queryErr);\n        return res.status(500).send('Query error');\n      }\n      res.json(results);\n    });\n  });\n});\n```\n\n**With Promises/Async-Await:**\n```javascript\nconst pool = mysql.createPool({\n  host: 'localhost',\n  user: 'root',\n  password: 'password',\n  database: 'testdb',\n  waitForConnections: true,\n  connectionLimit: 10,\n  queueLimit: 0\n}).promise(); // Enable promise support\n\napp.get('/users', async (req, res) => {\n  try {\n    const [rows] = await pool.execute('SELECT * FROM users');\n    res.json(rows);\n  } catch (error) {\n    console.error('Database error:', error);\n    res.status(500).send('Database error');\n  }\n});\n```\n\n**Pool Configuration Options:**\n- **connectionLimit**: Maximum number of connections in pool\n- **waitForConnections**: Wait for available connection vs throw error\n- **queueLimit**: Maximum number of queued connection requests\n- **acquireTimeout**: Time to wait for connection before timeout\n- **timeout**: Time before query timeout\n\n**Best Practices:**\n- Always release connections back to the pool\n- Set appropriate connection limits based on database capacity\n- Monitor pool usage and adjust limits as needed\n- Handle connection errors gracefully\n- Use connection validation to detect stale connections",
        "difficulty": "Medium",
        "category": "Database"
    },
    {
        "id": 18,
        "question": "What is Apache Kafka? How does it work and how is it different from RabbitMQ?",
        "solution": "**Apache Kafka** is a distributed **event streaming platform** designed to handle high-volume, real-time data streams. It's built for scenarios requiring high throughput, fault tolerance, and the ability to replay messages.\n\n**Key Components:**\n- **Producers**: Applications that send messages to Kafka\n- **Consumers**: Applications that read messages from Kafka\n- **Topics**: Categories/feeds where messages are published\n- **Partitions**: Topics split into ordered, immutable sequences\n- **Brokers**: Kafka servers that store data\n- **ZooKeeper**: Manages cluster state (newer versions moving away from this)\n\n**Data Flow:**\n```javascript\n// 1. Producer sends message to topic\n// 2. Broker stores message in partition with unique offset\n// 3. Consumer reads message by specifying topic, partition, offset\n// 4. Consumer tracks offset for resuming after failures\n```\n\n**Node.js Producer Example:**\n```javascript\nconst { Kafka } = require('kafkajs');\n\nconst kafka = new Kafka({\n  clientId: 'my-producer-app',\n  brokers: ['localhost:9092']\n});\n\nconst producer = kafka.producer();\n\nconst sendMessage = async (topic, message) => {\n  try {\n    await producer.connect();\n    await producer.send({\n      topic: topic,\n      messages: [{ value: message }]\n    });\n    console.log(`Message sent to ${topic}: ${message}`);\n  } catch (error) {\n    console.error('Error sending message:', error);\n  } finally {\n    await producer.disconnect();\n  }\n};\n\n// Send user signup event\nsendMessage('user-signups', 'New user signed up with ID 123');\n```\n\n**Node.js Consumer Example:**\n```javascript\nconst consumer = kafka.consumer({ groupId: 'my-group' });\n\nconst runConsumer = async () => {\n  await consumer.connect();\n  await consumer.subscribe({ topic: 'user-signups', fromBeginning: false });\n\n  await consumer.run({\n    eachMessage: async ({ topic, partition, message }) => {\n      console.log({\n        value: message.value.toString(),\n        topic: topic,\n        partition: partition,\n      });\n      // Process message (e.g., send welcome email)\n    },\n  });\n};\n\nrunConsumer().catch(console.error);\n```\n\n**Kafka vs RabbitMQ:**\n\n| Feature | Kafka | RabbitMQ |\n|---------|-------|----------|\n| **Paradigm** | Distributed log system (Pull model) | Traditional message broker (Push model) |\n| **Message Consumption** | Consumers pull data, track own offsets | Broker pushes messages, tracks acknowledgments |\n| **Message Retention** | Configurable retention (e.g., 7 days), allows replay | Messages deleted after consumption |\n| **Primary Use Case** | Event streaming, log aggregation, analytics | Task queues, complex routing, microservices |\n| **Topology** | Topics and Partitions | Exchanges and Queues with flexible routing |\n| **Scalability** | Extremely high throughput, horizontal scaling | Good scalability, lower throughput than Kafka |\n| **Ordering** | Per-partition ordering guaranteed | Can guarantee ordering with single consumer |\n| **Complexity** | Simpler model, more complex setup | More complex routing, easier to get started |\n\n**When to Use:**\n- **Kafka**: High-throughput event streaming, real-time analytics, log aggregation, data pipelines\n- **RabbitMQ**: Task distribution, complex routing, traditional messaging, microservice communication\n\n**Consumer Groups:**\nKafka uses consumer groups for load balancing - each message in a topic is delivered to only one consumer instance within a group, enabling horizontal scaling.",
        "difficulty": "Hard",
        "category": "Message Queues"
    },
    {
        "id": 19,
        "question": "How does Node.js handle concurrency in clusters? Explain the master-worker process model.",
        "solution": "Node.js handles concurrency in clusters using a **master-worker process model** to overcome single-threaded limitations and utilize multiple CPU cores effectively.\n\n**Master-Worker Architecture:**\n\n**Master Process:**\n- Main orchestrator and entry point\n- Listens for incoming connections\n- Distributes connections to worker processes\n- Monitors worker health and restarts failed workers\n- Manages cluster lifecycle\n\n**Worker Processes:**\n- Separate Node.js processes running application code\n- Each has its own event loop and memory space\n- Handle actual request processing\n- Run independently and concurrently\n\n**Implementation Example:**\n```javascript\n// cluster.js\nconst cluster = require('cluster');\nconst http = require('http');\nconst numCPUs = require('os').cpus().length;\n\nif (cluster.isMaster) {\n  console.log(`Master ${process.pid} is running`);\n  \n  // Fork workers equal to CPU cores\n  for (let i = 0; i < numCPUs; i++) {\n    cluster.fork();\n  }\n  \n  // Handle worker exit\n  cluster.on('exit', (worker, code, signal) => {\n    console.log(`Worker ${worker.process.pid} died`);\n    console.log('Starting a new worker');\n    cluster.fork(); // Restart failed worker\n  });\n  \n  // Monitor worker health\n  cluster.on('online', (worker) => {\n    console.log(`Worker ${worker.process.pid} is online`);\n  });\n  \n} else {\n  // Worker process\n  const server = http.createServer((req, res) => {\n    res.writeHead(200);\n    res.end(`Hello from worker ${process.pid}\\n`);\n  });\n  \n  server.listen(3000, () => {\n    console.log(`Worker ${process.pid} started`);\n  });\n}\n```\n\n**Round-Robin Load Balancing:**\nBy default, Node.js cluster uses **round-robin** approach:\n\n```javascript\n// Master distributes connections in sequence:\n// Request 1 → Worker 1\n// Request 2 → Worker 2  \n// Request 3 → Worker 3\n// Request 4 → Worker 1 (cycles back)\n```\n\n**Advanced Cluster Management:**\n```javascript\nconst cluster = require('cluster');\nconst numWorkers = process.env.NODE_ENV === 'production' ? numCPUs : 1;\n\nif (cluster.isMaster) {\n  console.log(`Master ${process.pid} starting ${numWorkers} workers`);\n  \n  // Create workers\n  for (let i = 0; i < numWorkers; i++) {\n    const worker = cluster.fork();\n    \n    // Send message to worker\n    worker.send({ cmd: 'config', data: { workerId: i } });\n  }\n  \n  // Graceful restart\n  const restartWorker = (worker) => {\n    worker.disconnect();\n    worker.kill();\n    \n    setTimeout(() => {\n      cluster.fork();\n    }, 1000);\n  };\n  \n  // Handle signals\n  process.on('SIGUSR2', () => {\n    console.log('Restarting all workers...');\n    Object.values(cluster.workers).forEach(restartWorker);\n  });\n  \n} else {\n  // Worker receives messages\n  process.on('message', (msg) => {\n    if (msg.cmd === 'config') {\n      console.log(`Worker ${process.pid} configured with ID: ${msg.data.workerId}`);\n    }\n  });\n  \n  require('./app'); // Your application code\n}\n```\n\n**Benefits:**\n- **CPU Utilization**: Uses all available CPU cores\n- **Fault Tolerance**: Failed workers are automatically restarted\n- **Load Distribution**: Requests distributed evenly across workers\n- **Zero Downtime**: Can restart workers without stopping service\n- **Scalability**: Handles more concurrent connections\n\n**Considerations:**\n- **Memory Usage**: Each worker has separate memory space\n- **Shared State**: Workers can't share memory directly (use Redis, database)\n- **Session Handling**: Use external session store for consistency\n- **Resource Coordination**: Coordinate shared resources (file locks, etc.)\n\n**Production Tools:**\n- **PM2**: Process manager with clustering, monitoring, and deployment features\n- **Forever**: Keeps processes running continuously\n- **Nodemon**: Development tool with automatic restarts\n\n**Restaurant Analogy:**\n- **Single Thread**: One chef handling all orders sequentially\n- **Cluster**: Manager (master) distributing orders to multiple chefs (workers) working simultaneously\n- **Result**: Much higher throughput and customer satisfaction",
        "difficulty": "Hard",
        "category": "Clustering"
    },
    {
        "id": 20,
        "question": "What is Jenkins? Explain CI/CD pipeline setup for Angular and Node.js applications with deployment strategies.",
        "solution": "**Jenkins** is an open-source automation server that facilitates **Continuous Integration (CI)** and **Continuous Delivery (CD)** for software development. It automates the non-human aspects of the software development lifecycle.\n\n**Architecture:**\n- **Master**: Central hub that schedules builds, manages agents, monitors processes\n- **Agents**: Machines that perform actual build and deployment work\n- **Distributed**: Scales to handle multiple concurrent builds\n\n**CI/CD Pipeline for Angular + Node.js:**\n\n**1. Jenkinsfile Setup:**\n```groovy\npipeline {\n    agent any\n    \n    environment {\n        NODE_VERSION = '18'\n        APP_NAME = 'my-fullstack-app'\n    }\n    \n    stages {\n        stage('Checkout') {\n            steps {\n                checkout scm\n                echo 'Code checked out from repository'\n            }\n        }\n        \n        stage('Install Dependencies') {\n            parallel {\n                stage('Frontend Dependencies') {\n                    steps {\n                        dir('frontend') {\n                            sh 'npm ci'\n                        }\n                    }\n                }\n                stage('Backend Dependencies') {\n                    steps {\n                        dir('backend') {\n                            sh 'npm ci'\n                        }\n                    }\n                }\n            }\n        }\n        \n        stage('Build') {\n            parallel {\n                stage('Build Angular') {\n                    steps {\n                        dir('frontend') {\n                            sh 'npm run build --prod'\n                        }\n                    }\n                }\n                stage('Build Node.js') {\n                    steps {\n                        dir('backend') {\n                            sh 'npm run build'\n                        }\n                    }\n                }\n            }\n        }\n        \n        stage('Test') {\n            parallel {\n                stage('Frontend Tests') {\n                    steps {\n                        dir('frontend') {\n                            sh 'npm run test:ci'\n                            sh 'npm run e2e:ci'\n                        }\n                    }\n                }\n                stage('Backend Tests') {\n                    steps {\n                        dir('backend') {\n                            sh 'npm run test'\n                            sh 'npm run test:integration'\n                        }\n                    }\n                }\n            }\n        }\n        \n        stage('Archive Artifacts') {\n            steps {\n                archiveArtifacts artifacts: 'frontend/dist/**, backend/dist/**', \n                                 fingerprint: true\n            }\n        }\n        \n        stage('Deploy to Staging') {\n            steps {\n                script {\n                    deployToEnvironment('staging')\n                }\n            }\n        }\n        \n        stage('Deploy to Production') {\n            when {\n                branch 'main'\n            }\n            steps {\n                input 'Deploy to production?'\n                script {\n                    deployToEnvironment('production')\n                }\n            }\n        }\n    }\n    \n    post {\n        always {\n            cleanWs()\n        }\n        success {\n            emailext (\n                subject: \"SUCCESS: Job '${env.JOB_NAME} [${env.BUILD_NUMBER}]'\",\n                body: \"Build completed successfully.\",\n                to: \"${env.CHANGE_AUTHOR_EMAIL}\"\n            )\n        }\n        failure {\n            emailext (\n                subject: \"FAILED: Job '${env.JOB_NAME} [${env.BUILD_NUMBER}]'\",\n                body: \"Build failed. Check console output.\",\n                to: \"${env.CHANGE_AUTHOR_EMAIL}\"\n            )\n        }\n    }\n}\n\ndef deployToEnvironment(environment) {\n    echo \"Deploying to ${environment}\"\n    // Deployment logic here\n}\n```\n\n**Deployment Strategies:**\n\n**1. Blue-Green Deployment:**\n```groovy\nstage('Blue-Green Deploy') {\n    steps {\n        script {\n            // Deploy to Green environment\n            sh 'docker-compose -f docker-compose.green.yml up -d'\n            \n            // Health check\n            sh 'curl -f http://green.myapp.com/health || exit 1'\n            \n            // Switch load balancer from Blue to Green\n            sh 'kubectl patch service myapp-service -p \\'{\"spec\":{\"selector\":{\"version\":\"green\"}}}\\'\n            \n            // Keep Blue as backup for rollback\n            echo 'Blue-Green deployment completed'\n        }\n    }\n}\n```\n\n**2. Canary Deployment:**\n```groovy\nstage('Canary Deploy') {\n    steps {\n        script {\n            // Deploy to 10% of instances\n            sh 'kubectl set image deployment/myapp-canary myapp=myapp:${BUILD_NUMBER}'\n            sh 'kubectl scale deployment myapp-canary --replicas=1'\n            \n            // Monitor metrics for 10 minutes\n            sleep(600)\n            \n            // Check error rates\n            def errorRate = sh(script: 'curl -s http://monitoring.com/api/error-rate', returnStdout: true).trim()\n            \n            if (errorRate.toFloat() < 0.01) {\n                // Roll out to all instances\n                sh 'kubectl set image deployment/myapp myapp=myapp:${BUILD_NUMBER}'\n                echo 'Canary deployment successful, rolling out to all instances'\n            } else {\n                // Rollback canary\n                sh 'kubectl scale deployment myapp-canary --replicas=0'\n                error('Canary deployment failed due to high error rate')\n            }\n        }\n    }\n}\n```\n\n**3. Rolling Deployment:**\n```groovy\nstage('Rolling Deploy') {\n    steps {\n        script {\n            // Kubernetes rolling update\n            sh 'kubectl set image deployment/myapp myapp=myapp:${BUILD_NUMBER}'\n            sh 'kubectl rollout status deployment/myapp --timeout=300s'\n            \n            // Verify deployment\n            sh 'kubectl get pods -l app=myapp'\n        }\n    }\n}\n```\n\n**Docker Integration:**\n```groovy\nstage('Build Docker Images') {\n    steps {\n        script {\n            // Build frontend image\n            def frontendImage = docker.build(\"myapp-frontend:${BUILD_NUMBER}\", \"./frontend\")\n            \n            // Build backend image  \n            def backendImage = docker.build(\"myapp-backend:${BUILD_NUMBER}\", \"./backend\")\n            \n            // Push to registry\n            docker.withRegistry('https://registry.hub.docker.com', 'docker-hub-credentials') {\n                frontendImage.push()\n                frontendImage.push('latest')\n                backendImage.push()\n                backendImage.push('latest')\n            }\n        }\n    }\n}\n```\n\n**Environment Management:**\n```groovy\nparameters {\n    choice(\n        name: 'DEPLOY_ENV',\n        choices: ['staging', 'production'],\n        description: 'Environment to deploy to'\n    )\n    booleanParam(\n        name: 'RUN_TESTS',\n        defaultValue: true,\n        description: 'Run tests before deployment'\n    )\n}\n```\n\n**Benefits:**\n- **Automated**: Reduces manual errors and deployment time\n- **Consistent**: Same process across all environments\n- **Rollback**: Quick rollback capabilities\n- **Monitoring**: Integrated health checks and notifications\n- **Scalable**: Handles multiple projects and environments",
        "difficulty": "Hard",
        "category": "DevOps"
    },
    {
        "id": 21,
        "question": "What is libuv and how does it work with the event loop to handle different types of operations?",
        "solution": "**libuv** is an open-source, multi-platform **C library** that provides the core functionality for Node.js's asynchronous I/O and Event Loop. It's the underlying engine that makes Node.js's non-blocking I/O possible.\n\n**Key Features:**\n- **Cross-platform**: Works on Windows, macOS, and Linux\n- **Thread pool management**: Handles operations that could block the main thread\n- **Event loop implementation**: Core mechanism for asynchronous operations\n- **File system operations**: Handles file I/O in background threads\n- **Network operations**: Manages TCP/UDP sockets and HTTP requests\n\n**How libuv Works with Event Loop:**\n\n**1. Main Thread vs Thread Pool:**\n```javascript\n// Main thread operations (non-blocking)\nconsole.log('1. This runs on main thread');\nsetTimeout(() => console.log('3. Timer callback'), 0);\nconsole.log('2. This also runs on main thread');\n\n// Thread pool operations (offloaded to libuv)\nimport fs from 'fs';\nfs.readFile('package.json', (err, data) => {\n  console.log('4. File read completed in thread pool');\n});\n```\n\n**2. Operation Types:**\n\n**CPU-bound operations (Thread Pool):**\n- File system operations (`fs.readFile`, `fs.writeFile`)\n- DNS lookups (`dns.lookup`)\n- CPU-intensive crypto operations\n- Compression operations\n\n**Network operations (Main Thread):**\n- HTTP requests/responses\n- TCP/UDP socket operations\n- Most networking is handled via system calls\n\n**Process Flow:**\n```javascript\n// When fs.readFile is called:\n// 1. libuv receives the request from Node.js\n// 2. libuv assigns the operation to a thread from its pool\n// 3. Main thread continues executing other code\n// 4. When file reading completes, libuv places callback in event queue\n// 5. Event loop picks up callback and executes it on main thread\n\nimport fs from 'fs';\n\nconsole.log('Starting file operations...');\n\n// These will be handled by libuv thread pool\nfs.readFile('file1.txt', () => console.log('File 1 complete'));\nfs.readFile('file2.txt', () => console.log('File 2 complete'));\nfs.readFile('file3.txt', () => console.log('File 3 complete'));\n\nconsole.log('All file operations started (non-blocking)');\n```\n\n**Thread Pool Configuration:**\n```javascript\n// Default thread pool size is 4\n// Can be configured via environment variable\nprocess.env.UV_THREADPOOL_SIZE = '8'; // Set before requiring any modules\n\n// Check current thread pool usage\nconst { threadId } = require('worker_threads');\nconsole.log('Current thread ID:', threadId);\n```\n\n**Benefits:**\n- **Non-blocking I/O**: Main thread never blocks on I/O operations\n- **Efficient resource usage**: Thread pool reuses threads for multiple operations\n- **Cross-platform consistency**: Same API works across different operating systems\n- **Optimal performance**: Network operations use efficient system calls\n\n**libuv Event Loop Phases:**\n1. **Timers**: Executes `setTimeout()` and `setInterval()` callbacks\n2. **Pending callbacks**: Executes I/O callbacks from previous loop iteration\n3. **Poll**: Fetches new I/O events and executes their callbacks\n4. **Check**: Executes `setImmediate()` callbacks\n5. **Close callbacks**: Executes close event callbacks\n\n**Important Note:**\nlibuv is what makes Node.js truly asynchronous. Without it, Node.js would need to block the main thread for file operations, making it similar to traditional synchronous server technologies.",
        "difficulty": "Medium",
        "category": "Core Concepts"
    },
    {
        "id": 22,
        "question": "How does Node.js handle child threads, worker threads, and CPU-intensive tasks?",
        "solution": "Node.js provides multiple ways to handle CPU-intensive tasks that would otherwise block the main thread:\n\n**1. Child Processes (`child_process` module):**\nSpawns separate Node.js processes with their own memory and CPU core.\n\n```javascript\nimport { fork } from 'child_process';\n\n// parent.js\nconst child = fork('worker.js');\n\nchild.on('message', (result) => {\n  console.log('Result from child:', result);\n});\n\nchild.send({ operation: 'calculate', numbers: [1, 2, 3, 4, 5] });\n\n// worker.js\nprocess.on('message', ({ operation, numbers }) => {\n  if (operation === 'calculate') {\n    // CPU-intensive calculation\n    const result = numbers.reduce((sum, num) => {\n      // Simulate heavy computation\n      for (let i = 0; i < 1000000; i++) {\n        Math.sqrt(num);\n      }\n      return sum + num;\n    }, 0);\n    \n    process.send(result);\n  }\n});\n```\n\n**2. Worker Threads (`worker_threads` module) - Modern Approach:**\nRuns in the same process but on separate threads, sharing memory efficiently.\n\n```javascript\nimport { Worker, isMainThread, parentPort, workerData } from 'worker_threads';\n\nif (isMainThread) {\n  // Main thread\n  console.log('Starting CPU-intensive task...');\n  \n  const worker = new Worker(__filename, {\n    workerData: { numbers: Array.from({length: 1000000}, (_, i) => i) }\n  });\n  \n  worker.on('message', (result) => {\n    console.log('Worker result:', result);\n  });\n  \n  worker.on('error', (error) => {\n    console.error('Worker error:', error);\n  });\n  \n  worker.on('exit', (code) => {\n    console.log(`Worker exited with code ${code}`);\n  });\n  \n} else {\n  // Worker thread\n  const { numbers } = workerData;\n  \n  // CPU-intensive calculation\n  let sum = 0;\n  for (const num of numbers) {\n    sum += Math.sqrt(num);\n  }\n  \n  parentPort.postMessage(sum);\n}\n```\n\n**3. Advanced Worker Thread Pool:**\n```javascript\nimport { Worker } from 'worker_threads';\nimport { cpus } from 'os';\n\nclass WorkerPool {\n  constructor(workerScript, poolSize = cpus().length) {\n    this.workerScript = workerScript;\n    this.poolSize = poolSize;\n    this.workers = [];\n    this.queue = [];\n    \n    this.initWorkers();\n  }\n  \n  initWorkers() {\n    for (let i = 0; i < this.poolSize; i++) {\n      const worker = new Worker(this.workerScript);\n      worker.isAvailable = true;\n      \n      worker.on('message', (result) => {\n        const { resolve } = worker.currentTask;\n        resolve(result);\n        worker.isAvailable = true;\n        this.processQueue();\n      });\n      \n      worker.on('error', (error) => {\n        const { reject } = worker.currentTask;\n        reject(error);\n        worker.isAvailable = true;\n        this.processQueue();\n      });\n      \n      this.workers.push(worker);\n    }\n  }\n  \n  execute(data) {\n    return new Promise((resolve, reject) => {\n      const task = { data, resolve, reject };\n      \n      const availableWorker = this.workers.find(w => w.isAvailable);\n      if (availableWorker) {\n        this.runTask(availableWorker, task);\n      } else {\n        this.queue.push(task);\n      }\n    });\n  }\n  \n  runTask(worker, task) {\n    worker.isAvailable = false;\n    worker.currentTask = task;\n    worker.postMessage(task.data);\n  }\n  \n  processQueue() {\n    if (this.queue.length === 0) return;\n    \n    const availableWorker = this.workers.find(w => w.isAvailable);\n    if (availableWorker) {\n      const task = this.queue.shift();\n      this.runTask(availableWorker, task);\n    }\n  }\n  \n  terminate() {\n    this.workers.forEach(worker => worker.terminate());\n  }\n}\n\n// Usage\nconst pool = new WorkerPool('./cpu-worker.js', 4);\n\n// Process multiple tasks\nPromise.all([\n  pool.execute({ operation: 'fibonacci', number: 40 }),\n  pool.execute({ operation: 'primes', max: 100000 }),\n  pool.execute({ operation: 'sort', array: Array.from({length: 1000000}, () => Math.random()) })\n]).then(results => {\n  console.log('All tasks completed:', results);\n  pool.terminate();\n});\n```\n\n**Comparison:**\n\n| Feature | Child Processes | Worker Threads |\n|---------|----------------|----------------|\n| **Memory** | Separate memory space | Shared memory |\n| **Startup Cost** | Higher (new process) | Lower (new thread) |\n| **Communication** | IPC (slower) | SharedArrayBuffer (faster) |\n| **Isolation** | Complete isolation | Shared process space |\n| **Use Case** | Heavy isolation needed | CPU-intensive tasks |\n\n**When to Use Each:**\n- **Child Processes**: When you need complete isolation, running external programs, or legacy code\n- **Worker Threads**: For CPU-intensive JavaScript computations, mathematical operations, data processing\n\n**Best Practices:**\n- Use worker threads for CPU-bound tasks in modern Node.js applications\n- Implement worker pools to reuse threads efficiently\n- Monitor memory usage when using shared memory\n- Always handle worker errors and cleanup properly",
        "difficulty": "Hard",
        "category": "Concurrency"
    },
    {
        "id": 23,
        "question": "What are global objects in Node.js and how do they differ from browser globals?",
        "solution": "**Global objects** in Node.js are objects available in every module without needing to be imported. However, Node.js's global scope works differently from browser environments.\n\n**Key Node.js Global Objects:**\n\n**1. `process`** - Information about current Node.js process:\n```javascript\n// Process information\nconsole.log('Node version:', process.version);\nconsole.log('Platform:', process.platform);\nconsole.log('Architecture:', process.arch);\nconsole.log('Process ID:', process.pid);\nconsole.log('Working directory:', process.cwd());\nconsole.log('Command line arguments:', process.argv);\n\n// Environment variables\nconsole.log('Environment:', process.env.NODE_ENV);\nconsole.log('Home directory:', process.env.HOME);\n\n// Memory usage\nconst memUsage = process.memoryUsage();\nconsole.log('Memory usage:', {\n  rss: `${Math.round(memUsage.rss / 1024 / 1024)} MB`,\n  heapTotal: `${Math.round(memUsage.heapTotal / 1024 / 1024)} MB`,\n  heapUsed: `${Math.round(memUsage.heapUsed / 1024 / 1024)} MB`\n});\n\n// Exit handling\nprocess.on('exit', (code) => {\n  console.log(`Process exiting with code: ${code}`);\n});\n\nprocess.on('SIGINT', () => {\n  console.log('Received SIGINT, graceful shutdown...');\n  process.exit(0);\n});\n```\n\n**2. `Buffer`** - Handle binary data:\n```javascript\n// Creating buffers\nconst buf1 = Buffer.from('Hello World', 'utf8');\nconst buf2 = Buffer.alloc(10); // Zero-filled buffer\nconst buf3 = Buffer.allocUnsafe(10); // Uninitialized buffer\n\nconsole.log('Buffer from string:', buf1);\nconsole.log('Buffer as string:', buf1.toString());\nconsole.log('Buffer as hex:', buf1.toString('hex'));\n\n// Buffer operations\nconst combined = Buffer.concat([buf1, Buffer.from(' - Node.js')]);\nconsole.log('Combined buffer:', combined.toString());\n```\n\n**3. `__dirname` and `__filename`** - Current module path info:\n```javascript\nconsole.log('Current file:', __filename);\nconsole.log('Current directory:', __dirname);\n\n// Useful for resolving paths\nimport path from 'path';\nconst configPath = path.join(__dirname, 'config', 'app.json');\nconsole.log('Config file path:', configPath);\n```\n\n**4. `global`** - Global namespace object:\n```javascript\n// Setting global variables (use sparingly!)\nglobal.myGlobalVar = 'Available everywhere';\nglobal.appConfig = {\n  name: 'My App',\n  version: '1.0.0'\n};\n\n// Better approach: create a global utility\nglobal.utils = {\n  formatDate: (date) => date.toISOString().split('T')[0],\n  isProduction: () => process.env.NODE_ENV === 'production'\n};\n```\n\n**5. Timer Functions** - Available globally:\n```javascript\n// setTimeout, setInterval, setImmediate, clearTimeout, etc.\nconst timeoutId = setTimeout(() => {\n  console.log('Timeout executed');\n}, 1000);\n\nconst intervalId = setInterval(() => {\n  console.log('Interval tick');\n}, 500);\n\n// Clear after 3 seconds\nsetTimeout(() => {\n  clearInterval(intervalId);\n  console.log('Interval cleared');\n}, 3000);\n\nsetImmediate(() => {\n  console.log('Immediate callback');\n});\n```\n\n**Differences from Browser Globals:**\n\n| Feature | Node.js | Browser |\n|---------|---------|----------|\n| **Global Object** | `global` | `window` |\n| **Module Scope** | Each module wrapped in function | Global scope shared |\n| **File System** | `fs`, `path` modules | Not available |\n| **DOM APIs** | Not available | `document`, `window`, etc. |\n| **Networking** | `http`, `https`, `net` | `fetch`, `XMLHttpRequest` |\n| **Timers** | Same API, different implementation | Same API |\n\n**Module Scope vs Global Scope:**\n```javascript\n// module1.js\nvar moduleVar = 'I am module-scoped';\nglobal.trulyGlobal = 'I am truly global';\n\n// This is NOT global - it's module-scoped\nfunction moduleFunction() {\n  return 'Module function';\n}\n\n// This IS global\nglobal.globalFunction = function() {\n  return 'Global function';\n};\n\n// module2.js\n// console.log(moduleVar); // ReferenceError - not available\nconsole.log(global.trulyGlobal); // Works - 'I am truly global'\n// console.log(moduleFunction()); // ReferenceError - not available\nconsole.log(global.globalFunction()); // Works - 'Global function'\n```\n\n**Best Practices:**\n\n**❌ Avoid:**\n```javascript\n// Polluting global namespace\nglobal.userData = {};\nglobal.helper1 = () => {};\nglobal.helper2 = () => {};\n```\n\n**✅ Better:**\n```javascript\n// Use modules for shared functionality\n// utils.js\nexport const formatDate = (date) => date.toISOString();\nexport const isProduction = () => process.env.NODE_ENV === 'production';\n\n// config.js\nexport default {\n  app: {\n    name: 'My App',\n    version: '1.0.0'\n  },\n  database: {\n    host: process.env.DB_HOST || 'localhost'\n  }\n};\n\n// main.js\nimport { formatDate, isProduction } from './utils.js';\nimport config from './config.js';\n```\n\n**Global Error Handling:**\n```javascript\n// Handle uncaught exceptions\nprocess.on('uncaughtException', (error) => {\n  console.error('Uncaught Exception:', error);\n  // Log error and exit gracefully\n  process.exit(1);\n});\n\n// Handle unhandled promise rejections\nprocess.on('unhandledRejection', (reason, promise) => {\n  console.error('Unhandled Rejection at:', promise, 'reason:', reason);\n  // Handle the error appropriately\n});\n```\n\n**Key Takeaway:**\nNode.js globals are designed for server-side development with focus on file system, networking, and process management, while browser globals focus on DOM manipulation and user interactions.",
        "difficulty": "Medium",
        "category": "Core Concepts"
    },
    {
        "id": 24,
        "question": "What is event-driven programming and how does the EventEmitter class work in Node.js?",
        "solution": "**Event-driven programming** is a paradigm where the program flow is determined by **events** (user actions, sensor outputs, messages, etc.) rather than a predetermined sequence. The program waits for events and reacts by executing specific event handlers.\n\n**EventEmitter Class** is the core of Node.js's event-driven architecture:\n\n**Basic EventEmitter Usage:**\n```javascript\nimport { EventEmitter } from 'events';\n\n// Create an EventEmitter instance\nconst myEmitter = new EventEmitter();\n\n// Register event listeners\nmyEmitter.on('data', (message) => {\n  console.log('Received data:', message);\n});\n\nmyEmitter.on('error', (error) => {\n  console.error('Error occurred:', error.message);\n});\n\n// Emit events\nmyEmitter.emit('data', 'Hello, World!');\nmyEmitter.emit('error', new Error('Something went wrong'));\n```\n\n**Creating Custom EventEmitters:**\n```javascript\nimport { EventEmitter } from 'events';\n\nclass DatabaseConnection extends EventEmitter {\n  constructor() {\n    super();\n    this.connected = false;\n  }\n  \n  connect() {\n    // Simulate connection process\n    setTimeout(() => {\n      this.connected = true;\n      this.emit('connected', { host: 'localhost', port: 5432 });\n    }, 1000);\n  }\n  \n  query(sql) {\n    if (!this.connected) {\n      this.emit('error', new Error('Not connected to database'));\n      return;\n    }\n    \n    // Simulate query execution\n    setTimeout(() => {\n      const results = { rows: [], rowCount: 0 };\n      this.emit('queryResult', { sql, results });\n    }, 500);\n  }\n  \n  disconnect() {\n    this.connected = false;\n    this.emit('disconnected');\n  }\n}\n\n// Usage\nconst db = new DatabaseConnection();\n\ndb.on('connected', (info) => {\n  console.log('Connected to database:', info);\n  db.query('SELECT * FROM users');\n});\n\ndb.on('queryResult', ({ sql, results }) => {\n  console.log(`Query '${sql}' returned ${results.rowCount} rows`);\n  db.disconnect();\n});\n\ndb.on('disconnected', () => {\n  console.log('Disconnected from database');\n});\n\ndb.on('error', (error) => {\n  console.error('Database error:', error.message);\n});\n\ndb.connect();\n```\n\n**Real-world Example - File Watcher:**\n```javascript\nimport { EventEmitter } from 'events';\nimport fs from 'fs';\nimport path from 'path';\n\nclass FileWatcher extends EventEmitter {\n  constructor(directory) {\n    super();\n    this.directory = directory;\n    this.watchers = new Map();\n  }\n  \n  startWatching() {\n    try {\n      const watcher = fs.watch(this.directory, (eventType, filename) => {\n        const filePath = path.join(this.directory, filename);\n        \n        fs.stat(filePath, (err, stats) => {\n          if (err) {\n            if (err.code === 'ENOENT') {\n              this.emit('fileDeleted', { filename, path: filePath });\n            } else {\n              this.emit('error', err);\n            }\n            return;\n          }\n          \n          if (eventType === 'rename') {\n            this.emit('fileCreated', { filename, path: filePath, stats });\n          } else if (eventType === 'change') {\n            this.emit('fileModified', { filename, path: filePath, stats });\n          }\n        });\n      });\n      \n      this.watchers.set(this.directory, watcher);\n      this.emit('watchStarted', { directory: this.directory });\n      \n    } catch (error) {\n      this.emit('error', error);\n    }\n  }\n  \n  stopWatching() {\n    const watcher = this.watchers.get(this.directory);\n    if (watcher) {\n      watcher.close();\n      this.watchers.delete(this.directory);\n      this.emit('watchStopped', { directory: this.directory });\n    }\n  }\n}\n\n// Usage\nconst fileWatcher = new FileWatcher('./watched-directory');\n\nfileWatcher.on('watchStarted', ({ directory }) => {\n  console.log(`Started watching: ${directory}`);\n});\n\nfileWatcher.on('fileCreated', ({ filename, path }) => {\n  console.log(`New file created: ${filename}`);\n  // Could trigger build process, send notifications, etc.\n});\n\nfileWatcher.on('fileModified', ({ filename, path }) => {\n  console.log(`File modified: ${filename}`);\n  // Could trigger hot reload, save to backup, etc.\n});\n\nfileWatcher.on('fileDeleted', ({ filename }) => {\n  console.log(`File deleted: ${filename}`);\n  // Could update indexes, clean up references, etc.\n});\n\nfileWatcher.on('error', (error) => {\n  console.error('File watcher error:', error.message);\n});\n\nfileWatcher.startWatching();\n\n// Stop watching after 30 seconds\nsetTimeout(() => {\n  fileWatcher.stopWatching();\n}, 30000);\n```\n\n**EventEmitter Methods:**\n```javascript\nconst emitter = new EventEmitter();\n\n// Adding listeners\nemitter.on('event', listener);           // Add listener\nemitter.addListener('event', listener);   // Alias for .on()\nemitter.once('event', listener);          // Listen only once\nemitter.prependListener('event', listener); // Add to beginning\n\n// Removing listeners\nemitter.off('event', listener);           // Remove specific listener\nemitter.removeListener('event', listener); // Alias for .off()\nemitter.removeAllListeners('event');      // Remove all listeners for event\nemitter.removeAllListeners();             // Remove all listeners\n\n// Emitting events\nemitter.emit('event', arg1, arg2);        // Emit event with arguments\n\n// Listener information\nemitter.listeners('event');               // Get array of listeners\nemitter.listenerCount('event');           // Get count of listeners\nemitter.eventNames();                     // Get array of event names\n\n// Max listeners (default: 10)\nemitter.setMaxListeners(20);              // Set max listeners\nemitter.getMaxListeners();                // Get max listeners limit\n```\n\n**Benefits of Event-Driven Programming:**\n- **Loose coupling**: Components don't need direct references\n- **Scalability**: Easy to add new event handlers\n- **Asynchronous**: Non-blocking event handling\n- **Flexibility**: Dynamic event registration/removal\n- **Reusability**: Same events can have multiple handlers",
        "difficulty": "Medium",
        "category": "Event-Driven Programming"
    },
    {
        "id": 25,
        "question": "How do you create custom events, handle event listeners, and prevent memory leaks in EventEmitter?",
        "solution": "**Creating Custom Events** and managing EventEmitter properly is crucial for building robust Node.js applications.\n\n**Creating Custom Events:**\n```javascript\nimport { EventEmitter } from 'events';\n\nclass UserManager extends EventEmitter {\n  constructor() {\n    super();\n    this.users = new Map();\n  }\n  \n  createUser(userData) {\n    const user = {\n      id: Date.now(),\n      ...userData,\n      createdAt: new Date()\n    };\n    \n    this.users.set(user.id, user);\n    \n    // Emit custom events\n    this.emit('userCreated', user);\n    this.emit('userActivity', { type: 'create', user, timestamp: Date.now() });\n    \n    return user;\n  }\n  \n  updateUser(userId, updates) {\n    const user = this.users.get(userId);\n    if (!user) {\n      this.emit('error', new Error(`User ${userId} not found`));\n      return null;\n    }\n    \n    const oldUser = { ...user };\n    Object.assign(user, updates, { updatedAt: new Date() });\n    \n    this.emit('userUpdated', { oldUser, newUser: user });\n    this.emit('userActivity', { type: 'update', user, timestamp: Date.now() });\n    \n    return user;\n  }\n  \n  deleteUser(userId) {\n    const user = this.users.get(userId);\n    if (!user) {\n      this.emit('error', new Error(`User ${userId} not found`));\n      return false;\n    }\n    \n    this.users.delete(userId);\n    this.emit('userDeleted', user);\n    this.emit('userActivity', { type: 'delete', user, timestamp: Date.now() });\n    \n    return true;\n  }\n}\n\n// Usage with custom events\nconst userManager = new UserManager();\n\n// Event handlers\nuserManager.on('userCreated', (user) => {\n  console.log(`New user created: ${user.name} (ID: ${user.id})`);\n  // Could send welcome email, update analytics, etc.\n});\n\nuserManager.on('userUpdated', ({ oldUser, newUser }) => {\n  console.log(`User ${newUser.id} updated:`, {\n    old: oldUser.name,\n    new: newUser.name\n  });\n});\n\nuserManager.on('userDeleted', (user) => {\n  console.log(`User deleted: ${user.name}`);\n  // Could cleanup related data, send notifications, etc.\n});\n\nuserManager.on('userActivity', ({ type, user, timestamp }) => {\n  console.log(`Activity logged: ${type} for user ${user.name} at ${new Date(timestamp)}`);\n});\n\nuserManager.on('error', (error) => {\n  console.error('UserManager error:', error.message);\n});\n```\n\n**Managing Event Listeners:**\n```javascript\nclass EventManagerDemo extends EventEmitter {\n  constructor() {\n    super();\n    this.intervalId = null;\n  }\n  \n  startEmitting() {\n    this.intervalId = setInterval(() => {\n      this.emit('tick', Date.now());\n    }, 1000);\n  }\n  \n  stopEmitting() {\n    if (this.intervalId) {\n      clearInterval(this.intervalId);\n      this.intervalId = null;\n    }\n  }\n}\n\nconst demo = new EventManagerDemo();\n\n// Multiple ways to add listeners\nconst listener1 = (timestamp) => console.log(`Listener 1: ${timestamp}`);\nconst listener2 = (timestamp) => console.log(`Listener 2: ${timestamp}`);\nconst onceListener = (timestamp) => console.log(`Once listener: ${timestamp}`);\n\n// Add listeners\ndemo.on('tick', listener1);\ndemo.addListener('tick', listener2);\ndemo.once('tick', onceListener); // Only fires once\n\n// Prepend listener (executes first)\ndemo.prependListener('tick', (timestamp) => {\n  console.log(`First listener: ${timestamp}`);\n});\n\ndemo.startEmitting();\n\n// Remove specific listener after 5 seconds\nsetTimeout(() => {\n  demo.off('tick', listener1);\n  console.log('Removed listener1');\n}, 5000);\n\n// Remove all listeners after 10 seconds\nsetTimeout(() => {\n  demo.removeAllListeners('tick');\n  demo.stopEmitting();\n  console.log('Removed all listeners and stopped emitting');\n}, 10000);\n```\n\n**Preventing Memory Leaks:**\n\n**1. Remove Listeners When Done:**\n```javascript\nclass ComponentWithCleanup extends EventEmitter {\n  constructor() {\n    super();\n    this.isDestroyed = false;\n    this.boundHandlers = new Map();\n  }\n  \n  addManagedListener(eventName, handler) {\n    // Store reference for cleanup\n    if (!this.boundHandlers.has(eventName)) {\n      this.boundHandlers.set(eventName, []);\n    }\n    this.boundHandlers.get(eventName).push(handler);\n    \n    this.on(eventName, handler);\n  }\n  \n  destroy() {\n    if (this.isDestroyed) return;\n    \n    // Remove all managed listeners\n    for (const [eventName, handlers] of this.boundHandlers) {\n      handlers.forEach(handler => this.off(eventName, handler));\n    }\n    \n    this.boundHandlers.clear();\n    this.removeAllListeners();\n    this.isDestroyed = true;\n    \n    console.log('Component destroyed and cleaned up');\n  }\n}\n\n// Usage\nconst component = new ComponentWithCleanup();\n\ncomponent.addManagedListener('data', (data) => {\n  console.log('Received data:', data);\n});\n\ncomponent.addManagedListener('error', (error) => {\n  console.error('Error:', error.message);\n});\n\n// Simulate component lifecycle\nsetTimeout(() => {\n  component.emit('data', 'test data');\n}, 1000);\n\nsetTimeout(() => {\n  component.destroy(); // Clean cleanup\n}, 5000);\n```\n\n**2. Handle Max Listeners Warning:**\n```javascript\nclass SafeEventEmitter extends EventEmitter {\n  constructor(maxListeners = 10) {\n    super();\n    this.setMaxListeners(maxListeners);\n    \n    // Monitor listener count\n    this.on('newListener', (eventName) => {\n      const count = this.listenerCount(eventName);\n      if (count > this.getMaxListeners() - 2) {\n        console.warn(`Warning: High listener count (${count}) for event '${eventName}'`);\n      }\n    });\n  }\n  \n  addSafeListener(eventName, listener, { once = false } = {}) {\n    const currentCount = this.listenerCount(eventName);\n    const maxListeners = this.getMaxListeners();\n    \n    if (currentCount >= maxListeners) {\n      console.error(`Cannot add listener: Max listeners (${maxListeners}) reached for '${eventName}'`);\n      return false;\n    }\n    \n    if (once) {\n      this.once(eventName, listener);\n    } else {\n      this.on(eventName, listener);\n    }\n    \n    return true;\n  }\n}\n\nconst safeEmitter = new SafeEventEmitter(5);\n\n// This will work\nfor (let i = 0; i < 5; i++) {\n  safeEmitter.addSafeListener('test', () => console.log(`Listener ${i}`));\n}\n\n// This will be rejected\nsafeEmitter.addSafeListener('test', () => console.log('This wont be added'));\n```\n\n**3. Weak References Pattern:**\n```javascript\nclass WeakEventEmitter extends EventEmitter {\n  constructor() {\n    super();\n    this.weakListeners = new WeakMap();\n  }\n  \n  addWeakListener(eventName, target, methodName) {\n    const weakListener = (...args) => {\n      // Check if target still exists\n      if (target && typeof target[methodName] === 'function') {\n        target[methodName](...args);\n      } else {\n        // Auto-cleanup if target is gone\n        this.off(eventName, weakListener);\n      }\n    };\n    \n    this.weakListeners.set(target, weakListener);\n    this.on(eventName, weakListener);\n  }\n  \n  removeWeakListener(eventName, target) {\n    const listener = this.weakListeners.get(target);\n    if (listener) {\n      this.off(eventName, listener);\n      this.weakListeners.delete(target);\n    }\n  }\n}\n```\n\n**Best Practices:**\n- Always remove listeners when components are destroyed\n- Use `once()` for one-time events\n- Monitor listener counts in development\n- Implement cleanup methods in custom classes\n- Use weak references for cross-object communication\n- Set appropriate `maxListeners` based on your use case",
        "difficulty": "Medium",
        "category": "Event-Driven Programming"
    },
    {
        "id": 26,
        "question": "Compare callbacks, Promises, and async/await - when to use each and how they handle errors?",
        "solution": "Understanding different asynchronous patterns in Node.js is crucial for writing efficient and maintainable code.\n\n**1. Callbacks (Traditional Pattern):**\n\n**Error-First Callback Pattern:**\n```javascript\nimport fs from 'fs';\n\n// Traditional callback with error-first pattern\nfunction readFileCallback(filename, callback) {\n  fs.readFile(filename, 'utf8', (err, data) => {\n    if (err) {\n      callback(err, null); // Error as first parameter\n      return;\n    }\n    callback(null, data); // Success: null error, data as second parameter\n  });\n}\n\n// Usage\nreadFileCallback('config.json', (err, data) => {\n  if (err) {\n    console.error('Error reading file:', err.message);\n    return;\n  }\n  \n  try {\n    const config = JSON.parse(data);\n    console.log('Config loaded:', config);\n  } catch (parseError) {\n    console.error('Error parsing JSON:', parseError.message);\n  }\n});\n\n// Multiple async operations (Callback Hell)\nreadFileCallback('users.json', (err, userData) => {\n  if (err) {\n    console.error('Error reading users:', err.message);\n    return;\n  }\n  \n  readFileCallback('permissions.json', (err, permissionData) => {\n    if (err) {\n      console.error('Error reading permissions:', err.message);\n      return;\n    }\n    \n    readFileCallback('settings.json', (err, settingsData) => {\n      if (err) {\n        console.error('Error reading settings:', err.message);\n        return;\n      }\n      \n      // Finally process all data (deeply nested!)\n      console.log('All data loaded successfully');\n    });\n  });\n});\n```\n\n**2. Promises (Modern Approach):**\n\n**Promise Creation and Chaining:**\n```javascript\nimport fs from 'fs';\nimport { promisify } from 'util';\n\n// Convert callback-based function to Promise\nconst readFilePromise = promisify(fs.readFile);\n\n// Or create custom Promise\nfunction readFileCustom(filename) {\n  return new Promise((resolve, reject) => {\n    fs.readFile(filename, 'utf8', (err, data) => {\n      if (err) {\n        reject(err);\n      } else {\n        resolve(data);\n      }\n    });\n  });\n}\n\n// Promise chaining (flatter structure)\nreadFilePromise('config.json', 'utf8')\n  .then(data => {\n    console.log('File read successfully');\n    return JSON.parse(data);\n  })\n  .then(config => {\n    console.log('Config parsed:', config);\n    return readFilePromise('users.json', 'utf8');\n  })\n  .then(userData => {\n    console.log('Users loaded');\n    return readFilePromise('permissions.json', 'utf8');\n  })\n  .then(permissionData => {\n    console.log('Permissions loaded');\n    return readFilePromise('settings.json', 'utf8');\n  })\n  .then(settingsData => {\n    console.log('All files loaded successfully');\n  })\n  .catch(error => {\n    console.error('Error in Promise chain:', error.message);\n  });\n\n// Parallel Promise execution\nPromise.all([\n  readFilePromise('users.json', 'utf8'),\n  readFilePromise('permissions.json', 'utf8'),\n  readFilePromise('settings.json', 'utf8')\n])\n.then(([userData, permissionData, settingsData]) => {\n  console.log('All files loaded in parallel');\n  // Process all data simultaneously\n})\n.catch(error => {\n  console.error('Error loading files:', error.message);\n});\n\n// Promise.allSettled - doesn't fail if one Promise rejects\nPromise.allSettled([\n  readFilePromise('existing-file.json', 'utf8'),\n  readFilePromise('non-existent-file.json', 'utf8'),\n  readFilePromise('another-file.json', 'utf8')\n])\n.then(results => {\n  results.forEach((result, index) => {\n    if (result.status === 'fulfilled') {\n      console.log(`File ${index} loaded:`, result.value.length, 'bytes');\n    } else {\n      console.log(`File ${index} failed:`, result.reason.message);\n    }\n  });\n});\n```\n\n**3. Async/Await (Most Modern and Readable):**\n\n**Clean, Synchronous-Looking Code:**\n```javascript\nimport fs from 'fs/promises'; // Modern fs promises API\n\n// Sequential operations\nasync function loadConfigSequential() {\n  try {\n    console.log('Loading config...');\n    const configData = await fs.readFile('config.json', 'utf8');\n    const config = JSON.parse(configData);\n    \n    console.log('Loading users...');\n    const userData = await fs.readFile('users.json', 'utf8');\n    const users = JSON.parse(userData);\n    \n    console.log('Loading permissions...');\n    const permissionData = await fs.readFile('permissions.json', 'utf8');\n    const permissions = JSON.parse(permissionData);\n    \n    console.log('All data loaded successfully');\n    return { config, users, permissions };\n    \n  } catch (error) {\n    console.error('Error in async function:', error.message);\n    throw error; // Re-throw to let caller handle\n  }\n}\n\n// Parallel operations with async/await\nasync function loadConfigParallel() {\n  try {\n    console.log('Loading all files in parallel...');\n    \n    // Start all operations simultaneously\n    const [configData, userData, permissionData] = await Promise.all([\n      fs.readFile('config.json', 'utf8'),\n      fs.readFile('users.json', 'utf8'),\n      fs.readFile('permissions.json', 'utf8')\n    ]);\n    \n    // Parse all data\n    const config = JSON.parse(configData);\n    const users = JSON.parse(userData);\n    const permissions = JSON.parse(permissionData);\n    \n    console.log('All files loaded and parsed successfully');\n    return { config, users, permissions };\n    \n  } catch (error) {\n    console.error('Error loading files:', error.message);\n    throw error;\n  }\n}\n\n// Error handling with multiple try-catch blocks\nasync function loadConfigWithDetailedErrorHandling() {\n  let config, users, permissions;\n  \n  try {\n    const configData = await fs.readFile('config.json', 'utf8');\n    config = JSON.parse(configData);\n    console.log('✅ Config loaded');\n  } catch (error) {\n    console.error('❌ Failed to load config:', error.message);\n    config = getDefaultConfig(); // Fallback\n  }\n  \n  try {\n    const userData = await fs.readFile('users.json', 'utf8');\n    users = JSON.parse(userData);\n    console.log('✅ Users loaded');\n  } catch (error) {\n    console.error('❌ Failed to load users:', error.message);\n    users = []; // Empty fallback\n  }\n  \n  try {\n    const permissionData = await fs.readFile('permissions.json', 'utf8');\n    permissions = JSON.parse(permissionData);\n    console.log('✅ Permissions loaded');\n  } catch (error) {\n    console.error('❌ Failed to load permissions:', error.message);\n    permissions = getDefaultPermissions(); // Fallback\n  }\n  \n  return { config, users, permissions };\n}\n\nfunction getDefaultConfig() {\n  return { app: 'default', version: '1.0.0' };\n}\n\nfunction getDefaultPermissions() {\n  return { admin: false, read: true, write: false };\n}\n```\n\n**Comparison Table:**\n\n| Pattern | Pros | Cons | Error Handling | When to Use |\n|---------|------|------|----------------|--------------|\n| **Callbacks** | • Simple concept<br>• No dependencies<br>• Universal support | • Callback hell<br>• Hard to read<br>• Error handling complex | Error-first pattern<br>`callback(err, result)` | • Legacy code<br>• Simple operations<br>• Library compatibility |\n| **Promises** | • Chainable<br>• Better error handling<br>• Parallel execution | • Still can be complex<br>• Learning curve<br>• Browser compatibility | `.catch()` method<br>Single error handler | • Complex workflows<br>• Multiple async operations<br>• When need chaining |\n| **Async/Await** | • Most readable<br>• Familiar syntax<br>• Easy debugging | • Requires modern Node.js<br>• Sequential by default<br>• Top-level await limited | `try...catch` blocks<br>Like synchronous code | • Modern applications<br>• Complex logic<br>• Preferred approach |\n\n**Best Practices:**\n\n**❌ Avoid:**\n```javascript\n// Callback hell\ngetUser(id, (err, user) => {\n  getPermissions(user.id, (err, permissions) => {\n    getSettings(user.id, (err, settings) => {\n      // Deep nesting continues...\n    });\n  });\n});\n\n// Mixing patterns\nasync function mixedPatterns() {\n  return new Promise((resolve, reject) => {\n    fs.readFile('file.txt', (err, data) => {\n      if (err) reject(err);\n      resolve(data);\n    });\n  });\n}\n```\n\n**✅ Prefer:**\n```javascript\n// Clean async/await\nasync function cleanPattern() {\n  const user = await getUser(id);\n  const [permissions, settings] = await Promise.all([\n    getPermissions(user.id),\n    getSettings(user.id)\n  ]);\n  return { user, permissions, settings };\n}\n\n// Proper error boundaries\nasync function withErrorBoundaries() {\n  try {\n    const result = await riskyOperation();\n    return result;\n  } catch (error) {\n    logger.error('Operation failed:', error);\n    return fallbackValue;\n  }\n}\n```",
        "difficulty": "Medium",
        "category": "Asynchronous Programming"
    },
    {
        "id": 27,
        "question": "What is the difference between process.nextTick(), setImmediate(), and setTimeout()? How do they relate to the Event Loop phases?",
        "solution": "These three functions schedule callbacks to execute at different phases of the **Event Loop**, affecting their execution order and priority.\n\n**Understanding Event Loop Phases:**\n```\n┌───────────────────────────┐\n┌─>│           Timers          │  ← setTimeout, setInterval\n│  └─────────────┬─────────────┘\n│  ┌─────────────┴─────────────┐\n│  │     Pending Callbacks     │  ← I/O callbacks\n│  └─────────────┬─────────────┘\n│  ┌─────────────┴─────────────┐\n│  │       Idle, Prepare       │  ← Internal use\n│  └─────────────┬─────────────┘\n│  ┌─────────────┴─────────────┐\n│  │           Poll            │  ← Fetch new I/O events\n│  └─────────────┬─────────────┘\n│  ┌─────────────┴─────────────┐\n│  │           Check           │  ← setImmediate callbacks\n│  └─────────────┬─────────────┘\n│  ┌─────────────┴─────────────┐\n└──┤      Close Callbacks      │  ← e.g. socket.on('close')\n   └───────────────────────────┘\n```\n\n**1. process.nextTick() - Highest Priority:**\n```javascript\nconsole.log('=== process.nextTick() Demo ===');\n\nconsole.log('1. Start');\n\nprocess.nextTick(() => {\n  console.log('3. nextTick callback 1');\n});\n\nprocess.nextTick(() => {\n  console.log('4. nextTick callback 2');\n  // Can schedule more nextTicks\n  process.nextTick(() => {\n    console.log('5. nested nextTick');\n  });\n});\n\nconsole.log('2. End of main execution');\n\n// Output:\n// 1. Start\n// 2. End of main execution\n// 3. nextTick callback 1\n// 4. nextTick callback 2\n// 5. nested nextTick\n```\n\n**2. setImmediate() - Check Phase:**\n```javascript\nconsole.log('=== setImmediate() Demo ===');\n\nconsole.log('1. Start');\n\nsetImmediate(() => {\n  console.log('4. setImmediate callback 1');\n});\n\nsetImmediate(() => {\n  console.log('5. setImmediate callback 2');\n});\n\nprocess.nextTick(() => {\n  console.log('3. nextTick (runs before setImmediate)');\n});\n\nconsole.log('2. End of main execution');\n\n// Output:\n// 1. Start\n// 2. End of main execution\n// 3. nextTick (runs before setImmediate)\n// 4. setImmediate callback 1\n// 5. setImmediate callback 2\n```\n\n**3. setTimeout() - Timers Phase:**\n```javascript\nconsole.log('=== setTimeout() Demo ===');\n\nconsole.log('1. Start');\n\nsetTimeout(() => {\n  console.log('4. setTimeout 0ms');\n}, 0);\n\nsetTimeout(() => {\n  console.log('5. setTimeout 1ms');\n}, 1);\n\nprocess.nextTick(() => {\n  console.log('3. nextTick (highest priority)');\n});\n\nconsole.log('2. End of main execution');\n\n// Output:\n// 1. Start\n// 2. End of main execution\n// 3. nextTick (highest priority)\n// 4. setTimeout 0ms\n// 5. setTimeout 1ms\n```\n\n**Complete Execution Order Demonstration:**\n```javascript\nconsole.log('=== Complete Order Demonstration ===');\n\nconsole.log('1. 🚀 Synchronous start');\n\n// Timers phase\nsetTimeout(() => {\n  console.log('6. ⏰ setTimeout 0ms (Timers phase)');\n}, 0);\n\nsetTimeout(() => {\n  console.log('7. ⏰ setTimeout 1ms (Timers phase)');\n}, 1);\n\n// Check phase\nsetImmediate(() => {\n  console.log('4. ⚡ setImmediate 1 (Check phase)');\n});\n\nsetImmediate(() => {\n  console.log('5. ⚡ setImmediate 2 (Check phase)');\n});\n\n// Microtask queue (highest priority)\nprocess.nextTick(() => {\n  console.log('3. 🔄 nextTick (Microtask queue)');\n  \n  // Nested nextTick\n  process.nextTick(() => {\n    console.log('3.1. 🔄 nested nextTick');\n  });\n});\n\n// Promise microtask\nPromise.resolve().then(() => {\n  console.log('3.2. 🤝 Promise then (Microtask queue)');\n});\n\nconsole.log('2. 🚀 Synchronous end');\n\n// Expected output:\n// 1. 🚀 Synchronous start\n// 2. 🚀 Synchronous end\n// 3. 🔄 nextTick (Microtask queue)\n// 3.1. 🔄 nested nextTick\n// 3.2. 🤝 Promise then (Microtask queue)\n// 4. ⚡ setImmediate 1 (Check phase)\n// 5. ⚡ setImmediate 2 (Check phase)\n// 6. ⏰ setTimeout 0ms (Timers phase)\n// 7. ⏰ setTimeout 1ms (Timers phase)\n```\n\n**Real-world Examples:**\n\n**1. Breaking Up CPU-Intensive Tasks:**\n```javascript\n// Bad: Blocks event loop\nfunction processLargeArrayBlocking(arr) {\n  const results = [];\n  for (let i = 0; i < arr.length; i++) {\n    results.push(heavyComputation(arr[i]));\n  }\n  return results;\n}\n\n// Good: Non-blocking with setImmediate\nfunction processLargeArrayNonBlocking(arr, callback) {\n  const results = [];\n  let index = 0;\n  \n  function processChunk() {\n    const chunkSize = 1000;\n    const endIndex = Math.min(index + chunkSize, arr.length);\n    \n    // Process chunk\n    for (let i = index; i < endIndex; i++) {\n      results.push(heavyComputation(arr[i]));\n    }\n    \n    index = endIndex;\n    \n    if (index < arr.length) {\n      // Use setImmediate to yield control\n      setImmediate(processChunk);\n    } else {\n      callback(results);\n    }\n  }\n  \n  processChunk();\n}\n\nfunction heavyComputation(x) {\n  // Simulate CPU-intensive work\n  let result = 0;\n  for (let i = 0; i < 10000; i++) {\n    result += Math.sqrt(x * i);\n  }\n  return result;\n}\n```\n\n**2. Ensuring Code Execution Order:**\n```javascript\nclass EventProcessor {\n  constructor() {\n    this.events = [];\n    this.processing = false;\n  }\n  \n  addEvent(event) {\n    this.events.push(event);\n    \n    // Use nextTick to ensure processing starts after current operation\n    if (!this.processing) {\n      process.nextTick(() => this.processEvents());\n    }\n  }\n  \n  processEvents() {\n    if (this.processing) return;\n    \n    this.processing = true;\n    \n    while (this.events.length > 0) {\n      const event = this.events.shift();\n      this.handleEvent(event);\n    }\n    \n    this.processing = false;\n  }\n  \n  handleEvent(event) {\n    console.log('Processing event:', event);\n  }\n}\n\nconst processor = new EventProcessor();\nprocessor.addEvent('event1');\nprocessor.addEvent('event2');\nprocessor.addEvent('event3');\n```\n\n**3. I/O vs Timer Coordination:**\n```javascript\nimport fs from 'fs';\n\nconsole.log('Starting I/O and timer demo...');\n\n// This will usually run first (Timers phase comes before Check)\nsetTimeout(() => {\n  console.log('setTimeout: Timer phase');\n}, 0);\n\n// This runs in Check phase\nsetImmediate(() => {\n  console.log('setImmediate: Check phase');\n});\n\n// I/O operation - callback runs in Poll/Pending phase\nfs.readFile(__filename, () => {\n  console.log('File read complete');\n  \n  // Inside I/O callback, setImmediate usually runs before setTimeout\n  setTimeout(() => {\n    console.log('setTimeout inside I/O callback');\n  }, 0);\n  \n  setImmediate(() => {\n    console.log('setImmediate inside I/O callback');\n  });\n});\n\nprocess.nextTick(() => {\n  console.log('nextTick: Always runs first');\n});\n```\n\n**Key Differences Summary:**\n\n| Function | Phase | Priority | Use Case |\n|----------|-------|----------|----------|\n| **process.nextTick()** | Microtask Queue | Highest | API consistency, error handling |\n| **setImmediate()** | Check Phase | Medium | Breaking up CPU work, after I/O |\n| **setTimeout(0)** | Timers Phase | Lowest | Minimum delay, scheduling |\n\n**Best Practices:**\n- Use `process.nextTick()` sparingly - can starve the event loop\n- Prefer `setImmediate()` for yielding control in CPU-intensive tasks\n- Use `setTimeout()` for actual delays, not just scheduling\n- Understand the order to avoid timing-dependent bugs",
        "difficulty": "Hard",
        "category": "Event Loop"
    },
    {
        "id": 28,
        "question": "Explain NPM, module.exports, require() mechanism, and how to create and publish custom modules.",
        "solution": "**NPM (Node Package Manager)** is the default package manager for Node.js and the world's largest software registry with over 1 million packages.\n\n**NPM Core Functions:**\n- **Package Installation**: Download and manage dependencies\n- **Version Management**: Handle semantic versioning\n- **Script Execution**: Run project scripts\n- **Publishing**: Share packages with the community\n- **Registry**: Central repository for JavaScript packages\n\n**Module System - require() and module.exports:**\n\n**1. Basic Module Creation:**\n```javascript\n// math-utils.js - Creating a module\nfunction add(a, b) {\n  return a + b;\n}\n\nfunction subtract(a, b) {\n  return a - b;\n}\n\nfunction multiply(a, b) {\n  return a * b;\n}\n\nfunction divide(a, b) {\n  if (b === 0) throw new Error('Division by zero');\n  return a / b;\n}\n\nconst PI = 3.14159;\nconst E = 2.71828;\n\n// Export multiple functions and constants\nmodule.exports = {\n  add,\n  subtract,\n  multiply,\n  divide,\n  PI,\n  E,\n  // Can also add computed properties\n  version: '1.0.0',\n  author: 'Your Name'\n};\n\n// Alternative syntax for single export\n// module.exports = add; // Only exports the add function\n```\n\n**2. Using Modules with require():**\n```javascript\n// app.js - Using the module\nconst mathUtils = require('./math-utils');\n\n// Use the imported functions\nconsole.log('Addition:', mathUtils.add(5, 3));\nconsole.log('Subtraction:', mathUtils.subtract(10, 4));\nconsole.log('PI value:', mathUtils.PI);\nconsole.log('Module info:', {\n  version: mathUtils.version,\n  author: mathUtils.author\n});\n\n// Destructuring import\nconst { add, multiply, PI } = require('./math-utils');\nconsole.log('Using destructured imports:', add(2, 3) * PI);\n\n// Import with different name\nconst calculator = require('./math-utils');\nconsole.log('Division:', calculator.divide(15, 3));\n```\n\n**3. Different Export Patterns:**\n```javascript\n// patterns.js - Various export patterns\n\n// Pattern 1: Direct assignment\nmodule.exports.greet = function(name) {\n  return `Hello, ${name}!`;\n};\n\nmodule.exports.farewell = function(name) {\n  return `Goodbye, ${name}!`;\n};\n\n// Pattern 2: Exports shorthand\nexports.currentDate = function() {\n  return new Date().toISOString();\n};\n\nexports.randomNumber = function(min = 0, max = 100) {\n  return Math.floor(Math.random() * (max - min + 1)) + min;\n};\n\n// Pattern 3: Class export\nclass Logger {\n  constructor(prefix = 'LOG') {\n    this.prefix = prefix;\n  }\n  \n  info(message) {\n    console.log(`[${this.prefix}] INFO: ${message}`);\n  }\n  \n  error(message) {\n    console.error(`[${this.prefix}] ERROR: ${message}`);\n  }\n  \n  debug(message) {\n    if (process.env.NODE_ENV === 'development') {\n      console.log(`[${this.prefix}] DEBUG: ${message}`);\n    }\n  }\n}\n\nmodule.exports.Logger = Logger;\n\n// Pattern 4: Function constructor export\nmodule.exports.createTimer = function(name) {\n  const startTime = Date.now();\n  \n  return {\n    name,\n    start: startTime,\n    elapsed() {\n      return Date.now() - startTime;\n    },\n    stop() {\n      const elapsed = this.elapsed();\n      console.log(`Timer '${this.name}' took ${elapsed}ms`);\n      return elapsed;\n    }\n  };\n};\n```\n\n**4. Creating and Publishing Custom NPM Package:**\n\n**Step 1: Initialize Package:**\n```bash\n# Create project directory\nmkdir my-awesome-package\ncd my-awesome-package\n\n# Initialize package.json\nnpm init\n\n# Or use defaults\nnpm init -y\n```\n\n**Step 2: Create package.json:**\n```json\n{\n  \"name\": \"my-awesome-utility\",\n  \"version\": \"1.0.0\",\n  \"description\": \"A collection of useful utility functions\",\n  \"main\": \"index.js\",\n  \"scripts\": {\n    \"test\": \"jest\",\n    \"build\": \"echo \\\"No build step\\\"\",\n    \"prepublishOnly\": \"npm test\"\n  },\n  \"keywords\": [\n    \"utility\",\n    \"helper\",\n    \"javascript\",\n    \"nodejs\"\n  ],\n  \"author\": \"Your Name <your.email@example.com>\",\n  \"license\": \"MIT\",\n  \"repository\": {\n    \"type\": \"git\",\n    \"url\": \"https://github.com/yourusername/my-awesome-package.git\"\n  },\n  \"bugs\": {\n    \"url\": \"https://github.com/yourusername/my-awesome-package/issues\"\n  },\n  \"homepage\": \"https://github.com/yourusername/my-awesome-package#readme\",\n  \"engines\": {\n    \"node\": \">=14.0.0\"\n  },\n  \"files\": [\n    \"index.js\",\n    \"lib/\",\n    \"README.md\",\n    \"LICENSE\"\n  ],\n  \"devDependencies\": {\n    \"jest\": \"^29.0.0\"\n  }\n}\n```\n\n**Step 3: Create Main Module (index.js):**\n```javascript\n// index.js - Main entry point\nconst stringUtils = require('./lib/string-utils');\nconst arrayUtils = require('./lib/array-utils');\nconst dateUtils = require('./lib/date-utils');\n\n// Export all utilities\nmodule.exports = {\n  string: stringUtils,\n  array: arrayUtils,\n  date: dateUtils,\n  \n  // Version info\n  version: require('./package.json').version,\n  \n  // Utility function to get all available functions\n  getAvailableFunctions() {\n    return {\n      string: Object.keys(stringUtils),\n      array: Object.keys(arrayUtils),\n      date: Object.keys(dateUtils)\n    };\n  }\n};\n```\n\n**Step 4: Create Utility Modules:**\n```javascript\n// lib/string-utils.js\nmodule.exports = {\n  capitalize(str) {\n    if (typeof str !== 'string') return '';\n    return str.charAt(0).toUpperCase() + str.slice(1).toLowerCase();\n  },\n  \n  slugify(str) {\n    return str\n      .toLowerCase()\n      .replace(/[^a-z0-9\\s-]/g, '')\n      .replace(/\\s+/g, '-')\n      .replace(/-+/g, '-')\n      .trim();\n  },\n  \n  truncate(str, length = 100, suffix = '...') {\n    if (str.length <= length) return str;\n    return str.substring(0, length) + suffix;\n  },\n  \n  isEmail(email) {\n    const emailRegex = /^[^\\s@]+@[^\\s@]+\\.[^\\s@]+$/;\n    return emailRegex.test(email);\n  }\n};\n\n// lib/array-utils.js\nmodule.exports = {\n  chunk(array, size) {\n    const chunks = [];\n    for (let i = 0; i < array.length; i += size) {\n      chunks.push(array.slice(i, i + size));\n    }\n    return chunks;\n  },\n  \n  unique(array) {\n    return [...new Set(array)];\n  },\n  \n  shuffle(array) {\n    const shuffled = [...array];\n    for (let i = shuffled.length - 1; i > 0; i--) {\n      const j = Math.floor(Math.random() * (i + 1));\n      [shuffled[i], shuffled[j]] = [shuffled[j], shuffled[i]];\n    }\n    return shuffled;\n  },\n  \n  groupBy(array, key) {\n    return array.reduce((groups, item) => {\n      const group = typeof key === 'function' ? key(item) : item[key];\n      groups[group] = groups[group] || [];\n      groups[group].push(item);\n      return groups;\n    }, {});\n  }\n};\n\n// lib/date-utils.js\nmodule.exports = {\n  formatDate(date, format = 'YYYY-MM-DD') {\n    const d = new Date(date);\n    const year = d.getFullYear();\n    const month = String(d.getMonth() + 1).padStart(2, '0');\n    const day = String(d.getDate()).padStart(2, '0');\n    \n    return format\n      .replace('YYYY', year)\n      .replace('MM', month)\n      .replace('DD', day);\n  },\n  \n  addDays(date, days) {\n    const result = new Date(date);\n    result.setDate(result.getDate() + days);\n    return result;\n  },\n  \n  diffInDays(date1, date2) {\n    const oneDay = 24 * 60 * 60 * 1000;\n    return Math.round(Math.abs((date1 - date2) / oneDay));\n  },\n  \n  isWeekend(date) {\n    const day = new Date(date).getDay();\n    return day === 0 || day === 6; // Sunday = 0, Saturday = 6\n  }\n};\n```\n\n**Step 5: Create Tests:**\n```javascript\n// tests/string-utils.test.js\nconst { string } = require('../index');\n\ntest('capitalize function', () => {\n  expect(string.capitalize('hello world')).toBe('Hello world');\n  expect(string.capitalize('HELLO WORLD')).toBe('Hello world');\n  expect(string.capitalize('')).toBe('');\n});\n\ntest('slugify function', () => {\n  expect(string.slugify('Hello World!')).toBe('hello-world');\n  expect(string.slugify('Test   Multiple   Spaces')).toBe('test-multiple-spaces');\n});\n\ntest('email validation', () => {\n  expect(string.isEmail('test@example.com')).toBe(true);\n  expect(string.isEmail('invalid-email')).toBe(false);\n});\n```\n\n**Step 6: Publishing Process:**\n```bash\n# Create .npmignore file\necho \"tests/\\n*.test.js\\n.git\\nnode_modules\" > .npmignore\n\n# Login to NPM (one time setup)\nnpm login\n\n# Run tests\nnpm test\n\n# Check package contents\nnpm pack --dry-run\n\n# Publish package\nnpm publish\n\n# For scoped packages\nnpm publish --access public\n```\n\n**Step 7: Using Published Package:**\n```bash\n# Install your package\nnpm install my-awesome-utility\n\n# Use in code\n```\n\n```javascript\n// Using the published package\nconst utils = require('my-awesome-utility');\n\nconsole.log(utils.string.capitalize('hello world'));\nconsole.log(utils.array.unique([1, 2, 2, 3, 3, 4]));\nconsole.log(utils.date.formatDate(new Date(), 'DD/MM/YYYY'));\nconsole.log('Available functions:', utils.getAvailableFunctions());\n```\n\n**Best Practices:**\n- Use semantic versioning (semver)\n- Include comprehensive README.md\n- Add proper error handling\n- Write unit tests\n- Use .npmignore to exclude unnecessary files\n- Document your API clearly\n- Consider TypeScript definitions\n- Test your package before publishing",
        "difficulty": "Medium",
        "category": "Modules"
    },
    {
        "id": 29,
        "question": "What is npm audit, semantic versioning (semver), and security best practices for package management?",
        "solution": "**NPM Security and Package Management** are crucial for maintaining secure Node.js applications.\n\n**1. NPM Audit:**\n`npm audit` scans your project for known security vulnerabilities in dependencies and provides recommendations.\n\n```bash\n# Run security audit\nnpm audit\n\n# Automatically fix vulnerabilities\nnpm audit fix\n\n# Force fix (may introduce breaking changes)\nnpm audit fix --force\n\n# Generate audit report\nnpm audit --json > audit-report.json\n\n# Audit production dependencies only\nnpm audit --production\n```\n\n**Audit Output Example:**\n```javascript\n// Example audit response\n{\n  \"auditReportVersion\": 2,\n  \"vulnerabilities\": {\n    \"lodash\": {\n      \"name\": \"lodash\",\n      \"severity\": \"high\",\n      \"isDirect\": false,\n      \"via\": [\"prototype-pollution\"],\n      \"range\": \"<4.17.21\",\n      \"nodes\": [\"node_modules/lodash\"],\n      \"fixAvailable\": {\n        \"name\": \"lodash\",\n        \"version\": \"4.17.21\",\n        \"isSemVerMajor\": false\n      }\n    }\n  },\n  \"metadata\": {\n    \"vulnerabilities\": {\n      \"info\": 0,\n      \"low\": 1,\n      \"moderate\": 2,\n      \"high\": 1,\n      \"critical\": 0\n    }\n  }\n}\n```\n\n**2. Semantic Versioning (SemVer):**\nVersioning scheme using `MAJOR.MINOR.PATCH` format:\n\n```javascript\n// Version format: MAJOR.MINOR.PATCH\n// Example: 2.1.3\n\n// MAJOR (2): Breaking changes - incompatible API changes\n// MINOR (1): New features - backward-compatible functionality\n// PATCH (3): Bug fixes - backward-compatible bug fixes\n\n// Version ranges in package.json\n{\n  \"dependencies\": {\n    \"express\": \"^4.18.0\",     // ^4.18.0 - Compatible with 4.x.x (>= 4.18.0, < 5.0.0)\n    \"lodash\": \"~4.17.21\",     // ~4.17.21 - Patch-level changes (>= 4.17.21, < 4.18.0)\n    \"moment\": \"4.17.21\",      // Exact version\n    \"react\": \">=16.0.0\",      // Greater than or equal\n    \"vue\": \"<3.0.0\",          // Less than\n    \"axios\": \"*\"              // Any version (not recommended)\n  }\n}\n\n// Understanding version ranges\nconst versionExamples = {\n  '^1.2.3': 'Allows 1.2.3 to 1.x.x (but not 2.0.0)',\n  '~1.2.3': 'Allows 1.2.3 to 1.2.x (but not 1.3.0)',\n  '1.2.3': 'Exact version only',\n  '>=1.2.3': 'Version 1.2.3 or higher',\n  '1.2.x': 'Any patch version in 1.2 series'\n};\n\nconsole.log('SemVer Examples:', versionExamples);\n```\n\n**3. Security Best Practices:**\n\n**Package Vetting:**\n```javascript\n// Before installing a package, check:\nconst packageVetting = {\n  popularity: 'Check weekly downloads on npmjs.com',\n  maintenance: 'Look for recent updates and active issues',\n  security: 'Check for known vulnerabilities',\n  reputation: 'Research maintainer and community trust',\n  alternatives: 'Compare with similar packages',\n  size: 'Consider bundle size impact'\n};\n\n// Check package information\nfunction checkPackageInfo(packageName) {\n  console.log(`Researching ${packageName}:`);\n  console.log(`• npm info ${packageName}`);\n  console.log(`• npm view ${packageName} dependencies`);\n  console.log(`• npm view ${packageName} repository`);\n  console.log(`• Check https://snyk.io/vuln/npm:${packageName}`);\n}\n\ncheckPackageInfo('example-package');\n```\n\n**Dependency Management:**\n```json\n// .npmrc configuration\nregistry=https://registry.npmjs.org/\naudit-level=moderate\nfund=false\nsave-exact=true\nengine-strict=true\n```\n\n**Security Commands:**\n```bash\n# Install with audit\nnpm install --audit\n\n# Check for outdated packages\nnpm outdated\n\n# Update packages safely\nnpm update\n\n# Check package licenses\nnpm ls --depth=0\nnpx license-checker\n\n# Use npm ci in production (faster, uses package-lock.json)\nnpm ci\n```\n\n**Advanced Security Practices:**\n```javascript\n// package.json security configuration\n{\n  \"scripts\": {\n    \"preinstall\": \"npm audit\",\n    \"security-audit\": \"npm audit && npm outdated\",\n    \"deps-check\": \"npx depcheck\",\n    \"license-check\": \"npx license-checker\"\n  },\n  \"engines\": {\n    \"node\": \">=16.0.0\",\n    \"npm\": \">=8.0.0\"\n  },\n  \"overrides\": {\n    // Force specific versions to fix vulnerabilities\n    \"lodash\": \"4.17.21\",\n    \"minimist\": \"1.2.6\"\n  }\n}\n```\n\n**Automated Security Tools:**\n```javascript\n// Integrate security tools in CI/CD\nconst securityTools = {\n  snyk: 'snyk test && snyk monitor',\n  auditCi: 'npx audit-ci --moderate',\n  retireJs: 'npx retire',\n  nsp: 'npx nsp check' // Legacy, now part of npm audit\n};\n\n// GitHub Actions security workflow\nconst githubAction = `\nname: Security Audit\non: [push, pull_request]\njobs:\n  security:\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2\n    - name: Setup Node.js\n      uses: actions/setup-node@v2\n      with:\n        node-version: '18'\n    - name: Install dependencies\n      run: npm ci\n    - name: Run security audit\n      run: npm audit --audit-level=high\n    - name: Check for outdated packages\n      run: npm outdated\n`;\n```\n\n**Best Practices Summary:**\n- Run `npm audit` regularly and fix vulnerabilities promptly\n- Use `package-lock.json` for consistent installations\n- Pin exact versions for critical dependencies\n- Regularly update dependencies\n- Use `npm ci` in production environments\n- Implement automated security scanning in CI/CD\n- Review dependencies before adding them\n- Monitor dependency licenses for compliance\n- Use tools like Snyk or WhiteSource for continuous monitoring",
        "difficulty": "Medium",
        "category": "Security"
    },
    {
        "id": 30,
        "question": "What are streams in Node.js? Explain readable, writable, duplex, and transform streams with practical examples.",
        "solution": "**Streams** in Node.js are objects that handle data piece by piece, rather than loading entire content into memory. This is crucial for handling large files or real-time data efficiently.\n\n**Types of Streams:**\n\n**1. Readable Streams** - Read data from a source:\n```javascript\nimport fs from 'fs';\nimport { Readable } from 'stream';\n\n// File readable stream\nconst readableStream = fs.createReadStream('large-file.txt', {\n  encoding: 'utf8',\n  highWaterMark: 1024 // Buffer size in bytes\n});\n\nreadableStream.on('data', (chunk) => {\n  console.log('Received chunk:', chunk.length, 'bytes');\n});\n\nreadableStream.on('end', () => {\n  console.log('Reading complete');\n});\n\nreadableStream.on('error', (error) => {\n  console.error('Read error:', error);\n});\n\n// Custom readable stream\nclass NumberStream extends Readable {\n  constructor(max, options) {\n    super(options);\n    this.current = 0;\n    this.max = max;\n  }\n  \n  _read() {\n    if (this.current < this.max) {\n      this.push(`Number: ${this.current++}\\n`);\n    } else {\n      this.push(null); // End the stream\n    }\n  }\n}\n\nconst numberStream = new NumberStream(5);\nnumberStream.on('data', (chunk) => {\n  console.log(chunk.toString());\n});\n```\n\n**2. Writable Streams** - Write data to a destination:\n```javascript\nimport fs from 'fs';\nimport { Writable } from 'stream';\n\n// File writable stream\nconst writableStream = fs.createWriteStream('output.txt');\n\nwritableStream.write('Hello ');\nwritableStream.write('World!');\nwritableStream.end(); // Signal end of writing\n\nwritableStream.on('finish', () => {\n  console.log('Writing complete');\n});\n\nwritableStream.on('error', (error) => {\n  console.error('Write error:', error);\n});\n\n// Custom writable stream\nclass ConsoleWriteStream extends Writable {\n  constructor(options) {\n    super(options);\n    this.lineCount = 0;\n  }\n  \n  _write(chunk, encoding, callback) {\n    this.lineCount++;\n    console.log(`[Line ${this.lineCount}] ${chunk.toString().trim()}`);\n    callback(); // Signal completion\n  }\n}\n\nconst consoleWriter = new ConsoleWriteStream();\nconsoleWriter.write('First line\\n');\nconsoleWriter.write('Second line\\n');\nconsoleWriter.end();\n```\n\n**3. Duplex Streams** - Both readable and writable:\n```javascript\nimport { Duplex } from 'stream';\nimport net from 'net';\n\n// TCP socket is a duplex stream\nconst server = net.createServer((socket) => {\n  console.log('Client connected');\n  \n  // Socket is duplex - can read and write\n  socket.write('Welcome to the server!\\n');\n  \n  socket.on('data', (data) => {\n    console.log('Received:', data.toString());\n    socket.write(`Echo: ${data}`);\n  });\n  \n  socket.on('end', () => {\n    console.log('Client disconnected');\n  });\n});\n\n// Custom duplex stream\nclass EchoStream extends Duplex {\n  constructor(options) {\n    super(options);\n    this.buffer = [];\n  }\n  \n  _read() {\n    if (this.buffer.length > 0) {\n      this.push(this.buffer.shift());\n    }\n  }\n  \n  _write(chunk, encoding, callback) {\n    // Echo back with prefix\n    this.buffer.push(`ECHO: ${chunk}`);\n    callback();\n  }\n}\n\nconst echoStream = new EchoStream();\nechoStream.write('Hello');\nechoStream.on('data', (data) => {\n  console.log('Echoed:', data.toString());\n});\n```\n\n**4. Transform Streams** - Modify data as it passes through:\n```javascript\nimport { Transform } from 'stream';\nimport zlib from 'zlib';\n\n// Built-in transform stream (gzip)\nconst gzip = zlib.createGzip();\nfs.createReadStream('input.txt')\n  .pipe(gzip)\n  .pipe(fs.createWriteStream('output.txt.gz'));\n\n// Custom transform stream\nclass UpperCaseTransform extends Transform {\n  _transform(chunk, encoding, callback) {\n    // Convert to uppercase\n    const upperChunk = chunk.toString().toUpperCase();\n    this.push(upperChunk);\n    callback();\n  }\n}\n\nclass LineNumberTransform extends Transform {\n  constructor(options) {\n    super(options);\n    this.lineNumber = 0;\n  }\n  \n  _transform(chunk, encoding, callback) {\n    const lines = chunk.toString().split('\\n');\n    const numberedLines = lines.map(line => {\n      if (line.trim()) {\n        return `${++this.lineNumber}: ${line}`;\n      }\n      return line;\n    }).join('\\n');\n    \n    this.push(numberedLines);\n    callback();\n  }\n}\n\n// JSON processor transform\nclass JSONTransform extends Transform {\n  constructor(options) {\n    super({ objectMode: true, ...options });\n  }\n  \n  _transform(chunk, encoding, callback) {\n    try {\n      const obj = JSON.parse(chunk);\n      // Add timestamp to JSON objects\n      obj.processedAt = new Date().toISOString();\n      this.push(JSON.stringify(obj) + '\\n');\n    } catch (error) {\n      this.emit('error', error);\n    }\n    callback();\n  }\n}\n```\n\n**Piping Streams:**\n```javascript\nimport fs from 'fs';\nimport { pipeline } from 'stream/promises';\n\n// Basic piping\nfs.createReadStream('input.txt')\n  .pipe(new UpperCaseTransform())\n  .pipe(new LineNumberTransform())\n  .pipe(fs.createWriteStream('output.txt'));\n\n// Advanced piping with error handling\nasync function processFile() {\n  try {\n    await pipeline(\n      fs.createReadStream('large-input.txt'),\n      new UpperCaseTransform(),\n      new LineNumberTransform(),\n      fs.createWriteStream('processed-output.txt')\n    );\n    console.log('Pipeline completed successfully');\n  } catch (error) {\n    console.error('Pipeline failed:', error);\n  }\n}\n\nprocessFile();\n```\n\n**Real-world Example - CSV Processor:**\n```javascript\nimport { Transform } from 'stream';\nimport fs from 'fs';\n\nclass CSVParser extends Transform {\n  constructor(options) {\n    super({ objectMode: true, ...options });\n    this.headers = null;\n    this.buffer = '';\n  }\n  \n  _transform(chunk, encoding, callback) {\n    this.buffer += chunk.toString();\n    const lines = this.buffer.split('\\n');\n    \n    // Keep the last incomplete line in buffer\n    this.buffer = lines.pop();\n    \n    lines.forEach((line, index) => {\n      if (line.trim()) {\n        if (!this.headers) {\n          this.headers = line.split(',').map(h => h.trim());\n        } else {\n          const values = line.split(',').map(v => v.trim());\n          const obj = {};\n          this.headers.forEach((header, i) => {\n            obj[header] = values[i] || '';\n          });\n          this.push(obj);\n        }\n      }\n    });\n    \n    callback();\n  }\n  \n  _flush(callback) {\n    // Process remaining data in buffer\n    if (this.buffer.trim() && this.headers) {\n      const values = this.buffer.split(',').map(v => v.trim());\n      const obj = {};\n      this.headers.forEach((header, i) => {\n        obj[header] = values[i] || '';\n      });\n      this.push(obj);\n    }\n    callback();\n  }\n}\n\nclass JSONStringify extends Transform {\n  constructor(options) {\n    super({ objectMode: true, ...options });\n    this.first = true;\n  }\n  \n  _transform(chunk, encoding, callback) {\n    if (this.first) {\n      this.push('[');\n      this.first = false;\n    } else {\n      this.push(',');\n    }\n    this.push(JSON.stringify(chunk));\n    callback();\n  }\n  \n  _flush(callback) {\n    this.push(']');\n    callback();\n  }\n}\n\n// Usage: Convert CSV to JSON\nfs.createReadStream('data.csv')\n  .pipe(new CSVParser())\n  .pipe(new JSONStringify())\n  .pipe(fs.createWriteStream('data.json'))\n  .on('finish', () => {\n    console.log('CSV to JSON conversion complete');\n  });\n```\n\n**Stream Utilities:**\n```javascript\nimport { pipeline, Readable, Writable } from 'stream';\n\n// Create readable from array\nfunction createReadableFromArray(array) {\n  let index = 0;\n  return new Readable({\n    objectMode: true,\n    read() {\n      if (index < array.length) {\n        this.push(array[index++]);\n      } else {\n        this.push(null);\n      }\n    }\n  });\n}\n\n// Create writable that collects data\nfunction createCollectorWritable() {\n  const collected = [];\n  const writable = new Writable({\n    objectMode: true,\n    write(chunk, encoding, callback) {\n      collected.push(chunk);\n      callback();\n    }\n  });\n  writable.collected = collected;\n  return writable;\n}\n\n// Usage\nconst data = [1, 2, 3, 4, 5];\nconst readable = createReadableFromArray(data);\nconst collector = createCollectorWritable();\n\nreadable.pipe(collector);\ncollector.on('finish', () => {\n  console.log('Collected:', collector.collected);\n});\n```\n\n**Benefits of Streams:**\n- **Memory Efficiency**: Process data without loading all into memory\n- **Time Efficiency**: Start processing as soon as first chunk arrives\n- **Backpressure Handling**: Automatically manages flow control\n- **Composability**: Can pipe streams together for complex processing\n- **Real-time Processing**: Handle continuous data streams",
        "difficulty": "Hard",
        "category": "Streams"
    },
    {
        "id": 31,
        "question": "What is backpressure in Node.js streams and how do you handle large files efficiently?",
        "solution": "**Backpressure** occurs when a readable stream produces data faster than a writable stream can consume it, causing memory buildup. Node.js handles this automatically in most cases.\n\n**Understanding Backpressure:**\n```javascript\nimport fs from 'fs';\nimport { pipeline } from 'stream/promises';\nimport { Transform } from 'stream';\n\n// Example of potential backpressure issue\nconst slowProcessor = new Transform({\n  transform(chunk, encoding, callback) {\n    // Simulate slow processing\n    setTimeout(() => {\n      this.push(chunk.toString().toUpperCase());\n      callback();\n    }, 100); // 100ms delay per chunk\n  }\n});\n\n// This could cause backpressure if input is faster than processing\nfs.createReadStream('large-file.txt')\n  .pipe(slowProcessor)\n  .pipe(fs.createWriteStream('output.txt'));\n```\n\n**Manual Backpressure Handling:**\n```javascript\nimport fs from 'fs';\n\n// Manual backpressure control\nfunction copyFileWithBackpressure(source, destination) {\n  const readable = fs.createReadStream(source);\n  const writable = fs.createWriteStream(destination);\n  \n  readable.on('data', (chunk) => {\n    const canWriteMore = writable.write(chunk);\n    \n    if (!canWriteMore) {\n      // Pause reading until writable drains\n      readable.pause();\n      \n      writable.once('drain', () => {\n        readable.resume();\n      });\n    }\n  });\n  \n  readable.on('end', () => {\n    writable.end();\n  });\n  \n  readable.on('error', (err) => {\n    writable.destroy(err);\n  });\n  \n  writable.on('error', (err) => {\n    readable.destroy(err);\n  });\n}\n\n// Usage\ncopyFileWithBackpressure('large-input.txt', 'large-output.txt');\n```\n\n**Efficient Large File Processing:**\n\n**1. Memory-Efficient File Reading:**\n```javascript\nimport fs from 'fs';\nimport { createReadStream } from 'fs';\n\n// Bad: Reading entire file into memory\nfunction readFileBad(filename) {\n  // This will crash with large files (>1GB)\n  fs.readFile(filename, (err, data) => {\n    if (err) throw err;\n    console.log('File size:', data.length);\n    // Process entire file at once\n  });\n}\n\n// Good: Streaming approach\nfunction readFileGood(filename) {\n  let totalSize = 0;\n  \n  const stream = createReadStream(filename, {\n    highWaterMark: 64 * 1024 // 64KB chunks\n  });\n  \n  stream.on('data', (chunk) => {\n    totalSize += chunk.length;\n    console.log(`Processed chunk: ${chunk.length} bytes`);\n    // Process chunk by chunk\n  });\n  \n  stream.on('end', () => {\n    console.log(`Total file size: ${totalSize} bytes`);\n  });\n  \n  stream.on('error', (err) => {\n    console.error('Error reading file:', err);\n  });\n}\n\nreadFileGood('very-large-file.txt');\n```\n\n**2. Large File Processing Pipeline:**\n```javascript\nimport { Transform, pipeline } from 'stream';\nimport fs from 'fs';\nimport zlib from 'zlib';\n\n// Log file analyzer for large files\nclass LogAnalyzer extends Transform {\n  constructor(options) {\n    super({ ...options });\n    this.lineCount = 0;\n    this.errorCount = 0;\n    this.warningCount = 0;\n    this.buffer = '';\n  }\n  \n  _transform(chunk, encoding, callback) {\n    this.buffer += chunk.toString();\n    const lines = this.buffer.split('\\n');\n    \n    // Keep last incomplete line\n    this.buffer = lines.pop();\n    \n    lines.forEach(line => {\n      this.lineCount++;\n      \n      if (line.includes('ERROR')) {\n        this.errorCount++;\n        this.push(`Line ${this.lineCount}: ERROR - ${line}\\n`);\n      } else if (line.includes('WARN')) {\n        this.warningCount++;\n        this.push(`Line ${this.lineCount}: WARNING - ${line}\\n`);\n      }\n      \n      // Report progress every 10000 lines\n      if (this.lineCount % 10000 === 0) {\n        console.log(`Processed ${this.lineCount} lines`);\n      }\n    });\n    \n    callback();\n  }\n  \n  _flush(callback) {\n    // Process remaining buffer\n    if (this.buffer) {\n      this.lineCount++;\n      if (this.buffer.includes('ERROR') || this.buffer.includes('WARN')) {\n        this.push(`Line ${this.lineCount}: ${this.buffer}\\n`);\n      }\n    }\n    \n    // Emit summary\n    this.push(`\\n=== SUMMARY ===\\n`);\n    this.push(`Total lines: ${this.lineCount}\\n`);\n    this.push(`Errors: ${this.errorCount}\\n`);\n    this.push(`Warnings: ${this.warningCount}\\n`);\n    \n    callback();\n  }\n}\n\n// Process large log file\nasync function processLargeLogFile() {\n  try {\n    await pipeline(\n      fs.createReadStream('application.log'), // Large log file\n      new LogAnalyzer(),\n      zlib.createGzip(), // Compress output\n      fs.createWriteStream('errors-and-warnings.log.gz')\n    );\n    console.log('Log analysis complete!');\n  } catch (error) {\n    console.error('Pipeline failed:', error);\n  }\n}\n\nprocessLargeLogFile();\n```\n\n**3. Chunk-based Processing:**\n```javascript\nimport fs from 'fs';\n\n// Process large file in controlled chunks\nclass ChunkedProcessor {\n  constructor(filename, chunkSize = 1024 * 1024) { // 1MB chunks\n    this.filename = filename;\n    this.chunkSize = chunkSize;\n    this.position = 0;\n    this.fileSize = 0;\n  }\n  \n  async initialize() {\n    const stats = await fs.promises.stat(this.filename);\n    this.fileSize = stats.size;\n    console.log(`File size: ${this.fileSize} bytes`);\n  }\n  \n  async processChunk(chunk, chunkNumber) {\n    // Simulate processing (e.g., data transformation, analysis)\n    console.log(`Processing chunk ${chunkNumber}: ${chunk.length} bytes`);\n    \n    // Add artificial delay to simulate heavy processing\n    await new Promise(resolve => setTimeout(resolve, 10));\n    \n    return chunk.toString().toUpperCase();\n  }\n  \n  async processFile() {\n    await this.initialize();\n    \n    const fileHandle = await fs.promises.open(this.filename, 'r');\n    const outputHandle = await fs.promises.open('processed-output.txt', 'w');\n    \n    let chunkNumber = 0;\n    \n    try {\n      while (this.position < this.fileSize) {\n        const remainingBytes = this.fileSize - this.position;\n        const bytesToRead = Math.min(this.chunkSize, remainingBytes);\n        \n        const buffer = Buffer.alloc(bytesToRead);\n        const { bytesRead } = await fileHandle.read(\n          buffer, 0, bytesToRead, this.position\n        );\n        \n        if (bytesRead === 0) break;\n        \n        const processedChunk = await this.processChunk(\n          buffer.slice(0, bytesRead), \n          ++chunkNumber\n        );\n        \n        await outputHandle.write(processedChunk);\n        \n        this.position += bytesRead;\n        \n        // Report progress\n        const progress = ((this.position / this.fileSize) * 100).toFixed(2);\n        console.log(`Progress: ${progress}%`);\n      }\n    } finally {\n      await fileHandle.close();\n      await outputHandle.close();\n    }\n    \n    console.log('File processing complete!');\n  }\n}\n\n// Usage\nconst processor = new ChunkedProcessor('large-data-file.txt');\nprocessor.processFile().catch(console.error);\n```\n\n**4. Memory Monitoring:**\n```javascript\nclass MemoryMonitor {\n  static logMemoryUsage(label = '') {\n    const usage = process.memoryUsage();\n    console.log(`Memory Usage ${label}:`, {\n      rss: `${Math.round(usage.rss / 1024 / 1024)} MB`,\n      heapTotal: `${Math.round(usage.heapTotal / 1024 / 1024)} MB`,\n      heapUsed: `${Math.round(usage.heapUsed / 1024 / 1024)} MB`,\n      external: `${Math.round(usage.external / 1024 / 1024)} MB`\n    });\n  }\n  \n  static startMonitoring(interval = 5000) {\n    return setInterval(() => {\n      this.logMemoryUsage('Periodic');\n      \n      // Trigger garbage collection if memory usage is high\n      if (global.gc && usage.heapUsed > 500 * 1024 * 1024) {\n        global.gc();\n        console.log('Garbage collection triggered');\n      }\n    }, interval);\n  }\n}\n\n// Monitor memory during file processing\nconst monitor = MemoryMonitor.startMonitoring();\n\n// Your file processing code here\nprocessLargeFile().finally(() => {\n  clearInterval(monitor);\n  MemoryMonitor.logMemoryUsage('Final');\n});\n```\n\n**Best Practices for Large Files:**\n\n1. **Use Streams**: Always prefer streams over reading entire files\n2. **Control Chunk Size**: Adjust `highWaterMark` based on available memory\n3. **Monitor Memory**: Track memory usage during processing\n4. **Handle Backpressure**: Use `pipeline()` or manual drain handling\n5. **Process in Batches**: Break large operations into smaller chunks\n6. **Use Transform Streams**: For data modification during streaming\n7. **Implement Progress Reporting**: Keep users informed of long operations\n8. **Error Handling**: Properly handle and cleanup on errors\n\n**Pipeline vs Manual Streaming:**\n```javascript\n// Preferred: Using pipeline (handles backpressure automatically)\nawait pipeline(\n  fs.createReadStream('input.txt'),\n  new MyTransform(),\n  fs.createWriteStream('output.txt')\n);\n\n// Manual: Only when you need fine control\nconst readable = fs.createReadStream('input.txt');\nconst writable = fs.createWriteStream('output.txt');\nreadable.pipe(writable);\n```",
        "difficulty": "Hard",
        "category": "Streams"
    },
    {
        "id": 32,
        "question": "Explain the Buffer class in Node.js. How do you handle binary data and what's the difference between Buffer and ArrayBuffer?",
        "solution": "The **Buffer class** is a global object in Node.js that represents a fixed-size, raw binary data container. It's essential for working with binary data in network communication, file operations, and cryptographic functions.\n\n**Creating Buffers:**\n```javascript\n// Different ways to create buffers\n\n// 1. From string\nconst buf1 = Buffer.from('Hello Node.js', 'utf8');\nconsole.log(buf1); // <Buffer 48 65 6c 6c 6f 20 4e 6f 64 65 2e 6a 73>\nconsole.log(buf1.toString()); // Hello Node.js\n\n// 2. From array of bytes\nconst buf2 = Buffer.from([72, 101, 108, 108, 111]); // 'Hello' in ASCII\nconsole.log(buf2.toString()); // Hello\n\n// 3. Allocate zero-filled buffer (safe)\nconst buf3 = Buffer.alloc(10); // 10 bytes filled with zeros\nconsole.log(buf3); // <Buffer 00 00 00 00 00 00 00 00 00 00>\n\n// 4. Allocate uninitialized buffer (faster but potentially unsafe)\nconst buf4 = Buffer.allocUnsafe(10); // Contains random data\nconsole.log(buf4); // <Buffer ?? ?? ?? ?? ?? ?? ?? ?? ?? ??>\nbuf4.fill(0); // Clear it manually\n\n// 5. From hex string\nconst buf5 = Buffer.from('48656c6c6f', 'hex');\nconsole.log(buf5.toString()); // Hello\n\n// 6. From base64\nconst buf6 = Buffer.from('SGVsbG8gV29ybGQ=', 'base64');\nconsole.log(buf6.toString()); // Hello World\n```\n\n**Buffer Operations:**\n```javascript\nconst buffer = Buffer.from('Hello World');\n\n// Length and indexing\nconsole.log('Buffer length:', buffer.length); // 11\nconsole.log('First byte:', buffer[0]); // 72 (ASCII for 'H')\nconsole.log('Last byte:', buffer[buffer.length - 1]); // 100 (ASCII for 'd')\n\n// Slicing (returns new buffer that references same memory)\nconst slice = buffer.slice(0, 5);\nconsole.log(slice.toString()); // Hello\n\n// Copying\nconst copy = Buffer.alloc(buffer.length);\nbuffer.copy(copy);\nconsole.log(copy.toString()); // Hello World\n\n// Concatenation\nconst buf1 = Buffer.from('Hello ');\nconst buf2 = Buffer.from('World');\nconst concatenated = Buffer.concat([buf1, buf2]);\nconsole.log(concatenated.toString()); // Hello World\n\n// Comparison\nconst bufA = Buffer.from('ABC');\nconst bufB = Buffer.from('ABC');\nconst bufC = Buffer.from('BCD');\nconsole.log(bufA.equals(bufB)); // true\nconsole.log(bufA.equals(bufC)); // false\nconsole.log(Buffer.compare(bufA, bufC)); // -1 (bufA < bufC)\n```\n\n**Encoding/Decoding:**\n```javascript\nconst text = 'Hello 世界 🌍';\nconst buffer = Buffer.from(text, 'utf8');\n\n// Different encoding outputs\nconsole.log('UTF-8:', buffer.toString('utf8'));\nconsole.log('Hex:', buffer.toString('hex'));\nconsole.log('Base64:', buffer.toString('base64'));\nconsole.log('Binary:', buffer.toString('binary'));\n\n// Supported encodings\nconst encodings = [\n  'ascii', 'utf8', 'utf16le', 'ucs2', \n  'base64', 'base64url', 'latin1', 'binary', 'hex'\n];\n\nencodings.forEach(encoding => {\n  try {\n    const encoded = buffer.toString(encoding);\n    console.log(`${encoding}: ${encoded.substring(0, 20)}...`);\n  } catch (error) {\n    console.log(`${encoding}: Error - ${error.message}`);\n  }\n});\n```\n\n**Working with Binary Data:**\n```javascript\n// Reading binary file data\nimport fs from 'fs';\n\n// Read image file as buffer\nconst imageBuffer = fs.readFileSync('image.jpg');\nconsole.log('Image size:', imageBuffer.length, 'bytes');\nconsole.log('First few bytes:', imageBuffer.slice(0, 10));\n\n// Check file type by magic numbers\nfunction getFileType(buffer) {\n  const header = buffer.slice(0, 4);\n  \n  if (header[0] === 0xFF && header[1] === 0xD8 && header[2] === 0xFF) {\n    return 'JPEG';\n  } else if (header[0] === 0x89 && header[1] === 0x50 && header[2] === 0x4E && header[3] === 0x47) {\n    return 'PNG';\n  } else if (header[0] === 0x47 && header[1] === 0x49 && header[2] === 0x46) {\n    return 'GIF';\n  } else if (header[0] === 0x25 && header[1] === 0x50 && header[2] === 0x44 && header[3] === 0x46) {\n    return 'PDF';\n  }\n  \n  return 'Unknown';\n}\n\nconsole.log('File type:', getFileType(imageBuffer));\n\n// Writing binary data\nconst binaryData = Buffer.from([\n  0x89, 0x50, 0x4E, 0x47, 0x0D, 0x0A, 0x1A, 0x0A // PNG header\n]);\nfs.writeFileSync('header.bin', binaryData);\n```\n\n**Buffer vs ArrayBuffer:**\n\n```javascript\n// Buffer (Node.js specific)\nconst nodeBuffer = Buffer.from('Hello');\nconsole.log('Buffer:', nodeBuffer);\nconsole.log('Buffer is Buffer:', Buffer.isBuffer(nodeBuffer)); // true\nconsole.log('Buffer methods:', Object.getOwnPropertyNames(Buffer.prototype).slice(0, 10));\n\n// ArrayBuffer (JavaScript standard)\nconst arrayBuffer = new ArrayBuffer(5);\nconst uint8View = new Uint8Array(arrayBuffer);\nuint8View[0] = 72; // H\nuint8View[1] = 101; // e\nuint8View[2] = 108; // l\nuint8View[3] = 108; // l\nuint8View[4] = 111; // o\n\nconsole.log('ArrayBuffer:', arrayBuffer);\nconsole.log('Uint8Array view:', uint8View);\nconsole.log('As string:', String.fromCharCode(...uint8View)); // Hello\n\n// Converting between Buffer and ArrayBuffer\nconst bufferFromArrayBuffer = Buffer.from(arrayBuffer);\nconsole.log('Buffer from ArrayBuffer:', bufferFromArrayBuffer.toString());\n\nconst arrayBufferFromBuffer = nodeBuffer.buffer.slice(\n  nodeBuffer.byteOffset,\n  nodeBuffer.byteOffset + nodeBuffer.byteLength\n);\nconsole.log('ArrayBuffer from Buffer:', new Uint8Array(arrayBufferFromBuffer));\n```\n\n**Key Differences:**\n\n| Feature | Buffer | ArrayBuffer |\n|---------|--------|-------------|\n| **Environment** | Node.js specific | JavaScript standard (browser + Node.js) |\n| **Mutability** | Mutable | Immutable (need TypedArray views) |\n| **Methods** | Rich API (slice, copy, concat, etc.) | Minimal API (needs views) |\n| **String Conversion** | Built-in `toString()` with encodings | Manual conversion needed |\n| **Memory Pool** | Uses memory pool for efficiency | Individual allocations |\n| **Size Limit** | ~2GB on 64-bit, ~1GB on 32-bit | Platform dependent |\n\n**Practical Examples:**\n\n**1. Network Data Processing:**\n```javascript\nimport net from 'net';\n\nconst server = net.createServer((socket) => {\n  socket.on('data', (buffer) => {\n    console.log('Received bytes:', buffer.length);\n    console.log('Data as hex:', buffer.toString('hex'));\n    console.log('Data as text:', buffer.toString('utf8'));\n    \n    // Echo back the data\n    socket.write(buffer);\n  });\n});\n\nserver.listen(3000, () => {\n  console.log('Binary server listening on port 3000');\n});\n```\n\n**2. Cryptographic Operations:**\n```javascript\nimport crypto from 'crypto';\n\nfunction hashBuffer(buffer) {\n  const hash = crypto.createHash('sha256');\n  hash.update(buffer);\n  return hash.digest();\n}\n\nfunction encryptBuffer(buffer, key) {\n  const cipher = crypto.createCipher('aes-256-cbc', key);\n  return Buffer.concat([cipher.update(buffer), cipher.final()]);\n}\n\nconst data = Buffer.from('Sensitive data');\nconst key = 'my-secret-key';\n\nconst hash = hashBuffer(data);\nconst encrypted = encryptBuffer(data, key);\n\nconsole.log('Original:', data.toString());\nconsole.log('Hash (hex):', hash.toString('hex'));\nconsole.log('Encrypted (base64):', encrypted.toString('base64'));\n```\n\n**3. Binary Protocol Implementation:**\n```javascript\nclass BinaryProtocol {\n  static createMessage(type, data) {\n    const typeBuffer = Buffer.from([type]);\n    const lengthBuffer = Buffer.alloc(4);\n    lengthBuffer.writeUInt32BE(data.length, 0);\n    \n    return Buffer.concat([typeBuffer, lengthBuffer, data]);\n  }\n  \n  static parseMessage(buffer) {\n    if (buffer.length < 5) {\n      throw new Error('Invalid message: too short');\n    }\n    \n    const type = buffer.readUInt8(0);\n    const length = buffer.readUInt32BE(1);\n    const data = buffer.slice(5, 5 + length);\n    \n    return { type, length, data };\n  }\n}\n\n// Usage\nconst message = BinaryProtocol.createMessage(1, Buffer.from('Hello'));\nconsole.log('Encoded message:', message);\n\nconst parsed = BinaryProtocol.parseMessage(message);\nconsole.log('Parsed:', parsed);\nconsole.log('Data as string:', parsed.data.toString());\n```\n\n**Memory Management Best Practices:**\n```javascript\n// Use Buffer.alloc for sensitive data (zero-filled)\nconst sensitiveBuffer = Buffer.alloc(1024);\n\n// Use Buffer.allocUnsafe only when you'll immediately overwrite\nconst tempBuffer = Buffer.allocUnsafe(1024);\ntempBuffer.fill(0); // Clear manually\n\n// Pool small buffers for efficiency\nconst smallBuffers = [];\nfor (let i = 0; i < 1000; i++) {\n  smallBuffers.push(Buffer.alloc(64)); // Better than allocUnsafe for small sizes\n}\n\n// Avoid string concatenation in loops, use Buffer.concat\nfunction efficientConcatenation(buffers) {\n  return Buffer.concat(buffers);\n}\n\n// Instead of:\n// let result = Buffer.alloc(0);\n// buffers.forEach(buf => {\n//   result = Buffer.concat([result, buf]); // Creates new buffer each time\n// });\n```",
        "difficulty": "Medium",
        "category": "Binary Data"
    },
    {
        "id": 33,
        "question": "How do you perform file operations in Node.js? Explain sync vs async operations, directory management, and file permissions.",
        "solution": "Node.js provides comprehensive file system operations through the `fs` module with both **synchronous** and **asynchronous** methods.\n\n**Synchronous vs Asynchronous Operations:**\n\n**Asynchronous (Recommended):**\n```javascript\nimport fs from 'fs';\nimport path from 'path';\n\n// Callback-based async operations\nfs.readFile('config.json', 'utf8', (err, data) => {\n  if (err) {\n    console.error('Error reading file:', err);\n    return;\n  }\n  console.log('File content:', data);\n});\n\n// Promise-based async operations\nimport fsPromises from 'fs/promises';\n\nasync function fileOperationsAsync() {\n  try {\n    // Write file\n    await fsPromises.writeFile('async-file.txt', 'Hello async world!', 'utf8');\n    console.log('File written successfully');\n    \n    // Read file\n    const data = await fsPromises.readFile('async-file.txt', 'utf8');\n    console.log('File content:', data);\n    \n    // Append to file\n    await fsPromises.appendFile('async-file.txt', '\\nAppended text');\n    \n    // Get file stats\n    const stats = await fsPromises.stat('async-file.txt');\n    console.log('File stats:', {\n      size: stats.size,\n      created: stats.birthtime,\n      modified: stats.mtime,\n      isFile: stats.isFile(),\n      isDirectory: stats.isDirectory()\n    });\n    \n  } catch (error) {\n    console.error('Async operation failed:', error);\n  }\n}\n\nfileOperationsAsync();\n```\n\n**Synchronous (Use Sparingly):**\n```javascript\n// Synchronous operations - block the event loop\nfunction fileOperationsSync() {\n  try {\n    console.log('Starting sync operations...');\n    \n    // Write file synchronously\n    fs.writeFileSync('sync-file.txt', 'Hello sync world!', 'utf8');\n    console.log('Sync file written');\n    \n    // Read file synchronously\n    const data = fs.readFileSync('sync-file.txt', 'utf8');\n    console.log('Sync file content:', data);\n    \n    // Get stats synchronously\n    const stats = fs.statSync('sync-file.txt');\n    console.log('Sync file size:', stats.size);\n    \n    console.log('Sync operations complete');\n    \n  } catch (error) {\n    console.error('Sync operation failed:', error);\n  }\n}\n\n// Only use sync operations for startup scripts or CLI tools\nfileOperationsSync();\n```\n\n**Directory Management:**\n```javascript\nimport fs from 'fs/promises';\nimport path from 'path';\n\nclass DirectoryManager {\n  static async createDirectory(dirPath) {\n    try {\n      await fs.mkdir(dirPath, { recursive: true });\n      console.log(`Directory created: ${dirPath}`);\n    } catch (error) {\n      if (error.code !== 'EEXIST') {\n        throw error;\n      }\n      console.log(`Directory already exists: ${dirPath}`);\n    }\n  }\n  \n  static async listDirectory(dirPath) {\n    try {\n      const entries = await fs.readdir(dirPath, { withFileTypes: true });\n      \n      const result = {\n        files: [],\n        directories: [],\n        other: []\n      };\n      \n      for (const entry of entries) {\n        const fullPath = path.join(dirPath, entry.name);\n        const stats = await fs.stat(fullPath);\n        \n        const item = {\n          name: entry.name,\n          path: fullPath,\n          size: stats.size,\n          modified: stats.mtime,\n          permissions: stats.mode.toString(8)\n        };\n        \n        if (entry.isFile()) {\n          result.files.push(item);\n        } else if (entry.isDirectory()) {\n          result.directories.push(item);\n        } else {\n          result.other.push(item);\n        }\n      }\n      \n      return result;\n    } catch (error) {\n      console.error(`Error listing directory ${dirPath}:`, error);\n      throw error;\n    }\n  }\n  \n  static async removeDirectory(dirPath, recursive = false) {\n    try {\n      if (recursive) {\n        await fs.rm(dirPath, { recursive: true, force: true });\n      } else {\n        await fs.rmdir(dirPath);\n      }\n      console.log(`Directory removed: ${dirPath}`);\n    } catch (error) {\n      console.error(`Error removing directory ${dirPath}:`, error);\n      throw error;\n    }\n  }\n  \n  static async copyDirectory(source, destination) {\n    await this.createDirectory(destination);\n    \n    const entries = await fs.readdir(source, { withFileTypes: true });\n    \n    for (const entry of entries) {\n      const srcPath = path.join(source, entry.name);\n      const destPath = path.join(destination, entry.name);\n      \n      if (entry.isDirectory()) {\n        await this.copyDirectory(srcPath, destPath);\n      } else {\n        await fs.copyFile(srcPath, destPath);\n      }\n    }\n  }\n}\n\n// Usage examples\nasync function directoryOperations() {\n  try {\n    // Create nested directory structure\n    await DirectoryManager.createDirectory('./test/nested/deep/directory');\n    \n    // Create some test files\n    await fs.writeFile('./test/file1.txt', 'Content 1');\n    await fs.writeFile('./test/nested/file2.txt', 'Content 2');\n    \n    // List directory contents\n    const contents = await DirectoryManager.listDirectory('./test');\n    console.log('Directory contents:', contents);\n    \n    // Copy directory\n    await DirectoryManager.copyDirectory('./test', './test-backup');\n    \n    // Remove directory\n    await DirectoryManager.removeDirectory('./test-backup', true);\n    \n  } catch (error) {\n    console.error('Directory operations failed:', error);\n  }\n}\n\ndirectoryOperations();\n```\n\n**File Permissions:**\n```javascript\nimport fs from 'fs/promises';\n\nclass FilePermissions {\n  // Convert numeric mode to human-readable string\n  static modeToString(mode) {\n    const permissions = {\n      7: 'rwx', 6: 'rw-', 5: 'r-x', 4: 'r--',\n      3: '-wx', 2: '-w-', 1: '--x', 0: '---'\n    };\n    \n    const modeStr = mode.toString(8);\n    const userPerms = permissions[parseInt(modeStr.slice(-3, -2))] || '---';\n    const groupPerms = permissions[parseInt(modeStr.slice(-2, -1))] || '---';\n    const otherPerms = permissions[parseInt(modeStr.slice(-1))] || '---';\n    \n    return `${userPerms}${groupPerms}${otherPerms}`;\n  }\n  \n  static async getPermissions(filePath) {\n    try {\n      const stats = await fs.stat(filePath);\n      const mode = stats.mode;\n      \n      return {\n        numeric: mode.toString(8),\n        string: this.modeToString(mode),\n        owner: {\n          read: (mode & 0o400) !== 0,\n          write: (mode & 0o200) !== 0,\n          execute: (mode & 0o100) !== 0\n        },\n        group: {\n          read: (mode & 0o040) !== 0,\n          write: (mode & 0o020) !== 0,\n          execute: (mode & 0o010) !== 0\n        },\n        others: {\n          read: (mode & 0o004) !== 0,\n          write: (mode & 0o002) !== 0,\n          execute: (mode & 0o001) !== 0\n        }\n      };\n    } catch (error) {\n      console.error(`Error getting permissions for ${filePath}:`, error);\n      throw error;\n    }\n  }\n  \n  static async setPermissions(filePath, mode) {\n    try {\n      await fs.chmod(filePath, mode);\n      console.log(`Permissions changed for ${filePath} to ${mode.toString(8)}`);\n    } catch (error) {\n      console.error(`Error setting permissions for ${filePath}:`, error);\n      throw error;\n    }\n  }\n  \n  static async makeExecutable(filePath) {\n    const stats = await fs.stat(filePath);\n    const newMode = stats.mode | 0o111; // Add execute for all\n    await this.setPermissions(filePath, newMode);\n  }\n  \n  static async makeReadOnly(filePath) {\n    const stats = await fs.stat(filePath);\n    const newMode = stats.mode & ~0o222; // Remove write for all\n    await this.setPermissions(filePath, newMode);\n  }\n}\n\n// File permission examples\nasync function permissionOperations() {\n  try {\n    const testFile = './permission-test.txt';\n    \n    // Create test file\n    await fs.writeFile(testFile, 'Test file content');\n    \n    // Get current permissions\n    let perms = await FilePermissions.getPermissions(testFile);\n    console.log('Current permissions:', perms);\n    \n    // Make file read-only\n    await FilePermissions.makeReadOnly(testFile);\n    perms = await FilePermissions.getPermissions(testFile);\n    console.log('After making read-only:', perms.string);\n    \n    // Set specific permissions (owner: read/write, group: read, others: none)\n    await FilePermissions.setPermissions(testFile, 0o640);\n    perms = await FilePermissions.getPermissions(testFile);\n    console.log('After setting 640:', perms.string);\n    \n    // Make executable\n    await FilePermissions.makeExecutable(testFile);\n    perms = await FilePermissions.getPermissions(testFile);\n    console.log('After making executable:', perms.string);\n    \n  } catch (error) {\n    console.error('Permission operations failed:', error);\n  }\n}\n\npermissionOperations();\n```\n\n**Advanced File Operations:**\n```javascript\nimport fs from 'fs/promises';\nimport { createReadStream, createWriteStream } from 'fs';\nimport { pipeline } from 'stream/promises';\n\nclass AdvancedFileOps {\n  static async fileExists(filePath) {\n    try {\n      await fs.access(filePath);\n      return true;\n    } catch {\n      return false;\n    }\n  }\n  \n  static async safeDelete(filePath) {\n    try {\n      if (await this.fileExists(filePath)) {\n        await fs.unlink(filePath);\n        console.log(`File deleted: ${filePath}`);\n        return true;\n      } else {\n        console.log(`File does not exist: ${filePath}`);\n        return false;\n      }\n    } catch (error) {\n      console.error(`Error deleting file ${filePath}:`, error);\n      throw error;\n    }\n  }\n  \n  static async moveFile(source, destination) {\n    try {\n      await fs.rename(source, destination);\n      console.log(`File moved from ${source} to ${destination}`);\n    } catch (error) {\n      // If rename fails (different filesystems), copy and delete\n      if (error.code === 'EXDEV') {\n        await this.copyFile(source, destination);\n        await fs.unlink(source);\n        console.log(`File moved (via copy) from ${source} to ${destination}`);\n      } else {\n        throw error;\n      }\n    }\n  }\n  \n  static async copyFile(source, destination) {\n    try {\n      await pipeline(\n        createReadStream(source),\n        createWriteStream(destination)\n      );\n      console.log(`File copied from ${source} to ${destination}`);\n    } catch (error) {\n      console.error(`Error copying file from ${source} to ${destination}:`, error);\n      throw error;\n    }\n  }\n  \n  static async getFileInfo(filePath) {\n    try {\n      const stats = await fs.stat(filePath);\n      const permissions = await FilePermissions.getPermissions(filePath);\n      \n      return {\n        path: filePath,\n        size: stats.size,\n        sizeHuman: this.formatBytes(stats.size),\n        created: stats.birthtime,\n        modified: stats.mtime,\n        accessed: stats.atime,\n        isFile: stats.isFile(),\n        isDirectory: stats.isDirectory(),\n        permissions: permissions.string,\n        mode: permissions.numeric\n      };\n    } catch (error) {\n      console.error(`Error getting file info for ${filePath}:`, error);\n      throw error;\n    }\n  }\n  \n  static formatBytes(bytes) {\n    if (bytes === 0) return '0 Bytes';\n    const k = 1024;\n    const sizes = ['Bytes', 'KB', 'MB', 'GB', 'TB'];\n    const i = Math.floor(Math.log(bytes) / Math.log(k));\n    return parseFloat((bytes / Math.pow(k, i)).toFixed(2)) + ' ' + sizes[i];\n  }\n}\n\n// Usage example\nasync function advancedOperations() {\n  try {\n    const sourceFile = './source.txt';\n    const backupFile = './backup.txt';\n    \n    // Create source file\n    await fs.writeFile(sourceFile, 'Important data that needs backup');\n    \n    // Get file info\n    const info = await AdvancedFileOps.getFileInfo(sourceFile);\n    console.log('File info:', info);\n    \n    // Copy file\n    await AdvancedFileOps.copyFile(sourceFile, backupFile);\n    \n    // Verify both files exist\n    console.log('Source exists:', await AdvancedFileOps.fileExists(sourceFile));\n    console.log('Backup exists:', await AdvancedFileOps.fileExists(backupFile));\n    \n    // Clean up\n    await AdvancedFileOps.safeDelete(sourceFile);\n    await AdvancedFileOps.safeDelete(backupFile);\n    \n  } catch (error) {\n    console.error('Advanced operations failed:', error);\n  }\n}\n\nadvancedOperations();\n```\n\n**Best Practices:**\n\n1. **Always use async operations** in production applications\n2. **Handle errors properly** with try-catch or error callbacks\n3. **Use fs/promises** for cleaner async/await syntax\n4. **Check file existence** before operations when necessary\n5. **Set appropriate permissions** for security\n6. **Use streams** for large files to avoid memory issues\n7. **Clean up resources** and handle edge cases\n8. **Use path.join()** for cross-platform path handling\n\n**Common Permission Modes:**\n- `0o755`: rwxr-xr-x (executable files)\n- `0o644`: rw-r--r-- (regular files)\n- `0o600`: rw------- (private files)\n- `0o777`: rwxrwxrwx (all permissions - use carefully)",
        "difficulty": "Medium",
        "category": "File System"
    },
    {
        "id": 34,
        "question": "How do you create HTTP servers and implement RESTful APIs in Node.js? Explain different HTTP methods and routing.",
        "solution": "Node.js provides built-in HTTP capabilities through the `http` module, allowing you to create servers and implement RESTful APIs.\n\n**Basic HTTP Server:**\n```javascript\nimport http from 'http';\nimport url from 'url';\nimport querystring from 'querystring';\n\n// Basic HTTP server\nconst server = http.createServer((req, res) => {\n  const parsedUrl = url.parse(req.url, true);\n  const method = req.method;\n  const pathname = parsedUrl.pathname;\n  const query = parsedUrl.query;\n  \n  // Set CORS headers\n  res.setHeader('Access-Control-Allow-Origin', '*');\n  res.setHeader('Access-Control-Allow-Methods', 'GET, POST, PUT, DELETE, OPTIONS');\n  res.setHeader('Access-Control-Allow-Headers', 'Content-Type, Authorization');\n  \n  // Handle preflight requests\n  if (method === 'OPTIONS') {\n    res.writeHead(200);\n    res.end();\n    return;\n  }\n  \n  // Basic routing\n  if (method === 'GET' && pathname === '/') {\n    res.writeHead(200, { 'Content-Type': 'text/html' });\n    res.end('<h1>Welcome to Node.js HTTP Server</h1>');\n    \n  } else if (method === 'GET' && pathname === '/api/status') {\n    res.writeHead(200, { 'Content-Type': 'application/json' });\n    res.end(JSON.stringify({ \n      status: 'OK', \n      timestamp: new Date().toISOString(),\n      uptime: process.uptime()\n    }));\n    \n  } else if (method === 'GET' && pathname === '/api/echo') {\n    res.writeHead(200, { 'Content-Type': 'application/json' });\n    res.end(JSON.stringify({ \n      method,\n      pathname,\n      query,\n      headers: req.headers\n    }));\n    \n  } else {\n    res.writeHead(404, { 'Content-Type': 'application/json' });\n    res.end(JSON.stringify({ error: 'Not Found' }));\n  }\n});\n\nserver.listen(3000, () => {\n  console.log('Server running on http://localhost:3000');\n});\n```\n\n**RESTful API Implementation:**\n```javascript\nimport http from 'http';\nimport url from 'url';\n\n// In-memory data store (use database in production)\nlet users = [\n  { id: 1, name: 'John Doe', email: 'john@example.com' },\n  { id: 2, name: 'Jane Smith', email: 'jane@example.com' }\n];\nlet nextId = 3;\n\nclass UsersAPI {\n  static getUsers() {\n    return users;\n  }\n  \n  static getUserById(id) {\n    return users.find(user => user.id === parseInt(id));\n  }\n  \n  static createUser(userData) {\n    const user = {\n      id: nextId++,\n      name: userData.name,\n      email: userData.email,\n      createdAt: new Date().toISOString()\n    };\n    users.push(user);\n    return user;\n  }\n  \n  static updateUser(id, userData) {\n    const userIndex = users.findIndex(user => user.id === parseInt(id));\n    if (userIndex === -1) return null;\n    \n    users[userIndex] = {\n      ...users[userIndex],\n      ...userData,\n      id: parseInt(id), // Ensure ID doesn't change\n      updatedAt: new Date().toISOString()\n    };\n    \n    return users[userIndex];\n  }\n  \n  static deleteUser(id) {\n    const userIndex = users.findIndex(user => user.id === parseInt(id));\n    if (userIndex === -1) return false;\n    \n    users.splice(userIndex, 1);\n    return true;\n  }\n}\n\n// Request body parser\nfunction parseRequestBody(req) {\n  return new Promise((resolve, reject) => {\n    let body = '';\n    \n    req.on('data', chunk => {\n      body += chunk.toString();\n    });\n    \n    req.on('end', () => {\n      try {\n        const data = body ? JSON.parse(body) : {};\n        resolve(data);\n      } catch (error) {\n        reject(new Error('Invalid JSON in request body'));\n      }\n    });\n    \n    req.on('error', reject);\n  });\n}\n\n// HTTP response helper\nclass ResponseHelper {\n  static sendJSON(res, statusCode, data) {\n    res.writeHead(statusCode, { 'Content-Type': 'application/json' });\n    res.end(JSON.stringify(data));\n  }\n  \n  static sendError(res, statusCode, message) {\n    this.sendJSON(res, statusCode, { \n      error: message,\n      timestamp: new Date().toISOString()\n    });\n  }\n  \n  static sendSuccess(res, data, message = 'Success') {\n    this.sendJSON(res, 200, {\n      success: true,\n      message,\n      data\n    });\n  }\n  \n  static sendCreated(res, data, message = 'Created') {\n    this.sendJSON(res, 201, {\n      success: true,\n      message,\n      data\n    });\n  }\n}\n\n// Router implementation\nclass Router {\n  constructor() {\n    this.routes = {\n      GET: {},\n      POST: {},\n      PUT: {},\n      DELETE: {},\n      PATCH: {}\n    };\n  }\n  \n  addRoute(method, path, handler) {\n    this.routes[method][path] = handler;\n  }\n  \n  get(path, handler) {\n    this.addRoute('GET', path, handler);\n  }\n  \n  post(path, handler) {\n    this.addRoute('POST', path, handler);\n  }\n  \n  put(path, handler) {\n    this.addRoute('PUT', path, handler);\n  }\n  \n  delete(path, handler) {\n    this.addRoute('DELETE', path, handler);\n  }\n  \n  async handleRequest(req, res) {\n    const parsedUrl = url.parse(req.url, true);\n    const method = req.method;\n    const pathname = parsedUrl.pathname;\n    \n    // Extract path parameters (simple implementation)\n    const routePattern = this.findMatchingRoute(method, pathname);\n    \n    if (routePattern) {\n      const params = this.extractParams(routePattern.pattern, pathname);\n      req.params = params;\n      req.query = parsedUrl.query;\n      \n      try {\n        if (['POST', 'PUT', 'PATCH'].includes(method)) {\n          req.body = await parseRequestBody(req);\n        }\n        \n        await routePattern.handler(req, res);\n      } catch (error) {\n        console.error('Route handler error:', error);\n        ResponseHelper.sendError(res, 500, 'Internal Server Error');\n      }\n    } else {\n      ResponseHelper.sendError(res, 404, 'Route not found');\n    }\n  }\n  \n  findMatchingRoute(method, pathname) {\n    const routes = this.routes[method];\n    \n    // First try exact match\n    if (routes[pathname]) {\n      return { pattern: pathname, handler: routes[pathname] };\n    }\n    \n    // Then try pattern matching\n    for (const pattern in routes) {\n      if (this.matchesPattern(pattern, pathname)) {\n        return { pattern, handler: routes[pattern] };\n      }\n    }\n    \n    return null;\n  }\n  \n  matchesPattern(pattern, pathname) {\n    const patternParts = pattern.split('/');\n    const pathParts = pathname.split('/');\n    \n    if (patternParts.length !== pathParts.length) {\n      return false;\n    }\n    \n    return patternParts.every((part, index) => {\n      return part.startsWith(':') || part === pathParts[index];\n    });\n  }\n  \n  extractParams(pattern, pathname) {\n    const patternParts = pattern.split('/');\n    const pathParts = pathname.split('/');\n    const params = {};\n    \n    patternParts.forEach((part, index) => {\n      if (part.startsWith(':')) {\n        const paramName = part.slice(1);\n        params[paramName] = pathParts[index];\n      }\n    });\n    \n    return params;\n  }\n}\n\n// Create RESTful API routes\nconst router = new Router();\n\n// GET /api/users - Get all users\nrouter.get('/api/users', (req, res) => {\n  const users = UsersAPI.getUsers();\n  ResponseHelper.sendSuccess(res, users, 'Users retrieved successfully');\n});\n\n// GET /api/users/:id - Get user by ID\nrouter.get('/api/users/:id', (req, res) => {\n  const user = UsersAPI.getUserById(req.params.id);\n  \n  if (user) {\n    ResponseHelper.sendSuccess(res, user, 'User found');\n  } else {\n    ResponseHelper.sendError(res, 404, 'User not found');\n  }\n});\n\n// POST /api/users - Create new user\nrouter.post('/api/users', (req, res) => {\n  const { name, email } = req.body;\n  \n  if (!name || !email) {\n    ResponseHelper.sendError(res, 400, 'Name and email are required');\n    return;\n  }\n  \n  const user = UsersAPI.createUser({ name, email });\n  ResponseHelper.sendCreated(res, user, 'User created successfully');\n});\n\n// PUT /api/users/:id - Update user\nrouter.put('/api/users/:id', (req, res) => {\n  const { name, email } = req.body;\n  \n  if (!name || !email) {\n    ResponseHelper.sendError(res, 400, 'Name and email are required');\n    return;\n  }\n  \n  const user = UsersAPI.updateUser(req.params.id, { name, email });\n  \n  if (user) {\n    ResponseHelper.sendSuccess(res, user, 'User updated successfully');\n  } else {\n    ResponseHelper.sendError(res, 404, 'User not found');\n  }\n});\n\n// DELETE /api/users/:id - Delete user\nrouter.delete('/api/users/:id', (req, res) => {\n  const deleted = UsersAPI.deleteUser(req.params.id);\n  \n  if (deleted) {\n    ResponseHelper.sendSuccess(res, null, 'User deleted successfully');\n  } else {\n    ResponseHelper.sendError(res, 404, 'User not found');\n  }\n});\n\n// Create HTTP server with router\nconst apiServer = http.createServer(async (req, res) => {\n  // Add CORS headers\n  res.setHeader('Access-Control-Allow-Origin', '*');\n  res.setHeader('Access-Control-Allow-Methods', 'GET, POST, PUT, DELETE, OPTIONS');\n  res.setHeader('Access-Control-Allow-Headers', 'Content-Type, Authorization');\n  \n  // Handle preflight requests\n  if (req.method === 'OPTIONS') {\n    res.writeHead(200);\n    res.end();\n    return;\n  }\n  \n  await router.handleRequest(req, res);\n});\n\napiServer.listen(3001, () => {\n  console.log('RESTful API server running on http://localhost:3001');\n  console.log('Available endpoints:');\n  console.log('  GET    /api/users     - Get all users');\n  console.log('  GET    /api/users/:id - Get user by ID');\n  console.log('  POST   /api/users     - Create new user');\n  console.log('  PUT    /api/users/:id - Update user');\n  console.log('  DELETE /api/users/:id - Delete user');\n});\n```\n\n**HTTP Methods Explained:**\n\n```javascript\n// HTTP Methods and their purposes\nconst httpMethods = {\n  GET: {\n    purpose: 'Retrieve data',\n    idempotent: true,\n    safe: true,\n    hasBody: false,\n    examples: [\n      'GET /api/users - Get all users',\n      'GET /api/users/123 - Get specific user',\n      'GET /api/products?category=electronics - Get filtered products'\n    ]\n  },\n  \n  POST: {\n    purpose: 'Create new resource',\n    idempotent: false,\n    safe: false,\n    hasBody: true,\n    examples: [\n      'POST /api/users - Create new user',\n      'POST /api/orders - Create new order',\n      'POST /api/auth/login - Authenticate user'\n    ]\n  },\n  \n  PUT: {\n    purpose: 'Update/replace entire resource',\n    idempotent: true,\n    safe: false,\n    hasBody: true,\n    examples: [\n      'PUT /api/users/123 - Replace user data',\n      'PUT /api/products/456 - Update product'\n    ]\n  },\n  \n  PATCH: {\n    purpose: 'Partial update of resource',\n    idempotent: false,\n    safe: false,\n    hasBody: true,\n    examples: [\n      'PATCH /api/users/123 - Update user email only',\n      'PATCH /api/posts/789 - Update post title'\n    ]\n  },\n  \n  DELETE: {\n    purpose: 'Remove resource',\n    idempotent: true,\n    safe: false,\n    hasBody: false,\n    examples: [\n      'DELETE /api/users/123 - Delete user',\n      'DELETE /api/orders/456 - Cancel order'\n    ]\n  },\n  \n  HEAD: {\n    purpose: 'Get headers only (like GET but no body)',\n    idempotent: true,\n    safe: true,\n    hasBody: false,\n    examples: [\n      'HEAD /api/users/123 - Check if user exists',\n      'HEAD /api/files/large.zip - Check file size'\n    ]\n  },\n  \n  OPTIONS: {\n    purpose: 'Get allowed methods for resource',\n    idempotent: true,\n    safe: true,\n    hasBody: false,\n    examples: [\n      'OPTIONS /api/users - Get allowed methods',\n      'CORS preflight requests'\n    ]\n  }\n};\n\nconsole.table(httpMethods);\n```\n\n**Advanced Features:**\n\n```javascript\n// Middleware system\nclass MiddlewareRouter extends Router {\n  constructor() {\n    super();\n    this.middlewares = [];\n  }\n  \n  use(middleware) {\n    this.middlewares.push(middleware);\n  }\n  \n  async handleRequest(req, res) {\n    // Execute middlewares first\n    for (const middleware of this.middlewares) {\n      const result = await middleware(req, res);\n      if (result === false) return; // Middleware stopped processing\n    }\n    \n    // Then handle route\n    await super.handleRequest(req, res);\n  }\n}\n\n// Authentication middleware\nconst authMiddleware = async (req, res) => {\n  const authHeader = req.headers.authorization;\n  \n  if (!authHeader || !authHeader.startsWith('Bearer ')) {\n    if (req.url.startsWith('/api/protected')) {\n      ResponseHelper.sendError(res, 401, 'Authorization required');\n      return false; // Stop processing\n    }\n  }\n  \n  // Extract and validate token\n  const token = authHeader?.split(' ')[1];\n  req.user = { id: 1, name: 'Authenticated User' }; // Simplified\n  \n  return true; // Continue processing\n};\n\n// Logging middleware\nconst loggingMiddleware = async (req, res) => {\n  const timestamp = new Date().toISOString();\n  console.log(`${timestamp} ${req.method} ${req.url}`);\n  return true;\n};\n\n// Rate limiting middleware\nconst rateLimitMap = new Map();\nconst rateLimitMiddleware = async (req, res) => {\n  const clientIP = req.connection.remoteAddress;\n  const now = Date.now();\n  const windowMs = 60000; // 1 minute\n  const maxRequests = 100;\n  \n  if (!rateLimitMap.has(clientIP)) {\n    rateLimitMap.set(clientIP, { count: 1, resetTime: now + windowMs });\n    return true;\n  }\n  \n  const clientData = rateLimitMap.get(clientIP);\n  \n  if (now > clientData.resetTime) {\n    // Reset window\n    clientData.count = 1;\n    clientData.resetTime = now + windowMs;\n    return true;\n  }\n  \n  if (clientData.count >= maxRequests) {\n    ResponseHelper.sendError(res, 429, 'Too Many Requests');\n    return false;\n  }\n  \n  clientData.count++;\n  return true;\n};\n\n// Create advanced router with middlewares\nconst advancedRouter = new MiddlewareRouter();\nadvancedRouter.use(loggingMiddleware);\nadvancedRouter.use(rateLimitMiddleware);\nadvancedRouter.use(authMiddleware);\n\n// Protected route\nadvancedRouter.get('/api/protected/profile', (req, res) => {\n  ResponseHelper.sendSuccess(res, req.user, 'Profile retrieved');\n});\n```\n\n**Best Practices:**\n\n1. **Use appropriate HTTP methods** for their intended purposes\n2. **Return correct status codes** (200, 201, 400, 404, 500, etc.)\n3. **Implement proper error handling** and consistent error responses\n4. **Use middleware** for cross-cutting concerns (auth, logging, CORS)\n5. **Validate input data** before processing\n6. **Implement rate limiting** to prevent abuse\n7. **Use HTTPS** in production\n8. **Version your APIs** (/api/v1/, /api/v2/)\n9. **Document your API** with tools like Swagger/OpenAPI\n10. **Handle CORS** properly for browser clients",
        "difficulty": "Hard",
        "category": "HTTP & APIs"
    },
    {
        "id": 35,
        "question": "How do you implement performance monitoring and optimization in Node.js applications? Explain APM solutions and metrics collection.",
        "solution": "Performance monitoring is crucial for maintaining healthy Node.js applications in production. Here's how to implement comprehensive monitoring and optimization:\n\n**Application Performance Monitoring (APM) Solutions:**\n\n```javascript\n// New Relic integration\nimport newrelic from 'newrelic';\n\n// Custom transaction tracking\nfunction performExpensiveOperation(data) {\n  return newrelic.startSegment('expensive-operation', true, () => {\n    // Your expensive operation here\n    return processData(data);\n  });\n}\n\n// Custom metric recording\nnewrelic.recordMetric('Custom/UserRegistrations', 1);\nnewrelic.recordMetric('Custom/DatabaseConnections', connectionPool.size);\n\n// Error tracking\ntry {\n  await riskyOperation();\n} catch (error) {\n  newrelic.noticeError(error, {\n    userId: req.user?.id,\n    operation: 'riskyOperation',\n    context: { data: req.body }\n  });\n  throw error;\n}\n```\n\n**Prometheus Metrics Collection:**\n\n```javascript\nimport express from 'express';\nimport promClient from 'prom-client';\nimport responseTime from 'response-time';\n\nconst app = express();\n\n// Create a Registry which registers the metrics\nconst register = new promClient.Registry();\n\n// Add a default label which is added to all metrics\nregister.setDefaultLabels({\n  app: 'nodejs-api',\n  version: process.env.APP_VERSION || '1.0.0'\n});\n\n// Enable the collection of default metrics\npromClient.collectDefaultMetrics({ register });\n\n// Custom metrics\nconst httpRequestDuration = new promClient.Histogram({\n  name: 'http_request_duration_seconds',\n  help: 'Duration of HTTP requests in seconds',\n  labelNames: ['method', 'route', 'status'],\n  buckets: [0.1, 0.5, 1, 2, 5, 10]\n});\n\nconst httpRequestTotal = new promClient.Counter({\n  name: 'http_requests_total',\n  help: 'Total number of HTTP requests',\n  labelNames: ['method', 'route', 'status']\n});\n\nconst activeConnections = new promClient.Gauge({\n  name: 'active_connections',\n  help: 'Number of active connections'\n});\n\nconst businessMetrics = new promClient.Counter({\n  name: 'business_operations_total',\n  help: 'Total business operations',\n  labelNames: ['operation', 'status']\n});\n\nregister.registerMetric(httpRequestDuration);\nregister.registerMetric(httpRequestTotal);\nregister.registerMetric(activeConnections);\nregister.registerMetric(businessMetrics);\n\n// Middleware to track HTTP metrics\napp.use(responseTime((req, res, time) => {\n  const route = req.route ? req.route.path : req.url;\n  const labels = {\n    method: req.method,\n    route,\n    status: res.statusCode\n  };\n  \n  httpRequestDuration.observe(labels, time / 1000);\n  httpRequestTotal.inc(labels);\n}));\n\n// Track active connections\nlet connectionCount = 0;\napp.use((req, res, next) => {\n  connectionCount++;\n  activeConnections.set(connectionCount);\n  \n  res.on('finish', () => {\n    connectionCount--;\n    activeConnections.set(connectionCount);\n  });\n  \n  next();\n});\n\n// Business metrics tracking\nclass MetricsService {\n  static trackOperation(operation, status = 'success') {\n    businessMetrics.inc({ operation, status });\n  }\n  \n  static async trackAsyncOperation(operation, asyncFn) {\n    const startTime = Date.now();\n    \n    try {\n      const result = await asyncFn();\n      this.trackOperation(operation, 'success');\n      \n      // Track operation duration\n      const duration = (Date.now() - startTime) / 1000;\n      const operationDuration = new promClient.Histogram({\n        name: `${operation}_duration_seconds`,\n        help: `Duration of ${operation} operations`,\n        buckets: [0.1, 0.5, 1, 2, 5]\n      });\n      operationDuration.observe(duration);\n      \n      return result;\n    } catch (error) {\n      this.trackOperation(operation, 'error');\n      throw error;\n    }\n  }\n}\n\n// Example business operation with metrics\napp.post('/api/users', async (req, res) => {\n  try {\n    const user = await MetricsService.trackAsyncOperation('user_creation', async () => {\n      return await createUser(req.body);\n    });\n    \n    res.status(201).json(user);\n  } catch (error) {\n    res.status(500).json({ error: error.message });\n  }\n});\n\n// Metrics endpoint for Prometheus\napp.get('/metrics', async (req, res) => {\n  res.set('Content-Type', register.contentType);\n  const metrics = await register.metrics();\n  res.end(metrics);\n});\n\n// Health check endpoint\napp.get('/health', (req, res) => {\n  const healthCheck = {\n    uptime: process.uptime(),\n    message: 'OK',\n    timestamp: new Date().toISOString(),\n    memory: process.memoryUsage(),\n    cpu: process.cpuUsage()\n  };\n  \n  res.status(200).json(healthCheck);\n});\n\napp.listen(3000, () => {\n  console.log('Server with metrics running on port 3000');\n  console.log('Metrics available at http://localhost:3000/metrics');\n});\n```\n\n**Custom Performance Monitoring Service:**\n\n```javascript\nimport EventEmitter from 'events';\nimport os from 'os';\n\nclass PerformanceMonitor extends EventEmitter {\n  constructor() {\n    super();\n    this.metrics = {\n      requests: 0,\n      errors: 0,\n      responseTime: [],\n      memoryUsage: [],\n      cpuUsage: []\n    };\n    \n    this.startSystemMonitoring();\n  }\n  \n  startSystemMonitoring() {\n    // Monitor memory and CPU every 30 seconds\n    setInterval(() => {\n      const memUsage = process.memoryUsage();\n      const cpuUsage = process.cpuUsage();\n      \n      this.metrics.memoryUsage.push({\n        timestamp: Date.now(),\n        heapUsed: memUsage.heapUsed,\n        heapTotal: memUsage.heapTotal,\n        external: memUsage.external,\n        rss: memUsage.rss\n      });\n      \n      this.metrics.cpuUsage.push({\n        timestamp: Date.now(),\n        user: cpuUsage.user,\n        system: cpuUsage.system,\n        loadAverage: os.loadavg()\n      });\n      \n      // Keep only last 100 entries\n      if (this.metrics.memoryUsage.length > 100) {\n        this.metrics.memoryUsage.shift();\n      }\n      if (this.metrics.cpuUsage.length > 100) {\n        this.metrics.cpuUsage.shift();\n      }\n      \n      this.emit('systemMetrics', {\n        memory: this.metrics.memoryUsage.slice(-1)[0],\n        cpu: this.metrics.cpuUsage.slice(-1)[0]\n      });\n    }, 30000);\n  }\n  \n  trackRequest(duration, statusCode) {\n    this.metrics.requests++;\n    this.metrics.responseTime.push({\n      timestamp: Date.now(),\n      duration,\n      statusCode\n    });\n    \n    if (statusCode >= 400) {\n      this.metrics.errors++;\n    }\n    \n    // Keep only last 1000 response times\n    if (this.metrics.responseTime.length > 1000) {\n      this.metrics.responseTime.shift();\n    }\n    \n    this.emit('requestTracked', { duration, statusCode });\n  }\n  \n  getStats() {\n    const recentResponses = this.metrics.responseTime.slice(-100);\n    const avgResponseTime = recentResponses.length > 0 \n      ? recentResponses.reduce((sum, r) => sum + r.duration, 0) / recentResponses.length\n      : 0;\n    \n    const errorRate = this.metrics.requests > 0 \n      ? (this.metrics.errors / this.metrics.requests) * 100\n      : 0;\n    \n    const recentMemory = this.metrics.memoryUsage.slice(-1)[0];\n    const recentCPU = this.metrics.cpuUsage.slice(-1)[0];\n    \n    return {\n      totalRequests: this.metrics.requests,\n      totalErrors: this.metrics.errors,\n      errorRate: errorRate.toFixed(2) + '%',\n      averageResponseTime: avgResponseTime.toFixed(2) + 'ms',\n      currentMemory: recentMemory ? {\n        heapUsed: (recentMemory.heapUsed / 1024 / 1024).toFixed(2) + 'MB',\n        heapTotal: (recentMemory.heapTotal / 1024 / 1024).toFixed(2) + 'MB',\n        rss: (recentMemory.rss / 1024 / 1024).toFixed(2) + 'MB'\n      } : null,\n      currentCPU: recentCPU ? {\n        userTime: recentCPU.user,\n        systemTime: recentCPU.system,\n        loadAverage: recentCPU.loadAverage\n      } : null,\n      uptime: process.uptime()\n    };\n  }\n  \n  // Alert when thresholds are exceeded\n  checkThresholds() {\n    const stats = this.getStats();\n    const recentMemory = this.metrics.memoryUsage.slice(-1)[0];\n    \n    // Memory threshold: 80% of heap\n    if (recentMemory && recentMemory.heapUsed / recentMemory.heapTotal > 0.8) {\n      this.emit('alert', {\n        type: 'HIGH_MEMORY_USAGE',\n        message: `Memory usage is ${((recentMemory.heapUsed / recentMemory.heapTotal) * 100).toFixed(2)}%`,\n        severity: 'warning'\n      });\n    }\n    \n    // Error rate threshold: 5%\n    const errorRate = parseFloat(stats.errorRate.replace('%', ''));\n    if (errorRate > 5) {\n      this.emit('alert', {\n        type: 'HIGH_ERROR_RATE',\n        message: `Error rate is ${stats.errorRate}`,\n        severity: 'critical'\n      });\n    }\n    \n    // Response time threshold: 2 seconds\n    const avgResponseTime = parseFloat(stats.averageResponseTime.replace('ms', ''));\n    if (avgResponseTime > 2000) {\n      this.emit('alert', {\n        type: 'SLOW_RESPONSE_TIME',\n        message: `Average response time is ${stats.averageResponseTime}`,\n        severity: 'warning'\n      });\n    }\n  }\n}\n\n// Usage example\nconst monitor = new PerformanceMonitor();\n\n// Set up alerting\nmonitor.on('alert', (alert) => {\n  console.error(`🚨 ALERT [${alert.severity}]: ${alert.type} - ${alert.message}`);\n  \n  // Send to external alerting service\n  // await sendToSlack(alert);\n  // await sendToPagerDuty(alert);\n});\n\n// Check thresholds every minute\nsetInterval(() => {\n  monitor.checkThresholds();\n}, 60000);\n\n// Express middleware integration\nfunction performanceMiddleware(req, res, next) {\n  const startTime = Date.now();\n  \n  res.on('finish', () => {\n    const duration = Date.now() - startTime;\n    monitor.trackRequest(duration, res.statusCode);\n  });\n  \n  next();\n}\n\n// Stats endpoint\napp.get('/api/stats', (req, res) => {\n  res.json(monitor.getStats());\n});\n\napp.use(performanceMiddleware);\n```\n\n**Key Performance Metrics to Monitor:**\n\n1. **Request Metrics:**\n   - Request rate (requests per second)\n   - Response time (average, percentiles)\n   - Error rate (4xx, 5xx responses)\n   - Throughput\n\n2. **System Metrics:**\n   - CPU usage\n   - Memory usage (heap, RSS)\n   - Disk I/O\n   - Network I/O\n\n3. **Application Metrics:**\n   - Database query time\n   - Queue length\n   - Cache hit/miss ratio\n   - Active connections\n\n4. **Business Metrics:**\n   - User registrations\n   - Order completions\n   - Revenue tracking\n   - Feature usage\n\n**Best Practices:**\n\n1. **Use structured logging** with correlation IDs\n2. **Set up alerting** for critical thresholds\n3. **Monitor both technical and business metrics**\n4. **Use dashboards** (Grafana) for visualization\n5. **Implement distributed tracing** for microservices\n6. **Regular performance testing** and benchmarking\n7. **Monitor external dependencies** and third-party services\n8. **Track deployment impact** on performance metrics",
        "difficulty": "Hard",
        "category": "Performance & Monitoring"
    },
    {
        "id": 36,
        "question": "How do you implement comprehensive testing strategies in Node.js? Explain unit, integration, and end-to-end testing with Jest, Mocha, and Cypress.",
        "solution": "Comprehensive testing is essential for reliable Node.js applications. Here's how to implement different testing strategies:\n\n**Unit Testing with Jest:**\n\n```javascript\n// math.js - Module to test\nexport const add = (a, b) => a + b;\nexport const divide = (a, b) => {\n  if (b === 0) throw new Error('Division by zero');\n  return a / b;\n};\nexport const asyncOperation = async (value) => {\n  return new Promise((resolve) => {\n    setTimeout(() => resolve(value * 2), 100);\n  });\n};\n\n// math.test.js - Jest unit tests\nimport { add, divide, asyncOperation } from './math.js';\n\ndescribe('Math utilities', () => {\n  describe('add', () => {\n    test('should add two positive numbers', () => {\n      expect(add(2, 3)).toBe(5);\n    });\n    \n    test('should handle negative numbers', () => {\n      expect(add(-1, 1)).toBe(0);\n      expect(add(-2, -3)).toBe(-5);\n    });\n    \n    test('should handle zero', () => {\n      expect(add(0, 5)).toBe(5);\n      expect(add(0, 0)).toBe(0);\n    });\n  });\n  \n  describe('divide', () => {\n    test('should divide two numbers correctly', () => {\n      expect(divide(10, 2)).toBe(5);\n      expect(divide(7, 2)).toBe(3.5);\n    });\n    \n    test('should throw error for division by zero', () => {\n      expect(() => divide(10, 0)).toThrow('Division by zero');\n    });\n  });\n  \n  describe('asyncOperation', () => {\n    test('should double the input value asynchronously', async () => {\n      const result = await asyncOperation(5);\n      expect(result).toBe(10);\n    });\n    \n    test('should handle multiple async operations', async () => {\n      const promises = [asyncOperation(1), asyncOperation(2), asyncOperation(3)];\n      const results = await Promise.all(promises);\n      expect(results).toEqual([2, 4, 6]);\n    });\n  });\n});\n```\n\n**Mocking Dependencies with Jest:**\n\n```javascript\n// userService.js - Service with external dependencies\nimport axios from 'axios';\nimport { sendEmail } from './emailService.js';\nimport { logActivity } from './logger.js';\n\nexport class UserService {\n  static async createUser(userData) {\n    try {\n      // Validate with external API\n      const validation = await axios.post('https://api.validator.com/validate', userData);\n      \n      if (!validation.data.isValid) {\n        throw new Error('Invalid user data');\n      }\n      \n      // Create user in database\n      const user = {\n        id: Date.now(),\n        ...userData,\n        createdAt: new Date().toISOString()\n      };\n      \n      // Send welcome email\n      await sendEmail(user.email, 'Welcome!', 'Thank you for joining us.');\n      \n      // Log activity\n      logActivity('user_created', { userId: user.id });\n      \n      return user;\n    } catch (error) {\n      logActivity('user_creation_failed', { error: error.message });\n      throw error;\n    }\n  }\n  \n  static async getUserById(id) {\n    const response = await axios.get(`https://api.users.com/users/${id}`);\n    return response.data;\n  }\n}\n\n// userService.test.js - Testing with mocks\nimport axios from 'axios';\nimport { UserService } from './userService.js';\nimport { sendEmail } from './emailService.js';\nimport { logActivity } from './logger.js';\n\n// Mock external dependencies\njest.mock('axios');\njest.mock('./emailService.js');\njest.mock('./logger.js');\n\nconst mockedAxios = axios as jest.Mocked<typeof axios>;\nconst mockedSendEmail = sendEmail as jest.MockedFunction<typeof sendEmail>;\nconst mockedLogActivity = logActivity as jest.MockedFunction<typeof logActivity>;\n\ndescribe('UserService', () => {\n  beforeEach(() => {\n    jest.clearAllMocks();\n  });\n  \n  describe('createUser', () => {\n    test('should create user successfully with valid data', async () => {\n      // Arrange\n      const userData = { name: 'John Doe', email: 'john@example.com' };\n      mockedAxios.post.mockResolvedValue({\n        data: { isValid: true }\n      });\n      mockedSendEmail.mockResolvedValue(undefined);\n      \n      // Act\n      const user = await UserService.createUser(userData);\n      \n      // Assert\n      expect(user).toMatchObject({\n        name: 'John Doe',\n        email: 'john@example.com'\n      });\n      expect(user.id).toBeDefined();\n      expect(user.createdAt).toBeDefined();\n      \n      expect(mockedAxios.post).toHaveBeenCalledWith(\n        'https://api.validator.com/validate',\n        userData\n      );\n      expect(mockedSendEmail).toHaveBeenCalledWith(\n        'john@example.com',\n        'Welcome!',\n        'Thank you for joining us.'\n      );\n      expect(mockedLogActivity).toHaveBeenCalledWith(\n        'user_created',\n        { userId: user.id }\n      );\n    });\n    \n    test('should throw error for invalid user data', async () => {\n      // Arrange\n      const userData = { name: '', email: 'invalid-email' };\n      mockedAxios.post.mockResolvedValue({\n        data: { isValid: false }\n      });\n      \n      // Act & Assert\n      await expect(UserService.createUser(userData))\n        .rejects.toThrow('Invalid user data');\n      \n      expect(mockedSendEmail).not.toHaveBeenCalled();\n      expect(mockedLogActivity).toHaveBeenCalledWith(\n        'user_creation_failed',\n        { error: 'Invalid user data' }\n      );\n    });\n    \n    test('should handle external API failure', async () => {\n      // Arrange\n      const userData = { name: 'John Doe', email: 'john@example.com' };\n      mockedAxios.post.mockRejectedValue(new Error('API unavailable'));\n      \n      // Act & Assert\n      await expect(UserService.createUser(userData))\n        .rejects.toThrow('API unavailable');\n      \n      expect(mockedSendEmail).not.toHaveBeenCalled();\n      expect(mockedLogActivity).toHaveBeenCalledWith(\n        'user_creation_failed',\n        { error: 'API unavailable' }\n      );\n    });\n  });\n  \n  describe('getUserById', () => {\n    test('should return user data', async () => {\n      // Arrange\n      const userId = 123;\n      const userData = { id: 123, name: 'John Doe' };\n      mockedAxios.get.mockResolvedValue({ data: userData });\n      \n      // Act\n      const user = await UserService.getUserById(userId);\n      \n      // Assert\n      expect(user).toEqual(userData);\n      expect(mockedAxios.get).toHaveBeenCalledWith(\n        'https://api.users.com/users/123'\n      );\n    });\n  });\n});\n```\n\n**Integration Testing with Supertest:**\n\n```javascript\n// app.js - Express application\nimport express from 'express';\nimport { UserService } from './userService.js';\n\nconst app = express();\napp.use(express.json());\n\napp.post('/api/users', async (req, res) => {\n  try {\n    const user = await UserService.createUser(req.body);\n    res.status(201).json(user);\n  } catch (error) {\n    res.status(400).json({ error: error.message });\n  }\n});\n\napp.get('/api/users/:id', async (req, res) => {\n  try {\n    const user = await UserService.getUserById(req.params.id);\n    res.json(user);\n  } catch (error) {\n    res.status(404).json({ error: 'User not found' });\n  }\n});\n\napp.get('/health', (req, res) => {\n  res.json({ status: 'OK' });\n});\n\nexport default app;\n\n// app.integration.test.js - Integration tests\nimport request from 'supertest';\nimport app from './app.js';\nimport { UserService } from './userService.js';\n\n// Mock the UserService for integration tests\njest.mock('./userService.js');\nconst mockedUserService = UserService as jest.Mocked<typeof UserService>;\n\ndescribe('User API Integration Tests', () => {\n  beforeEach(() => {\n    jest.clearAllMocks();\n  });\n  \n  describe('POST /api/users', () => {\n    test('should create user and return 201', async () => {\n      // Arrange\n      const userData = { name: 'John Doe', email: 'john@example.com' };\n      const createdUser = { id: 1, ...userData, createdAt: '2024-01-01T00:00:00.000Z' };\n      mockedUserService.createUser.mockResolvedValue(createdUser);\n      \n      // Act\n      const response = await request(app)\n        .post('/api/users')\n        .send(userData)\n        .expect(201);\n      \n      // Assert\n      expect(response.body).toEqual(createdUser);\n      expect(mockedUserService.createUser).toHaveBeenCalledWith(userData);\n    });\n    \n    test('should return 400 for invalid user data', async () => {\n      // Arrange\n      const userData = { name: '', email: 'invalid' };\n      mockedUserService.createUser.mockRejectedValue(new Error('Invalid user data'));\n      \n      // Act\n      const response = await request(app)\n        .post('/api/users')\n        .send(userData)\n        .expect(400);\n      \n      // Assert\n      expect(response.body.error).toBe('Invalid user data');\n    });\n    \n    test('should handle missing request body', async () => {\n      await request(app)\n        .post('/api/users')\n        .expect(400);\n    });\n  });\n  \n  describe('GET /api/users/:id', () => {\n    test('should return user data', async () => {\n      // Arrange\n      const userId = '123';\n      const userData = { id: 123, name: 'John Doe' };\n      mockedUserService.getUserById.mockResolvedValue(userData);\n      \n      // Act\n      const response = await request(app)\n        .get(`/api/users/${userId}`)\n        .expect(200);\n      \n      // Assert\n      expect(response.body).toEqual(userData);\n      expect(mockedUserService.getUserById).toHaveBeenCalledWith(userId);\n    });\n    \n    test('should return 404 for non-existent user', async () => {\n      // Arrange\n      mockedUserService.getUserById.mockRejectedValue(new Error('User not found'));\n      \n      // Act\n      const response = await request(app)\n        .get('/api/users/999')\n        .expect(404);\n      \n      // Assert\n      expect(response.body.error).toBe('User not found');\n    });\n  });\n  \n  describe('GET /health', () => {\n    test('should return health status', async () => {\n      const response = await request(app)\n        .get('/health')\n        .expect(200);\n      \n      expect(response.body).toEqual({ status: 'OK' });\n    });\n  });\n});\n```\n\n**Testing with Mocha and Chai:**\n\n```javascript\n// calculator.js\nexport class Calculator {\n  add(a, b) {\n    return a + b;\n  }\n  \n  subtract(a, b) {\n    return a - b;\n  }\n  \n  async asyncAdd(a, b) {\n    return new Promise((resolve) => {\n      setTimeout(() => resolve(a + b), 10);\n    });\n  }\n}\n\n// calculator.test.js - Mocha with Chai\nimport { expect } from 'chai';\nimport { Calculator } from './calculator.js';\n\ndescribe('Calculator', () => {\n  let calculator;\n  \n  beforeEach(() => {\n    calculator = new Calculator();\n  });\n  \n  describe('#add()', () => {\n    it('should add two numbers correctly', () => {\n      const result = calculator.add(2, 3);\n      expect(result).to.equal(5);\n    });\n    \n    it('should handle negative numbers', () => {\n      expect(calculator.add(-1, 1)).to.equal(0);\n      expect(calculator.add(-2, -3)).to.equal(-5);\n    });\n    \n    it('should be commutative', () => {\n      expect(calculator.add(3, 5)).to.equal(calculator.add(5, 3));\n    });\n  });\n  \n  describe('#subtract()', () => {\n    it('should subtract second number from first', () => {\n      expect(calculator.subtract(5, 3)).to.equal(2);\n      expect(calculator.subtract(1, 5)).to.equal(-4);\n    });\n  });\n  \n  describe('#asyncAdd()', () => {\n    it('should add numbers asynchronously', async () => {\n      const result = await calculator.asyncAdd(2, 3);\n      expect(result).to.equal(5);\n    });\n    \n    it('should handle multiple async operations', (done) => {\n      calculator.asyncAdd(1, 2).then(result => {\n        expect(result).to.equal(3);\n        done();\n      }).catch(done);\n    });\n  });\n});\n```\n\n**End-to-End Testing with Cypress:**\n\n```javascript\n// cypress/e2e/user-registration.cy.js\ndescribe('User Registration Flow', () => {\n  beforeEach(() => {\n    // Visit the application\n    cy.visit('/register');\n  });\n  \n  it('should register a new user successfully', () => {\n    // Fill out the registration form\n    cy.get('[data-cy=\"name-input\"]').type('John Doe');\n    cy.get('[data-cy=\"email-input\"]').type('john@example.com');\n    cy.get('[data-cy=\"password-input\"]').type('securePassword123');\n    cy.get('[data-cy=\"confirm-password-input\"]').type('securePassword123');\n    \n    // Submit the form\n    cy.get('[data-cy=\"submit-button\"]').click();\n    \n    // Verify success\n    cy.get('[data-cy=\"success-message\"]')\n      .should('be.visible')\n      .and('contain', 'Registration successful');\n    \n    // Verify redirect to dashboard\n    cy.url().should('include', '/dashboard');\n    cy.get('[data-cy=\"welcome-message\"]')\n      .should('contain', 'Welcome, John Doe');\n  });\n  \n  it('should show validation errors for invalid data', () => {\n    // Submit empty form\n    cy.get('[data-cy=\"submit-button\"]').click();\n    \n    // Check validation errors\n    cy.get('[data-cy=\"name-error\"]')\n      .should('be.visible')\n      .and('contain', 'Name is required');\n    \n    cy.get('[data-cy=\"email-error\"]')\n      .should('be.visible')\n      .and('contain', 'Email is required');\n    \n    // Test invalid email format\n    cy.get('[data-cy=\"email-input\"]').type('invalid-email');\n    cy.get('[data-cy=\"submit-button\"]').click();\n    \n    cy.get('[data-cy=\"email-error\"]')\n      .should('contain', 'Please enter a valid email');\n  });\n  \n  it('should handle password mismatch', () => {\n    cy.get('[data-cy=\"password-input\"]').type('password123');\n    cy.get('[data-cy=\"confirm-password-input\"]').type('password456');\n    cy.get('[data-cy=\"submit-button\"]').click();\n    \n    cy.get('[data-cy=\"password-error\"]')\n      .should('be.visible')\n      .and('contain', 'Passwords do not match');\n  });\n  \n  it('should handle server errors gracefully', () => {\n    // Intercept the API call and return an error\n    cy.intercept('POST', '/api/users', {\n      statusCode: 500,\n      body: { error: 'Internal server error' }\n    }).as('registerUser');\n    \n    // Fill out and submit form\n    cy.get('[data-cy=\"name-input\"]').type('John Doe');\n    cy.get('[data-cy=\"email-input\"]').type('john@example.com');\n    cy.get('[data-cy=\"password-input\"]').type('password123');\n    cy.get('[data-cy=\"confirm-password-input\"]').type('password123');\n    cy.get('[data-cy=\"submit-button\"]').click();\n    \n    // Wait for the API call\n    cy.wait('@registerUser');\n    \n    // Verify error handling\n    cy.get('[data-cy=\"error-message\"]')\n      .should('be.visible')\n      .and('contain', 'Registration failed');\n  });\n});\n\n// cypress/e2e/api-tests.cy.js\ndescribe('API Testing', () => {\n  it('should create and retrieve a user via API', () => {\n    const userData = {\n      name: 'API Test User',\n      email: 'api@example.com'\n    };\n    \n    // Create user via API\n    cy.request({\n      method: 'POST',\n      url: '/api/users',\n      body: userData\n    }).then((response) => {\n      expect(response.status).to.eq(201);\n      expect(response.body).to.have.property('id');\n      expect(response.body.name).to.eq(userData.name);\n      expect(response.body.email).to.eq(userData.email);\n      \n      const userId = response.body.id;\n      \n      // Retrieve user via API\n      cy.request({\n        method: 'GET',\n        url: `/api/users/${userId}`\n      }).then((getResponse) => {\n        expect(getResponse.status).to.eq(200);\n        expect(getResponse.body.id).to.eq(userId);\n        expect(getResponse.body.name).to.eq(userData.name);\n      });\n    });\n  });\n});\n```\n\n**Test Configuration Files:**\n\n```javascript\n// jest.config.js\nexport default {\n  testEnvironment: 'node',\n  roots: ['<rootDir>/src'],\n  testMatch: ['**/__tests__/**/*.js', '**/?(*.)+(spec|test).js'],\n  collectCoverageFrom: [\n    'src/**/*.js',\n    '!src/**/*.test.js',\n    '!src/coverage/**',\n    '!src/node_modules/**'\n  ],\n  coverageThreshold: {\n    global: {\n      branches: 80,\n      functions: 80,\n      lines: 80,\n      statements: 80\n    }\n  },\n  setupFilesAfterEnv: ['<rootDir>/src/test-setup.js'],\n  testTimeout: 10000\n};\n\n// test-setup.js\n// Global test setup\nglobal.console = {\n  ...console,\n  log: jest.fn(),\n  warn: jest.fn(),\n  error: jest.fn()\n};\n\n// Custom matchers\nexpect.extend({\n  toBeValidEmail(received) {\n    const emailRegex = /^[^\\s@]+@[^\\s@]+\\.[^\\s@]+$/;\n    const pass = emailRegex.test(received);\n    \n    return {\n      message: () => `expected ${received} ${pass ? 'not ' : ''}to be a valid email`,\n      pass\n    };\n  }\n});\n\n// .mocharc.json\n{\n  \"require\": [\"@babel/register\"],\n  \"spec\": \"src/**/*.test.js\",\n  \"timeout\": 5000,\n  \"reporter\": \"spec\",\n  \"recursive\": true\n}\n\n// cypress.config.js\nimport { defineConfig } from 'cypress';\n\nexport default defineConfig({\n  e2e: {\n    baseUrl: 'http://localhost:3000',\n    viewportWidth: 1280,\n    viewportHeight: 720,\n    video: false,\n    screenshotOnRunFailure: true,\n    defaultCommandTimeout: 10000,\n    requestTimeout: 10000,\n    responseTimeout: 10000,\n    setupNodeEvents(on, config) {\n      // implement node event listeners here\n    }\n  },\n  component: {\n    devServer: {\n      framework: 'react',\n      bundler: 'webpack'\n    }\n  }\n});\n```\n\n**Best Testing Practices:**\n\n1. **Follow the Testing Pyramid** - More unit tests, fewer integration tests, minimal E2E tests\n2. **Use descriptive test names** that explain what is being tested\n3. **Keep tests independent** - each test should be able to run in isolation\n4. **Mock external dependencies** in unit tests\n5. **Test both happy paths and error cases**\n6. **Maintain good test coverage** (aim for 80%+ code coverage)\n7. **Use data-cy attributes** for stable E2E test selectors\n8. **Run tests in CI/CD pipelines** for continuous validation\n9. **Keep tests fast** - slow tests discourage frequent running\n10. **Write tests first** when possible (TDD approach)",
        "difficulty": "Hard",
        "category": "Testing"
    },
    {
        "id": 37,
        "question": "How do you implement microservices architecture with Node.js? Explain API Gateway, service discovery, and circuit breaker patterns.",
        "solution": "Microservices architecture breaks down applications into small, independent services. Here's how to implement it with Node.js:\n\n**API Gateway Implementation:**\n\n```javascript\n// api-gateway.js - Central entry point for all client requests\nimport express from 'express';\nimport httpProxy from 'http-proxy-middleware';\nimport rateLimit from 'express-rate-limit';\nimport helmet from 'helmet';\nimport cors from 'cors';\nimport jwt from 'jsonwebtoken';\n\nconst app = express();\n\n// Security middleware\napp.use(helmet());\napp.use(cors());\napp.use(express.json());\n\n// Rate limiting\nconst limiter = rateLimit({\n  windowMs: 15 * 60 * 1000, // 15 minutes\n  max: 100, // limit each IP to 100 requests per windowMs\n  message: 'Too many requests from this IP'\n});\napp.use(limiter);\n\n// Service registry\nconst serviceRegistry = {\n  'user-service': {\n    url: 'http://localhost:3001',\n    healthCheck: '/health',\n    instances: [\n      { url: 'http://localhost:3001', healthy: true },\n      { url: 'http://localhost:3002', healthy: true }\n    ]\n  },\n  'order-service': {\n    url: 'http://localhost:3003',\n    healthCheck: '/health',\n    instances: [\n      { url: 'http://localhost:3003', healthy: true }\n    ]\n  },\n  'payment-service': {\n    url: 'http://localhost:3004',\n    healthCheck: '/health',\n    instances: [\n      { url: 'http://localhost:3004', healthy: true }\n    ]\n  }\n};\n\n// Load balancer - Round robin\nclass LoadBalancer {\n  constructor() {\n    this.currentIndex = {};\n  }\n  \n  getNextInstance(serviceName) {\n    const service = serviceRegistry[serviceName];\n    if (!service || !service.instances.length) {\n      throw new Error(`Service ${serviceName} not available`);\n    }\n    \n    // Filter healthy instances\n    const healthyInstances = service.instances.filter(instance => instance.healthy);\n    if (!healthyInstances.length) {\n      throw new Error(`No healthy instances for service ${serviceName}`);\n    }\n    \n    // Round robin\n    if (!this.currentIndex[serviceName]) {\n      this.currentIndex[serviceName] = 0;\n    }\n    \n    const instance = healthyInstances[this.currentIndex[serviceName]];\n    this.currentIndex[serviceName] = \n      (this.currentIndex[serviceName] + 1) % healthyInstances.length;\n    \n    return instance;\n  }\n}\n\nconst loadBalancer = new LoadBalancer();\n\n// Authentication middleware\nconst authenticateToken = (req, res, next) => {\n  const authHeader = req.headers['authorization'];\n  const token = authHeader && authHeader.split(' ')[1];\n  \n  if (!token) {\n    return res.status(401).json({ error: 'Access token required' });\n  }\n  \n  jwt.verify(token, process.env.JWT_SECRET || 'fallback-secret', (err, user) => {\n    if (err) {\n      return res.status(403).json({ error: 'Invalid token' });\n    }\n    req.user = user;\n    next();\n  });\n};\n\n// Request logging middleware\nconst requestLogger = (req, res, next) => {\n  console.log(`${new Date().toISOString()} ${req.method} ${req.url}`);\n  next();\n};\n\napp.use(requestLogger);\n\n// Dynamic proxy middleware\nconst createServiceProxy = (serviceName, requireAuth = false) => {\n  return (req, res, next) => {\n    try {\n      const instance = loadBalancer.getNextInstance(serviceName);\n      \n      const proxy = httpProxy.createProxyMiddleware({\n        target: instance.url,\n        changeOrigin: true,\n        pathRewrite: {\n          [`^/api/${serviceName}`]: ''\n        },\n        onError: (err, req, res) => {\n          console.error(`Proxy error for ${serviceName}:`, err.message);\n          // Mark instance as unhealthy\n          instance.healthy = false;\n          res.status(503).json({ error: 'Service temporarily unavailable' });\n        },\n        onProxyReq: (proxyReq, req, res) => {\n          // Add user context to downstream services\n          if (req.user) {\n            proxyReq.setHeader('X-User-ID', req.user.id);\n            proxyReq.setHeader('X-User-Role', req.user.role);\n          }\n          \n          // Add correlation ID for tracing\n          const correlationId = req.headers['x-correlation-id'] || \n            `gw-${Date.now()}-${Math.random().toString(36).substr(2, 9)}`;\n          proxyReq.setHeader('X-Correlation-ID', correlationId);\n        }\n      });\n      \n      proxy(req, res, next);\n    } catch (error) {\n      console.error(`Service routing error:`, error.message);\n      res.status(503).json({ error: 'Service unavailable' });\n    }\n  };\n};\n\n// Public routes (no authentication required)\napp.use('/api/user-service/auth', createServiceProxy('user-service'));\napp.use('/api/user-service/register', createServiceProxy('user-service'));\n\n// Protected routes (authentication required)\napp.use('/api/user-service', authenticateToken, createServiceProxy('user-service', true));\napp.use('/api/order-service', authenticateToken, createServiceProxy('order-service', true));\napp.use('/api/payment-service', authenticateToken, createServiceProxy('payment-service', true));\n\n// Health check endpoint\napp.get('/health', (req, res) => {\n  res.json({ \n    status: 'healthy', \n    timestamp: new Date().toISOString(),\n    services: Object.keys(serviceRegistry)\n  });\n});\n\n// Service discovery endpoint\napp.get('/api/services', (req, res) => {\n  const services = Object.entries(serviceRegistry).map(([name, config]) => ({\n    name,\n    instances: config.instances.length,\n    healthy: config.instances.filter(i => i.healthy).length\n  }));\n  \n  res.json({ services });\n});\n\nconst PORT = process.env.PORT || 3000;\napp.listen(PORT, () => {\n  console.log(`API Gateway running on port ${PORT}`);\n});\n\nexport default app;\n```\n\n**Service Discovery Implementation:**\n\n```javascript\n// service-discovery.js - Service registry with health checks\nimport express from 'express';\nimport axios from 'axios';\n\nclass ServiceDiscovery {\n  constructor() {\n    this.services = new Map();\n    this.healthCheckInterval = 30000; // 30 seconds\n    this.startHealthChecks();\n  }\n  \n  // Register a service\n  registerService(serviceName, serviceInfo) {\n    const service = {\n      name: serviceName,\n      url: serviceInfo.url,\n      port: serviceInfo.port,\n      healthCheck: serviceInfo.healthCheck || '/health',\n      metadata: serviceInfo.metadata || {},\n      registeredAt: new Date().toISOString(),\n      lastHealthCheck: null,\n      healthy: true,\n      version: serviceInfo.version || '1.0.0'\n    };\n    \n    if (!this.services.has(serviceName)) {\n      this.services.set(serviceName, []);\n    }\n    \n    const instances = this.services.get(serviceName);\n    \n    // Check if instance already exists\n    const existingIndex = instances.findIndex(i => i.url === service.url);\n    if (existingIndex !== -1) {\n      instances[existingIndex] = service;\n    } else {\n      instances.push(service);\n    }\n    \n    console.log(`Service registered: ${serviceName} at ${service.url}`);\n    return service;\n  }\n  \n  // Deregister a service\n  deregisterService(serviceName, serviceUrl) {\n    const instances = this.services.get(serviceName);\n    if (instances) {\n      const filtered = instances.filter(instance => instance.url !== serviceUrl);\n      if (filtered.length === 0) {\n        this.services.delete(serviceName);\n      } else {\n        this.services.set(serviceName, filtered);\n      }\n      console.log(`Service deregistered: ${serviceName} at ${serviceUrl}`);\n    }\n  }\n  \n  // Get all instances of a service\n  getService(serviceName) {\n    return this.services.get(serviceName) || [];\n  }\n  \n  // Get healthy instances only\n  getHealthyInstances(serviceName) {\n    const instances = this.getService(serviceName);\n    return instances.filter(instance => instance.healthy);\n  }\n  \n  // Get all services\n  getAllServices() {\n    const result = {};\n    for (const [name, instances] of this.services.entries()) {\n      result[name] = instances;\n    }\n    return result;\n  }\n  \n  // Health check for all services\n  async performHealthCheck(service) {\n    try {\n      const response = await axios.get(\n        `${service.url}${service.healthCheck}`,\n        { timeout: 5000 }\n      );\n      \n      service.healthy = response.status === 200;\n      service.lastHealthCheck = new Date().toISOString();\n      \n      if (!service.healthy) {\n        console.warn(`Health check failed for ${service.name} at ${service.url}`);\n      }\n    } catch (error) {\n      service.healthy = false;\n      service.lastHealthCheck = new Date().toISOString();\n      console.error(`Health check error for ${service.name}:`, error.message);\n    }\n  }\n  \n  // Start periodic health checks\n  startHealthChecks() {\n    setInterval(async () => {\n      for (const instances of this.services.values()) {\n        for (const instance of instances) {\n          await this.performHealthCheck(instance);\n        }\n      }\n    }, this.healthCheckInterval);\n    \n    console.log(`Health checks started (interval: ${this.healthCheckInterval}ms)`);\n  }\n}\n\n// Service discovery server\nconst serviceDiscovery = new ServiceDiscovery();\nconst app = express();\napp.use(express.json());\n\n// Register service endpoint\napp.post('/register', (req, res) => {\n  const { serviceName, url, port, healthCheck, metadata, version } = req.body;\n  \n  if (!serviceName || !url) {\n    return res.status(400).json({ error: 'serviceName and url are required' });\n  }\n  \n  const service = serviceDiscovery.registerService(serviceName, {\n    url,\n    port,\n    healthCheck,\n    metadata,\n    version\n  });\n  \n  res.status(201).json({ message: 'Service registered successfully', service });\n});\n\n// Deregister service endpoint\napp.delete('/register/:serviceName', (req, res) => {\n  const { serviceName } = req.params;\n  const { url } = req.body;\n  \n  serviceDiscovery.deregisterService(serviceName, url);\n  res.json({ message: 'Service deregistered successfully' });\n});\n\n// Discover service endpoint\napp.get('/discover/:serviceName', (req, res) => {\n  const { serviceName } = req.params;\n  const healthyOnly = req.query.healthy === 'true';\n  \n  const instances = healthyOnly \n    ? serviceDiscovery.getHealthyInstances(serviceName)\n    : serviceDiscovery.getService(serviceName);\n  \n  if (instances.length === 0) {\n    return res.status(404).json({ error: `Service ${serviceName} not found` });\n  }\n  \n  res.json({ serviceName, instances });\n});\n\n// List all services\napp.get('/services', (req, res) => {\n  const services = serviceDiscovery.getAllServices();\n  res.json({ services });\n});\n\n// Health check endpoint\napp.get('/health', (req, res) => {\n  res.json({ \n    status: 'healthy',\n    services: Object.keys(serviceDiscovery.getAllServices()).length\n  });\n});\n\nconst PORT = process.env.SERVICE_DISCOVERY_PORT || 8500;\napp.listen(PORT, () => {\n  console.log(`Service Discovery running on port ${PORT}`);\n});\n\nexport { ServiceDiscovery };\nexport default app;\n```\n\n**Circuit Breaker Pattern:**\n\n```javascript\n// circuit-breaker.js - Prevents cascading failures\nimport EventEmitter from 'events';\n\nclass CircuitBreaker extends EventEmitter {\n  constructor(options = {}) {\n    super();\n    \n    // Configuration\n    this.failureThreshold = options.failureThreshold || 5;\n    this.recoveryTimeout = options.recoveryTimeout || 60000; // 60 seconds\n    this.monitoringPeriod = options.monitoringPeriod || 10000; // 10 seconds\n    this.expectedErrors = options.expectedErrors || [];\n    \n    // State\n    this.state = 'CLOSED'; // CLOSED, OPEN, HALF_OPEN\n    this.failureCount = 0;\n    this.successCount = 0;\n    this.lastFailureTime = null;\n    this.nextAttempt = Date.now();\n    \n    // Statistics\n    this.stats = {\n      totalRequests: 0,\n      totalFailures: 0,\n      totalSuccesses: 0\n    };\n    \n    // Reset failure count periodically\n    setInterval(() => {\n      if (this.state === 'CLOSED') {\n        this.failureCount = 0;\n      }\n    }, this.monitoringPeriod);\n  }\n  \n  async call(asyncFunction, ...args) {\n    this.stats.totalRequests++;\n    \n    if (this.state === 'OPEN') {\n      if (Date.now() < this.nextAttempt) {\n        const error = new Error('Circuit breaker is OPEN');\n        error.circuitBreakerOpen = true;\n        this.emit('fallback', error);\n        throw error;\n      } else {\n        this.state = 'HALF_OPEN';\n        this.emit('stateChange', 'HALF_OPEN');\n      }\n    }\n    \n    try {\n      const result = await asyncFunction.apply(this, args);\n      this.onSuccess();\n      return result;\n    } catch (error) {\n      this.onFailure(error);\n      throw error;\n    }\n  }\n  \n  onSuccess() {\n    this.stats.totalSuccesses++;\n    this.failureCount = 0;\n    \n    if (this.state === 'HALF_OPEN') {\n      this.state = 'CLOSED';\n      this.emit('stateChange', 'CLOSED');\n      console.log('Circuit breaker reset to CLOSED state');\n    }\n    \n    this.successCount++;\n  }\n  \n  onFailure(error) {\n    this.stats.totalFailures++;\n    this.failureCount++;\n    this.lastFailureTime = Date.now();\n    \n    // Check if error should be ignored\n    if (this.expectedErrors.some(expectedError => error instanceof expectedError)) {\n      return;\n    }\n    \n    this.emit('failure', error);\n    \n    if (this.failureCount >= this.failureThreshold) {\n      this.trip();\n    }\n  }\n  \n  trip() {\n    this.state = 'OPEN';\n    this.nextAttempt = Date.now() + this.recoveryTimeout;\n    this.emit('stateChange', 'OPEN');\n    this.emit('open');\n    console.log(`Circuit breaker tripped to OPEN state. Next attempt in ${this.recoveryTimeout}ms`);\n  }\n  \n  reset() {\n    this.state = 'CLOSED';\n    this.failureCount = 0;\n    this.successCount = 0;\n    this.lastFailureTime = null;\n    this.emit('stateChange', 'CLOSED');\n    console.log('Circuit breaker manually reset to CLOSED state');\n  }\n  \n  getStats() {\n    return {\n      state: this.state,\n      failureCount: this.failureCount,\n      successCount: this.successCount,\n      lastFailureTime: this.lastFailureTime,\n      nextAttempt: this.nextAttempt,\n      stats: this.stats,\n      healthPercentage: this.stats.totalRequests > 0 \n        ? ((this.stats.totalSuccesses / this.stats.totalRequests) * 100).toFixed(2)\n        : 100\n    };\n  }\n}\n\n// Usage example with external service calls\nimport axios from 'axios';\n\nclass ExternalServiceClient {\n  constructor(baseURL, options = {}) {\n    this.baseURL = baseURL;\n    this.circuitBreaker = new CircuitBreaker({\n      failureThreshold: options.failureThreshold || 3,\n      recoveryTimeout: options.recoveryTimeout || 30000,\n      expectedErrors: [axios.AxiosError]\n    });\n    \n    // Set up event listeners\n    this.circuitBreaker.on('open', () => {\n      console.log(`Circuit breaker OPEN for ${this.baseURL}`);\n    });\n    \n    this.circuitBreaker.on('stateChange', (newState) => {\n      console.log(`Circuit breaker state changed to ${newState} for ${this.baseURL}`);\n    });\n    \n    this.circuitBreaker.on('fallback', (error) => {\n      console.log(`Circuit breaker fallback triggered for ${this.baseURL}`);\n    });\n  }\n  \n  async get(endpoint, config = {}) {\n    return this.circuitBreaker.call(async () => {\n      const response = await axios.get(`${this.baseURL}${endpoint}`, {\n        timeout: 5000,\n        ...config\n      });\n      return response.data;\n    });\n  }\n  \n  async post(endpoint, data, config = {}) {\n    return this.circuitBreaker.call(async () => {\n      const response = await axios.post(`${this.baseURL}${endpoint}`, data, {\n        timeout: 5000,\n        ...config\n      });\n      return response.data;\n    });\n  }\n  \n  getCircuitBreakerStats() {\n    return this.circuitBreaker.getStats();\n  }\n  \n  resetCircuitBreaker() {\n    this.circuitBreaker.reset();\n  }\n}\n\n// Example microservice using circuit breaker\nclass OrderService {\n  constructor() {\n    this.userServiceClient = new ExternalServiceClient('http://user-service:3001');\n    this.paymentServiceClient = new ExternalServiceClient('http://payment-service:3004');\n    this.inventoryServiceClient = new ExternalServiceClient('http://inventory-service:3005');\n  }\n  \n  async createOrder(orderData) {\n    try {\n      // Validate user (with circuit breaker protection)\n      const user = await this.userServiceClient.get(`/users/${orderData.userId}`);\n      \n      // Check inventory (with circuit breaker protection)\n      const inventoryCheck = await this.inventoryServiceClient.post('/check', {\n        items: orderData.items\n      });\n      \n      if (!inventoryCheck.available) {\n        throw new Error('Insufficient inventory');\n      }\n      \n      // Process payment (with circuit breaker protection)\n      const payment = await this.paymentServiceClient.post('/charge', {\n        userId: orderData.userId,\n        amount: orderData.total,\n        paymentMethod: orderData.paymentMethod\n      });\n      \n      // Create order\n      const order = {\n        id: Date.now(),\n        userId: orderData.userId,\n        items: orderData.items,\n        total: orderData.total,\n        paymentId: payment.id,\n        status: 'confirmed',\n        createdAt: new Date().toISOString()\n      };\n      \n      return order;\n    } catch (error) {\n      if (error.circuitBreakerOpen) {\n        // Handle circuit breaker fallback\n        return this.handleFallback(orderData, error);\n      }\n      throw error;\n    }\n  }\n  \n  async handleFallback(orderData, error) {\n    // Implement fallback logic\n    console.log('Executing fallback logic for order creation');\n    \n    // Could save order to queue for later processing\n    // Could return cached data\n    // Could use alternative service\n    \n    return {\n      id: Date.now(),\n      userId: orderData.userId,\n      status: 'pending',\n      message: 'Order queued for processing when services are available',\n      error: error.message\n    };\n  }\n  \n  getServiceHealth() {\n    return {\n      userService: this.userServiceClient.getCircuitBreakerStats(),\n      paymentService: this.paymentServiceClient.getCircuitBreakerStats(),\n      inventoryService: this.inventoryServiceClient.getCircuitBreakerStats()\n    };\n  }\n}\n\nexport { CircuitBreaker, ExternalServiceClient, OrderService };\n```\n\n**Complete Microservice Example:**\n\n```javascript\n// user-service.js - Individual microservice\nimport express from 'express';\nimport { ServiceDiscovery } from './service-discovery.js';\n\nconst app = express();\napp.use(express.json());\n\n// In-memory user store (use database in production)\nconst users = new Map();\nlet nextId = 1;\n\n// User routes\napp.post('/users', (req, res) => {\n  const user = {\n    id: nextId++,\n    ...req.body,\n    createdAt: new Date().toISOString()\n  };\n  \n  users.set(user.id, user);\n  res.status(201).json(user);\n});\n\napp.get('/users/:id', (req, res) => {\n  const user = users.get(parseInt(req.params.id));\n  if (!user) {\n    return res.status(404).json({ error: 'User not found' });\n  }\n  res.json(user);\n});\n\napp.get('/users', (req, res) => {\n  res.json(Array.from(users.values()));\n});\n\n// Health check\napp.get('/health', (req, res) => {\n  res.json({ \n    status: 'healthy',\n    service: 'user-service',\n    timestamp: new Date().toISOString(),\n    users: users.size\n  });\n});\n\nconst PORT = process.env.PORT || 3001;\nconst SERVICE_URL = `http://localhost:${PORT}`;\n\napp.listen(PORT, async () => {\n  console.log(`User Service running on port ${PORT}`);\n  \n  // Register with service discovery\n  try {\n    await fetch('http://localhost:8500/register', {\n      method: 'POST',\n      headers: { 'Content-Type': 'application/json' },\n      body: JSON.stringify({\n        serviceName: 'user-service',\n        url: SERVICE_URL,\n        port: PORT,\n        healthCheck: '/health',\n        version: '1.0.0',\n        metadata: {\n          description: 'User management service',\n          team: 'user-team'\n        }\n      })\n    });\n    console.log('Registered with service discovery');\n  } catch (error) {\n    console.error('Failed to register with service discovery:', error.message);\n  }\n});\n\n// Graceful shutdown\nprocess.on('SIGTERM', async () => {\n  console.log('Shutting down gracefully...');\n  \n  // Deregister from service discovery\n  try {\n    await fetch('http://localhost:8500/register/user-service', {\n      method: 'DELETE',\n      headers: { 'Content-Type': 'application/json' },\n      body: JSON.stringify({ url: SERVICE_URL })\n    });\n    console.log('Deregistered from service discovery');\n  } catch (error) {\n    console.error('Failed to deregister:', error.message);\n  }\n  \n  process.exit(0);\n});\n\nexport default app;\n```\n\n**Benefits of Microservices with Node.js:**\n\n1. **Technology Diversity** - Each service can use different tech stacks\n2. **Independent Scaling** - Scale services based on individual load\n3. **Team Autonomy** - Teams can work independently on services\n4. **Fault Isolation** - Failures in one service don't affect others\n5. **Deployment Independence** - Deploy services separately\n6. **Better Resource Utilization** - Right-size infrastructure per service\n\n**Best Practices:**\n\n1. **Design for failure** - Use circuit breakers and timeouts\n2. **Implement proper monitoring** and distributed tracing\n3. **Use event-driven communication** for loose coupling\n4. **Implement proper security** with service-to-service authentication\n5. **Version your APIs** to handle breaking changes\n6. **Use containerization** (Docker) for consistent environments\n7. **Implement proper logging** with correlation IDs\n8. **Design for eventual consistency** in distributed systems",
        "difficulty": "Expert",
        "category": "Microservices & Architecture"
    },
    {
        "id": 38,
        "question": "How do you implement message queues, event sourcing, and CQRS patterns in Node.js? Explain with RabbitMQ and event-driven architecture.",
        "solution": "Message queues and event-driven patterns are essential for building scalable, decoupled systems. Here's how to implement them:\n\n**Message Queue Implementation with RabbitMQ:**\n\n```javascript\n// message-queue.js - RabbitMQ wrapper\nimport amqp from 'amqplib';\nimport EventEmitter from 'events';\n\nclass MessageQueue extends EventEmitter {\n  constructor(connectionString = 'amqp://localhost') {\n    super();\n    this.connectionString = connectionString;\n    this.connection = null;\n    this.channel = null;\n    this.exchanges = new Map();\n    this.queues = new Map();\n  }\n  \n  async connect() {\n    try {\n      this.connection = await amqp.connect(this.connectionString);\n      this.channel = await this.connection.createChannel();\n      \n      // Handle connection events\n      this.connection.on('error', (err) => {\n        console.error('RabbitMQ connection error:', err);\n        this.emit('error', err);\n      });\n      \n      this.connection.on('close', () => {\n        console.log('RabbitMQ connection closed');\n        this.emit('disconnected');\n      });\n      \n      console.log('Connected to RabbitMQ');\n      this.emit('connected');\n    } catch (error) {\n      console.error('Failed to connect to RabbitMQ:', error);\n      throw error;\n    }\n  }\n  \n  async declareExchange(exchangeName, exchangeType = 'topic', options = {}) {\n    if (!this.channel) {\n      throw new Error('Not connected to RabbitMQ');\n    }\n    \n    await this.channel.assertExchange(exchangeName, exchangeType, {\n      durable: true,\n      ...options\n    });\n    \n    this.exchanges.set(exchangeName, { type: exchangeType, options });\n    console.log(`Exchange declared: ${exchangeName} (${exchangeType})`);\n  }\n  \n  async declareQueue(queueName, options = {}) {\n    if (!this.channel) {\n      throw new Error('Not connected to RabbitMQ');\n    }\n    \n    const queue = await this.channel.assertQueue(queueName, {\n      durable: true,\n      ...options\n    });\n    \n    this.queues.set(queueName, { options, info: queue });\n    console.log(`Queue declared: ${queueName}`);\n    return queue;\n  }\n  \n  async bindQueue(queueName, exchangeName, routingKey) {\n    if (!this.channel) {\n      throw new Error('Not connected to RabbitMQ');\n    }\n    \n    await this.channel.bindQueue(queueName, exchangeName, routingKey);\n    console.log(`Queue ${queueName} bound to exchange ${exchangeName} with key ${routingKey}`);\n  }\n  \n  async publishMessage(exchangeName, routingKey, message, options = {}) {\n    if (!this.channel) {\n      throw new Error('Not connected to RabbitMQ');\n    }\n    \n    const messageBuffer = Buffer.from(JSON.stringify(message));\n    \n    const publishOptions = {\n      persistent: true,\n      timestamp: Date.now(),\n      messageId: this.generateMessageId(),\n      ...options\n    };\n    \n    const published = this.channel.publish(\n      exchangeName,\n      routingKey,\n      messageBuffer,\n      publishOptions\n    );\n    \n    if (!published) {\n      throw new Error('Failed to publish message - buffer full');\n    }\n    \n    console.log(`Message published to ${exchangeName}:${routingKey}`);\n    this.emit('messagePublished', { exchangeName, routingKey, message });\n  }\n  \n  async consumeMessages(queueName, handler, options = {}) {\n    if (!this.channel) {\n      throw new Error('Not connected to RabbitMQ');\n    }\n    \n    const consumerOptions = {\n      noAck: false,\n      ...options\n    };\n    \n    await this.channel.consume(queueName, async (msg) => {\n      if (msg === null) return;\n      \n      try {\n        const messageContent = JSON.parse(msg.content.toString());\n        const messageInfo = {\n          content: messageContent,\n          properties: msg.properties,\n          fields: msg.fields\n        };\n        \n        console.log(`Processing message from ${queueName}:`, messageContent);\n        \n        // Call the handler\n        await handler(messageInfo);\n        \n        // Acknowledge the message\n        this.channel.ack(msg);\n        \n        this.emit('messageProcessed', { queueName, message: messageContent });\n      } catch (error) {\n        console.error(`Error processing message from ${queueName}:`, error);\n        \n        // Reject and requeue the message (or send to DLQ)\n        this.channel.nack(msg, false, false);\n        \n        this.emit('messageError', { queueName, error, message: msg });\n      }\n    }, consumerOptions);\n    \n    console.log(`Consumer started for queue: ${queueName}`);\n  }\n  \n  generateMessageId() {\n    return `msg-${Date.now()}-${Math.random().toString(36).substr(2, 9)}`;\n  }\n  \n  async close() {\n    if (this.connection) {\n      await this.connection.close();\n      console.log('RabbitMQ connection closed');\n    }\n  }\n}\n\n// Event-driven service architecture\nclass EventBus {\n  constructor(messageQueue) {\n    this.messageQueue = messageQueue;\n    this.eventHandlers = new Map();\n    this.setupInfrastructure();\n  }\n  \n  async setupInfrastructure() {\n    // Create main events exchange\n    await this.messageQueue.declareExchange('events', 'topic');\n    \n    // Create dead letter exchange for failed events\n    await this.messageQueue.declareExchange('events.dlx', 'direct');\n  }\n  \n  async publishEvent(eventType, eventData, metadata = {}) {\n    const event = {\n      id: this.generateEventId(),\n      type: eventType,\n      data: eventData,\n      timestamp: new Date().toISOString(),\n      version: '1.0',\n      source: metadata.source || 'unknown',\n      correlationId: metadata.correlationId,\n      causationId: metadata.causationId\n    };\n    \n    await this.messageQueue.publishMessage(\n      'events',\n      eventType,\n      event,\n      {\n        headers: {\n          eventType,\n          version: event.version,\n          correlationId: event.correlationId\n        }\n      }\n    );\n    \n    console.log(`Event published: ${eventType}`);\n    return event;\n  }\n  \n  async subscribeToEvent(eventType, serviceName, handler) {\n    const queueName = `${serviceName}.${eventType}`;\n    \n    // Declare queue with dead letter exchange\n    await this.messageQueue.declareQueue(queueName, {\n      arguments: {\n        'x-dead-letter-exchange': 'events.dlx',\n        'x-dead-letter-routing-key': queueName + '.failed'\n      }\n    });\n    \n    // Bind queue to events exchange\n    await this.messageQueue.bindQueue(queueName, 'events', eventType);\n    \n    // Set up consumer\n    await this.messageQueue.consumeMessages(queueName, async (messageInfo) => {\n      const event = messageInfo.content;\n      console.log(`Handling event ${event.type} in service ${serviceName}`);\n      \n      try {\n        await handler(event);\n      } catch (error) {\n        console.error(`Event handler failed for ${event.type}:`, error);\n        throw error; // This will cause message to be nacked and sent to DLQ\n      }\n    });\n    \n    console.log(`Subscribed to event: ${eventType} (service: ${serviceName})`);\n  }\n  \n  generateEventId() {\n    return `evt-${Date.now()}-${Math.random().toString(36).substr(2, 9)}`;\n  }\n}\n\nexport { MessageQueue, EventBus };\n```\n\n**Event Sourcing Implementation:**\n\n```javascript\n// event-store.js - Event sourcing implementation\nimport fs from 'fs/promises';\nimport path from 'path';\nimport { EventEmitter } from 'events';\n\nclass EventStore extends EventEmitter {\n  constructor(storePath = './events') {\n    super();\n    this.storePath = storePath;\n    this.streams = new Map();\n    this.snapshots = new Map();\n    this.eventSequence = 0;\n    this.init();\n  }\n  \n  async init() {\n    try {\n      await fs.mkdir(this.storePath, { recursive: true });\n      await this.loadEvents();\n    } catch (error) {\n      console.error('Failed to initialize event store:', error);\n    }\n  }\n  \n  async loadEvents() {\n    try {\n      const files = await fs.readdir(this.storePath);\n      const eventFiles = files.filter(file => file.endsWith('.events'));\n      \n      for (const file of eventFiles) {\n        const streamId = path.basename(file, '.events');\n        const content = await fs.readFile(path.join(this.storePath, file), 'utf8');\n        \n        if (content.trim()) {\n          const events = content.split('\\n')\n            .filter(line => line.trim())\n            .map(line => JSON.parse(line));\n          \n          this.streams.set(streamId, events);\n          \n          // Update sequence number\n          events.forEach(event => {\n            if (event.sequence > this.eventSequence) {\n              this.eventSequence = event.sequence;\n            }\n          });\n        }\n      }\n      \n      console.log(`Loaded ${this.streams.size} event streams`);\n    } catch (error) {\n      console.error('Error loading events:', error);\n    }\n  }\n  \n  async appendEvent(streamId, eventType, eventData, metadata = {}) {\n    const event = {\n      id: this.generateEventId(),\n      streamId,\n      eventType,\n      eventData,\n      sequence: ++this.eventSequence,\n      timestamp: new Date().toISOString(),\n      version: metadata.version || 1,\n      correlationId: metadata.correlationId,\n      causationId: metadata.causationId,\n      userId: metadata.userId\n    };\n    \n    // Add to in-memory stream\n    if (!this.streams.has(streamId)) {\n      this.streams.set(streamId, []);\n    }\n    this.streams.get(streamId).push(event);\n    \n    // Persist to disk\n    await this.persistEvent(streamId, event);\n    \n    // Emit event for subscribers\n    this.emit('eventAppended', event);\n    this.emit(`event:${eventType}`, event);\n    \n    console.log(`Event appended: ${eventType} to stream ${streamId}`);\n    return event;\n  }\n  \n  async persistEvent(streamId, event) {\n    const filePath = path.join(this.storePath, `${streamId}.events`);\n    const eventLine = JSON.stringify(event) + '\\n';\n    \n    try {\n      await fs.appendFile(filePath, eventLine, 'utf8');\n    } catch (error) {\n      console.error('Failed to persist event:', error);\n      throw error;\n    }\n  }\n  \n  getEvents(streamId, fromVersion = 0) {\n    const events = this.streams.get(streamId) || [];\n    return events.filter(event => event.version > fromVersion);\n  }\n  \n  getAllEvents(fromSequence = 0) {\n    const allEvents = [];\n    \n    for (const events of this.streams.values()) {\n      allEvents.push(...events.filter(event => event.sequence > fromSequence));\n    }\n    \n    return allEvents.sort((a, b) => a.sequence - b.sequence);\n  }\n  \n  async createSnapshot(streamId, aggregateState, version) {\n    const snapshot = {\n      streamId,\n      aggregateState,\n      version,\n      timestamp: new Date().toISOString()\n    };\n    \n    this.snapshots.set(streamId, snapshot);\n    \n    // Persist snapshot\n    const snapshotPath = path.join(this.storePath, `${streamId}.snapshot`);\n    await fs.writeFile(snapshotPath, JSON.stringify(snapshot), 'utf8');\n    \n    console.log(`Snapshot created for stream ${streamId} at version ${version}`);\n    return snapshot;\n  }\n  \n  getSnapshot(streamId) {\n    return this.snapshots.get(streamId);\n  }\n  \n  generateEventId() {\n    return `evt-${Date.now()}-${Math.random().toString(36).substr(2, 9)}`;\n  }\n}\n\n// Aggregate base class for event sourcing\nclass Aggregate {\n  constructor(id) {\n    this.id = id;\n    this.version = 0;\n    this.uncommittedEvents = [];\n  }\n  \n  // Apply event to aggregate state\n  apply(event) {\n    const handler = this[`on${event.eventType}`];\n    if (handler) {\n      handler.call(this, event.eventData);\n    }\n    this.version = event.version;\n  }\n  \n  // Raise a new event\n  raise(eventType, eventData) {\n    const event = {\n      eventType,\n      eventData,\n      version: this.version + 1\n    };\n    \n    this.uncommittedEvents.push(event);\n    this.apply(event);\n  }\n  \n  // Get uncommitted events and clear them\n  getUncommittedEvents() {\n    const events = [...this.uncommittedEvents];\n    this.uncommittedEvents = [];\n    return events;\n  }\n  \n  // Load aggregate from events\n  static fromEvents(id, events) {\n    const aggregate = new this(id);\n    \n    events.forEach(event => {\n      aggregate.apply(event);\n    });\n    \n    return aggregate;\n  }\n}\n\n// Example: User aggregate\nclass User extends Aggregate {\n  constructor(id) {\n    super(id);\n    this.email = null;\n    this.name = null;\n    this.isActive = false;\n    this.registeredAt = null;\n  }\n  \n  // Commands\n  register(email, name) {\n    if (this.isActive) {\n      throw new Error('User is already registered');\n    }\n    \n    this.raise('UserRegistered', {\n      email,\n      name,\n      registeredAt: new Date().toISOString()\n    });\n  }\n  \n  updateEmail(newEmail) {\n    if (!this.isActive) {\n      throw new Error('User is not active');\n    }\n    \n    if (this.email === newEmail) {\n      return; // No change\n    }\n    \n    this.raise('UserEmailUpdated', {\n      oldEmail: this.email,\n      newEmail\n    });\n  }\n  \n  deactivate() {\n    if (!this.isActive) {\n      throw new Error('User is already inactive');\n    }\n    \n    this.raise('UserDeactivated', {\n      deactivatedAt: new Date().toISOString()\n    });\n  }\n  \n  // Event handlers\n  onUserRegistered(eventData) {\n    this.email = eventData.email;\n    this.name = eventData.name;\n    this.isActive = true;\n    this.registeredAt = eventData.registeredAt;\n  }\n  \n  onUserEmailUpdated(eventData) {\n    this.email = eventData.newEmail;\n  }\n  \n  onUserDeactivated(eventData) {\n    this.isActive = false;\n  }\n}\n\nexport { EventStore, Aggregate, User };\n```\n\n**CQRS (Command Query Responsibility Segregation) Implementation:**\n\n```javascript\n// cqrs.js - CQRS implementation\nimport { EventEmitter } from 'events';\n\n// Command side - handles writes\nclass CommandHandler extends EventEmitter {\n  constructor(eventStore, aggregateClass) {\n    super();\n    this.eventStore = eventStore;\n    this.aggregateClass = aggregateClass;\n  }\n  \n  async handle(command) {\n    try {\n      console.log(`Handling command: ${command.type}`);\n      \n      // Load aggregate from events\n      const events = this.eventStore.getEvents(command.aggregateId);\n      const aggregate = this.aggregateClass.fromEvents(command.aggregateId, events);\n      \n      // Execute command\n      const methodName = `handle${command.type}`;\n      if (typeof this[methodName] === 'function') {\n        await this[methodName](aggregate, command);\n      } else {\n        throw new Error(`Unknown command type: ${command.type}`);\n      }\n      \n      // Save new events\n      const uncommittedEvents = aggregate.getUncommittedEvents();\n      for (const event of uncommittedEvents) {\n        await this.eventStore.appendEvent(\n          command.aggregateId,\n          event.eventType,\n          event.eventData,\n          {\n            version: event.version,\n            correlationId: command.correlationId,\n            causationId: command.id,\n            userId: command.userId\n          }\n        );\n      }\n      \n      this.emit('commandHandled', { command, events: uncommittedEvents });\n      \n      return {\n        success: true,\n        events: uncommittedEvents,\n        aggregateId: command.aggregateId\n      };\n    } catch (error) {\n      console.error(`Command handling failed:`, error);\n      this.emit('commandFailed', { command, error });\n      throw error;\n    }\n  }\n}\n\n// User command handler\nclass UserCommandHandler extends CommandHandler {\n  constructor(eventStore) {\n    super(eventStore, User);\n  }\n  \n  async handleRegisterUser(aggregate, command) {\n    aggregate.register(command.email, command.name);\n  }\n  \n  async handleUpdateUserEmail(aggregate, command) {\n    aggregate.updateEmail(command.newEmail);\n  }\n  \n  async handleDeactivateUser(aggregate, command) {\n    aggregate.deactivate();\n  }\n}\n\n// Query side - handles reads\nclass QueryHandler {\n  constructor() {\n    this.projections = new Map();\n  }\n  \n  // Register a projection\n  registerProjection(name, projection) {\n    this.projections.set(name, projection);\n  }\n  \n  // Query a projection\n  async query(projectionName, query) {\n    const projection = this.projections.get(projectionName);\n    if (!projection) {\n      throw new Error(`Unknown projection: ${projectionName}`);\n    }\n    \n    return await projection.query(query);\n  }\n}\n\n// Read model projections\nclass UserListProjection {\n  constructor() {\n    this.users = new Map();\n  }\n  \n  // Handle events to build read model\n  async handleUserRegistered(event) {\n    const user = {\n      id: event.streamId,\n      email: event.eventData.email,\n      name: event.eventData.name,\n      isActive: true,\n      registeredAt: event.eventData.registeredAt,\n      lastUpdated: event.timestamp\n    };\n    \n    this.users.set(event.streamId, user);\n    console.log(`User projection updated: ${user.email}`);\n  }\n  \n  async handleUserEmailUpdated(event) {\n    const user = this.users.get(event.streamId);\n    if (user) {\n      user.email = event.eventData.newEmail;\n      user.lastUpdated = event.timestamp;\n    }\n  }\n  \n  async handleUserDeactivated(event) {\n    const user = this.users.get(event.streamId);\n    if (user) {\n      user.isActive = false;\n      user.lastUpdated = event.timestamp;\n    }\n  }\n  \n  // Query methods\n  async query(queryParams) {\n    const { type, filters = {} } = queryParams;\n    \n    switch (type) {\n      case 'getAllUsers':\n        return Array.from(this.users.values());\n        \n      case 'getUserById':\n        return this.users.get(filters.id);\n        \n      case 'getActiveUsers':\n        return Array.from(this.users.values())\n          .filter(user => user.isActive);\n        \n      case 'getUsersByEmail':\n        return Array.from(this.users.values())\n          .filter(user => user.email.includes(filters.email));\n        \n      default:\n        throw new Error(`Unknown query type: ${type}`);\n    }\n  }\n}\n\n// CQRS Application Service\nclass UserApplicationService {\n  constructor(eventStore, eventBus) {\n    this.commandHandler = new UserCommandHandler(eventStore);\n    this.queryHandler = new QueryHandler();\n    this.eventBus = eventBus;\n    \n    // Set up projections\n    this.userListProjection = new UserListProjection();\n    this.queryHandler.registerProjection('userList', this.userListProjection);\n    \n    // Subscribe to events for projections\n    this.setupEventHandlers();\n  }\n  \n  setupEventHandlers() {\n    // Subscribe to events to update read models\n    this.eventBus.subscribeToEvent('UserRegistered', 'user-projection', \n      (event) => this.userListProjection.handleUserRegistered(event));\n    \n    this.eventBus.subscribeToEvent('UserEmailUpdated', 'user-projection',\n      (event) => this.userListProjection.handleUserEmailUpdated(event));\n    \n    this.eventBus.subscribeToEvent('UserDeactivated', 'user-projection',\n      (event) => this.userListProjection.handleUserDeactivated(event));\n  }\n  \n  // Command methods\n  async registerUser(userId, email, name, metadata = {}) {\n    const command = {\n      id: this.generateId(),\n      type: 'RegisterUser',\n      aggregateId: userId,\n      email,\n      name,\n      correlationId: metadata.correlationId,\n      userId: metadata.userId\n    };\n    \n    return await this.commandHandler.handle(command);\n  }\n  \n  async updateUserEmail(userId, newEmail, metadata = {}) {\n    const command = {\n      id: this.generateId(),\n      type: 'UpdateUserEmail',\n      aggregateId: userId,\n      newEmail,\n      correlationId: metadata.correlationId,\n      userId: metadata.userId\n    };\n    \n    return await this.commandHandler.handle(command);\n  }\n  \n  async deactivateUser(userId, metadata = {}) {\n    const command = {\n      id: this.generateId(),\n      type: 'DeactivateUser',\n      aggregateId: userId,\n      correlationId: metadata.correlationId,\n      userId: metadata.userId\n    };\n    \n    return await this.commandHandler.handle(command);\n  }\n  \n  // Query methods\n  async getAllUsers() {\n    return await this.queryHandler.query('userList', { type: 'getAllUsers' });\n  }\n  \n  async getUserById(userId) {\n    return await this.queryHandler.query('userList', {\n      type: 'getUserById',\n      filters: { id: userId }\n    });\n  }\n  \n  async getActiveUsers() {\n    return await this.queryHandler.query('userList', { type: 'getActiveUsers' });\n  }\n  \n  generateId() {\n    return `cmd-${Date.now()}-${Math.random().toString(36).substr(2, 9)}`;\n  }\n}\n\nexport { CommandHandler, QueryHandler, UserApplicationService, UserListProjection };\n```\n\n**Usage Example:**\n\n```javascript\n// app.js - Putting it all together\nimport { MessageQueue, EventBus } from './message-queue.js';\nimport { EventStore } from './event-store.js';\nimport { UserApplicationService } from './cqrs.js';\n\nasync function main() {\n  try {\n    // Initialize components\n    const messageQueue = new MessageQueue();\n    await messageQueue.connect();\n    \n    const eventBus = new EventBus(messageQueue);\n    const eventStore = new EventStore('./data/events');\n    const userService = new UserApplicationService(eventStore, eventBus);\n    \n    // Example usage\n    console.log('\\n=== CQRS Example ==={');\n    \n    // Register a user (command)\n    const userId = 'user-123';\n    await userService.registerUser(userId, 'john@example.com', 'John Doe');\n    \n    // Query users (query)\n    const allUsers = await userService.getAllUsers();\n    console.log('All users:', allUsers);\n    \n    // Update user email (command)\n    await userService.updateUserEmail(userId, 'john.doe@example.com');\n    \n    // Query specific user (query)\n    const user = await userService.getUserById(userId);\n    console.log('Updated user:', user);\n    \n    // Deactivate user (command)\n    await userService.deactivateUser(userId);\n    \n    // Query active users (query)\n    const activeUsers = await userService.getActiveUsers();\n    console.log('Active users:', activeUsers);\n    \n  } catch (error) {\n    console.error('Application error:', error);\n  }\n}\n\nmain();\n```\n\n**Benefits of This Architecture:**\n\n1. **Scalability** - Commands and queries can be scaled independently\n2. **Event History** - Complete audit trail of all changes\n3. **Loose Coupling** - Services communicate via events\n4. **Flexibility** - Easy to add new projections and handlers\n5. **Fault Tolerance** - Events can be replayed if projections fail\n6. **Time Travel** - Can reconstruct state at any point in time\n\n**Best Practices:**\n\n1. **Idempotent handlers** - Handle duplicate events gracefully\n2. **Event versioning** - Handle schema evolution\n3. **Monitoring** - Track message processing and failures\n4. **Dead letter queues** - Handle poison messages\n5. **Correlation IDs** - Track requests across services\n6. **Snapshots** - Optimize aggregate rebuilding\n7. **Eventual consistency** - Design for delayed consistency",
        "difficulty": "Expert",
        "category": "Event-Driven Architecture"
    },
    {
        "id": 39,
        "question": "How do you design and implement a scalable real-time chat application with Node.js? Include WebSockets, message persistence, and horizontal scaling.",
        "solution": "Building a scalable chat application requires careful architecture for real-time communication, data persistence, and horizontal scaling. Here's a comprehensive implementation:\n\n**Core Chat Server with Socket.IO:**\n\n```javascript\n// chat-server.js - Main chat server\nimport express from 'express';\nimport { createServer } from 'http';\nimport { Server } from 'socket.io';\nimport { createAdapter } from '@socket.io/redis-adapter';\nimport { createClient } from 'redis';\nimport jwt from 'jsonwebtoken';\nimport rateLimit from 'express-rate-limit';\n\nclass ChatServer {\n  constructor(options = {}) {\n    this.app = express();\n    this.server = createServer(this.app);\n    this.port = options.port || 3000;\n    this.redisUrl = options.redisUrl || 'redis://localhost:6379';\n    \n    // Initialize components\n    this.setupMiddleware();\n    this.setupSocketIO();\n    this.setupRedis();\n    this.setupRoutes();\n    \n    // Chat state\n    this.rooms = new Map();\n    this.userSessions = new Map();\n    this.messageHistory = new MessageStore();\n  }\n  \n  setupMiddleware() {\n    this.app.use(express.json());\n    \n    // Rate limiting\n    const limiter = rateLimit({\n      windowMs: 1 * 60 * 1000, // 1 minute\n      max: 60, // limit each IP to 60 requests per windowMs\n      message: 'Too many requests'\n    });\n    this.app.use('/api/', limiter);\n  }\n  \n  async setupRedis() {\n    try {\n      // Redis for Socket.IO adapter (scaling across multiple servers)\n      this.pubClient = createClient({ url: this.redisUrl });\n      this.subClient = this.pubClient.duplicate();\n      \n      await this.pubClient.connect();\n      await this.subClient.connect();\n      \n      // Use Redis adapter for Socket.IO clustering\n      this.io.adapter(createAdapter(this.pubClient, this.subClient));\n      \n      console.log('Redis connected for Socket.IO clustering');\n    } catch (error) {\n      console.error('Redis connection failed:', error);\n    }\n  }\n  \n  setupSocketIO() {\n    this.io = new Server(this.server, {\n      cors: {\n        origin: process.env.CLIENT_URL || \"http://localhost:3000\",\n        methods: [\"GET\", \"POST\"]\n      },\n      transports: ['websocket', 'polling'],\n      allowEIO3: true\n    });\n    \n    // Authentication middleware\n    this.io.use(async (socket, next) => {\n      try {\n        const token = socket.handshake.auth.token;\n        if (!token) {\n          throw new Error('No token provided');\n        }\n        \n        const decoded = jwt.verify(token, process.env.JWT_SECRET || 'fallback-secret');\n        socket.userId = decoded.userId;\n        socket.username = decoded.username;\n        \n        next();\n      } catch (error) {\n        console.error('Socket authentication failed:', error.message);\n        next(new Error('Authentication failed'));\n      }\n    });\n    \n    // Rate limiting for socket events\n    this.io.use((socket, next) => {\n      socket.rateLimiter = new Map();\n      next();\n    });\n    \n    this.setupSocketEvents();\n  }\n  \n  setupSocketEvents() {\n    this.io.on('connection', (socket) => {\n      console.log(`User connected: ${socket.username} (${socket.userId})`);\n      \n      // Track user session\n      this.userSessions.set(socket.userId, {\n        socketId: socket.id,\n        username: socket.username,\n        connectedAt: new Date(),\n        lastActivity: new Date()\n      });\n      \n      // Socket event handlers\n      socket.on('join-room', (data) => this.handleJoinRoom(socket, data));\n      socket.on('leave-room', (data) => this.handleLeaveRoom(socket, data));\n      socket.on('send-message', (data) => this.handleSendMessage(socket, data));\n      socket.on('typing-start', (data) => this.handleTypingStart(socket, data));\n      socket.on('typing-stop', (data) => this.handleTypingStop(socket, data));\n      socket.on('get-room-history', (data) => this.handleGetRoomHistory(socket, data));\n      socket.on('disconnect', () => this.handleDisconnect(socket));\n      \n      // Send user's active rooms\n      this.sendUserRooms(socket);\n    });\n  }\n  \n  // Rate limiting helper\n  checkRateLimit(socket, event, maxRequests = 10, windowMs = 60000) {\n    const now = Date.now();\n    const userLimits = socket.rateLimiter.get(event) || { count: 0, resetTime: now + windowMs };\n    \n    if (now > userLimits.resetTime) {\n      userLimits.count = 0;\n      userLimits.resetTime = now + windowMs;\n    }\n    \n    if (userLimits.count >= maxRequests) {\n      socket.emit('rate-limit-exceeded', { event, retryAfter: userLimits.resetTime - now });\n      return false;\n    }\n    \n    userLimits.count++;\n    socket.rateLimiter.set(event, userLimits);\n    return true;\n  }\n  \n  async handleJoinRoom(socket, data) {\n    if (!this.checkRateLimit(socket, 'join-room', 5)) return;\n    \n    try {\n      const { roomId, roomType = 'public' } = data;\n      \n      if (!roomId) {\n        socket.emit('error', { message: 'Room ID is required' });\n        return;\n      }\n      \n      // Validate room access (implement your authorization logic)\n      const canJoin = await this.validateRoomAccess(socket.userId, roomId, roomType);\n      if (!canJoin) {\n        socket.emit('error', { message: 'Access denied to room' });\n        return;\n      }\n      \n      socket.join(roomId);\n      \n      // Update room info\n      if (!this.rooms.has(roomId)) {\n        this.rooms.set(roomId, {\n          id: roomId,\n          type: roomType,\n          members: new Set(),\n          createdAt: new Date(),\n          lastActivity: new Date()\n        });\n      }\n      \n      const room = this.rooms.get(roomId);\n      room.members.add(socket.userId);\n      room.lastActivity = new Date();\n      \n      // Notify room members\n      socket.to(roomId).emit('user-joined', {\n        userId: socket.userId,\n        username: socket.username,\n        timestamp: new Date().toISOString()\n      });\n      \n      // Send confirmation to user\n      socket.emit('room-joined', {\n        roomId,\n        memberCount: room.members.size,\n        roomInfo: {\n          id: room.id,\n          type: room.type,\n          memberCount: room.members.size\n        }\n      });\n      \n      console.log(`${socket.username} joined room: ${roomId}`);\n    } catch (error) {\n      console.error('Error joining room:', error);\n      socket.emit('error', { message: 'Failed to join room' });\n    }\n  }\n  \n  async handleSendMessage(socket, data) {\n    if (!this.checkRateLimit(socket, 'send-message', 30)) return;\n    \n    try {\n      const { roomId, content, messageType = 'text', replyTo } = data;\n      \n      if (!roomId || !content?.trim()) {\n        socket.emit('error', { message: 'Room ID and message content are required' });\n        return;\n      }\n      \n      // Validate message content\n      if (content.length > 4000) {\n        socket.emit('error', { message: 'Message too long' });\n        return;\n      }\n      \n      // Check if user is in room\n      const rooms = Array.from(socket.rooms);\n      if (!rooms.includes(roomId)) {\n        socket.emit('error', { message: 'You are not in this room' });\n        return;\n      }\n      \n      // Create message object\n      const message = {\n        id: this.generateMessageId(),\n        roomId,\n        userId: socket.userId,\n        username: socket.username,\n        content: this.sanitizeMessage(content),\n        messageType,\n        replyTo,\n        timestamp: new Date().toISOString(),\n        edited: false\n      };\n      \n      // Save to message store\n      await this.messageHistory.saveMessage(message);\n      \n      // Broadcast to room members\n      this.io.to(roomId).emit('new-message', message);\n      \n      // Update room activity\n      const room = this.rooms.get(roomId);\n      if (room) {\n        room.lastActivity = new Date();\n      }\n      \n      console.log(`Message sent in room ${roomId} by ${socket.username}`);\n    } catch (error) {\n      console.error('Error sending message:', error);\n      socket.emit('error', { message: 'Failed to send message' });\n    }\n  }\n  \n  handleTypingStart(socket, data) {\n    if (!this.checkRateLimit(socket, 'typing', 20)) return;\n    \n    const { roomId } = data;\n    if (roomId) {\n      socket.to(roomId).emit('user-typing', {\n        userId: socket.userId,\n        username: socket.username,\n        isTyping: true\n      });\n    }\n  }\n  \n  handleTypingStop(socket, data) {\n    const { roomId } = data;\n    if (roomId) {\n      socket.to(roomId).emit('user-typing', {\n        userId: socket.userId,\n        username: socket.username,\n        isTyping: false\n      });\n    }\n  }\n  \n  async handleGetRoomHistory(socket, data) {\n    if (!this.checkRateLimit(socket, 'get-history', 10)) return;\n    \n    try {\n      const { roomId, limit = 50, offset = 0 } = data;\n      \n      // Check if user has access to room\n      const rooms = Array.from(socket.rooms);\n      if (!rooms.includes(roomId)) {\n        socket.emit('error', { message: 'Access denied to room history' });\n        return;\n      }\n      \n      const messages = await this.messageHistory.getRoomMessages(roomId, limit, offset);\n      \n      socket.emit('room-history', {\n        roomId,\n        messages,\n        hasMore: messages.length === limit\n      });\n    } catch (error) {\n      console.error('Error getting room history:', error);\n      socket.emit('error', { message: 'Failed to get room history' });\n    }\n  }\n  \n  handleDisconnect(socket) {\n    console.log(`User disconnected: ${socket.username} (${socket.userId})`);\n    \n    // Remove from user sessions\n    this.userSessions.delete(socket.userId);\n    \n    // Remove from rooms and notify\n    for (const [roomId, room] of this.rooms.entries()) {\n      if (room.members.has(socket.userId)) {\n        room.members.delete(socket.userId);\n        \n        // Notify room members\n        socket.to(roomId).emit('user-left', {\n          userId: socket.userId,\n          username: socket.username,\n          timestamp: new Date().toISOString()\n        });\n        \n        // Clean up empty rooms\n        if (room.members.size === 0) {\n          this.rooms.delete(roomId);\n        }\n      }\n    }\n  }\n  \n  // Helper methods\n  async validateRoomAccess(userId, roomId, roomType) {\n    // Implement your room access logic here\n    // For now, allow access to all public rooms\n    if (roomType === 'public') return true;\n    \n    // For private rooms, check membership, invitations, etc.\n    // This would typically involve database queries\n    return true;\n  }\n  \n  sanitizeMessage(content) {\n    // Basic HTML sanitization (use a proper library like DOMPurify in production)\n    return content\n      .replace(/</g, '&lt;')\n      .replace(/>/g, '&gt;')\n      .replace(/\"/g, '&quot;')\n      .replace(/'/g, '&#x27;')\n      .trim();\n  }\n  \n  generateMessageId() {\n    return `msg-${Date.now()}-${Math.random().toString(36).substr(2, 9)}`;\n  }\n  \n  async sendUserRooms(socket) {\n    // Send list of rooms user is a member of\n    const userRooms = [];\n    for (const [roomId, room] of this.rooms.entries()) {\n      if (room.members.has(socket.userId)) {\n        userRooms.push({\n          id: roomId,\n          type: room.type,\n          memberCount: room.members.size,\n          lastActivity: room.lastActivity\n        });\n      }\n    }\n    \n    socket.emit('user-rooms', userRooms);\n  }\n  \n  // REST API routes\n  setupRoutes() {\n    // Create room\n    this.app.post('/api/rooms', async (req, res) => {\n      try {\n        const { name, type = 'public', description } = req.body;\n        \n        const roomId = `room-${Date.now()}-${Math.random().toString(36).substr(2, 9)}`;\n        const room = {\n          id: roomId,\n          name,\n          type,\n          description,\n          createdAt: new Date().toISOString(),\n          memberCount: 0\n        };\n        \n        // Save room to database (implement your persistence logic)\n        \n        res.status(201).json({ room });\n      } catch (error) {\n        res.status(500).json({ error: 'Failed to create room' });\n      }\n    });\n    \n    // Get active rooms\n    this.app.get('/api/rooms', (req, res) => {\n      const activeRooms = Array.from(this.rooms.values()).map(room => ({\n        id: room.id,\n        type: room.type,\n        memberCount: room.members.size,\n        lastActivity: room.lastActivity\n      }));\n      \n      res.json({ rooms: activeRooms });\n    });\n    \n    // Health check\n    this.app.get('/health', (req, res) => {\n      res.json({\n        status: 'healthy',\n        connectedUsers: this.userSessions.size,\n        activeRooms: this.rooms.size,\n        uptime: process.uptime()\n      });\n    });\n  }\n  \n  start() {\n    this.server.listen(this.port, () => {\n      console.log(`Chat server running on port ${this.port}`);\n      console.log(`Socket.IO path: /socket.io/`);\n    });\n  }\n}\n\n// Message persistence\nclass MessageStore {\n  constructor() {\n    this.messages = new Map(); // In production, use a database\n  }\n  \n  async saveMessage(message) {\n    const roomMessages = this.messages.get(message.roomId) || [];\n    roomMessages.push(message);\n    this.messages.set(message.roomId, roomMessages);\n    \n    // In production, save to database\n    // await db.messages.create(message);\n  }\n  \n  async getRoomMessages(roomId, limit = 50, offset = 0) {\n    const roomMessages = this.messages.get(roomId) || [];\n    return roomMessages\n      .slice(-limit - offset, -offset || undefined)\n      .reverse();\n  }\n  \n  async searchMessages(query, roomId) {\n    const roomMessages = this.messages.get(roomId) || [];\n    return roomMessages.filter(msg => \n      msg.content.toLowerCase().includes(query.toLowerCase())\n    );\n  }\n}\n\nexport { ChatServer, MessageStore };\n```\n\n**Client-Side Implementation:**\n\n```javascript\n// chat-client.js - Client-side Socket.IO integration\nimport { io } from 'socket.io-client';\n\nclass ChatClient {\n  constructor(serverUrl, token) {\n    this.serverUrl = serverUrl;\n    this.token = token;\n    this.socket = null;\n    this.currentRoom = null;\n    this.eventHandlers = new Map();\n  }\n  \n  connect() {\n    return new Promise((resolve, reject) => {\n      this.socket = io(this.serverUrl, {\n        auth: {\n          token: this.token\n        },\n        transports: ['websocket', 'polling']\n      });\n      \n      this.socket.on('connect', () => {\n        console.log('Connected to chat server');\n        this.setupEventHandlers();\n        resolve();\n      });\n      \n      this.socket.on('connect_error', (error) => {\n        console.error('Connection failed:', error.message);\n        reject(error);\n      });\n    });\n  }\n  \n  setupEventHandlers() {\n    this.socket.on('new-message', (message) => {\n      this.emit('message', message);\n    });\n    \n    this.socket.on('user-joined', (data) => {\n      this.emit('userJoined', data);\n    });\n    \n    this.socket.on('user-left', (data) => {\n      this.emit('userLeft', data);\n    });\n    \n    this.socket.on('user-typing', (data) => {\n      this.emit('userTyping', data);\n    });\n    \n    this.socket.on('room-history', (data) => {\n      this.emit('roomHistory', data);\n    });\n    \n    this.socket.on('error', (error) => {\n      this.emit('error', error);\n    });\n  }\n  \n  joinRoom(roomId, roomType = 'public') {\n    this.currentRoom = roomId;\n    this.socket.emit('join-room', { roomId, roomType });\n  }\n  \n  leaveRoom(roomId) {\n    this.socket.emit('leave-room', { roomId });\n    if (this.currentRoom === roomId) {\n      this.currentRoom = null;\n    }\n  }\n  \n  sendMessage(content, options = {}) {\n    if (!this.currentRoom) {\n      throw new Error('Not in a room');\n    }\n    \n    this.socket.emit('send-message', {\n      roomId: this.currentRoom,\n      content,\n      messageType: options.type || 'text',\n      replyTo: options.replyTo\n    });\n  }\n  \n  startTyping() {\n    if (this.currentRoom) {\n      this.socket.emit('typing-start', { roomId: this.currentRoom });\n    }\n  }\n  \n  stopTyping() {\n    if (this.currentRoom) {\n      this.socket.emit('typing-stop', { roomId: this.currentRoom });\n    }\n  }\n  \n  getRoomHistory(limit = 50, offset = 0) {\n    if (this.currentRoom) {\n      this.socket.emit('get-room-history', {\n        roomId: this.currentRoom,\n        limit,\n        offset\n      });\n    }\n  }\n  \n  // Event system\n  on(event, handler) {\n    if (!this.eventHandlers.has(event)) {\n      this.eventHandlers.set(event, []);\n    }\n    this.eventHandlers.get(event).push(handler);\n  }\n  \n  emit(event, data) {\n    const handlers = this.eventHandlers.get(event) || [];\n    handlers.forEach(handler => handler(data));\n  }\n  \n  disconnect() {\n    if (this.socket) {\n      this.socket.disconnect();\n    }\n  }\n}\n\n// Usage example\nconst chatClient = new ChatClient('http://localhost:3000', 'your-jwt-token');\n\n// Set up event handlers\nchatClient.on('message', (message) => {\n  console.log('New message:', message);\n  displayMessage(message);\n});\n\nchatClient.on('userJoined', (data) => {\n  console.log('User joined:', data.username);\n  showNotification(`${data.username} joined the room`);\n});\n\nchatClient.on('error', (error) => {\n  console.error('Chat error:', error);\n  showError(error.message);\n});\n\n// Connect and join a room\nawait chatClient.connect();\nchatClient.joinRoom('general');\n\nexport { ChatClient };\n```\n\n**Scaling Considerations:**\n\n1. **Horizontal Scaling**: Use Redis adapter for Socket.IO to share connections across multiple server instances\n2. **Database Optimization**: Index message tables by roomId and timestamp\n3. **Message Persistence**: Use a fast database like MongoDB or Cassandra for message storage\n4. **CDN Integration**: Serve static assets and file uploads through CDN\n5. **Load Balancing**: Use sticky sessions to maintain WebSocket connections\n6. **Caching**: Cache frequently accessed room data and user sessions\n7. **Rate Limiting**: Prevent spam and abuse with comprehensive rate limiting\n8. **Monitoring**: Track connection counts, message rates, and error rates\n\n**Best Practices:**\n\n1. **Authentication**: Always validate user tokens and permissions\n2. **Input Validation**: Sanitize all user inputs to prevent XSS\n3. **Error Handling**: Gracefully handle connection drops and failures\n4. **Performance**: Use efficient data structures and minimize broadcasts\n5. **Security**: Implement proper CORS, rate limiting, and input validation\n6. **Monitoring**: Log important events and monitor system health\n7. **Backup**: Implement message backup and recovery strategies",
        "difficulty": "Expert",
        "category": "Real-World Applications"
    }
]